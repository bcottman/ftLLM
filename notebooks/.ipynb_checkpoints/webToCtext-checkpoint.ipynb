{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6478ae",
   "metadata": {},
   "source": [
    "# finetune a LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608067b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T19:12:33.125685Z",
     "start_time": "2023-05-04T19:12:33.121785Z"
    }
   },
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7775c62f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T20:18:01.493210Z",
     "start_time": "2023-05-15T20:18:01.198075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.9\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c948735",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T20:18:05.185832Z",
     "start_time": "2023-05-15T20:18:05.181334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/brucecottman/Documents/pyProjects/ftLLM/notebooks', '/usr/local/Cellar/apache-spark/2.0.1/libexec/python', '/Users/brucecottman/Documents/pyProjects/ftLLM/notebooks/$', '/Library/Frameworks/Python.framework/Versions/3.7/lib/python37.zip', '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7', '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload', '', '/Users/brucecottman/Library/Python/3.7/lib/python/site-packages', '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages', '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/extensions', '/Users/brucecottman/.ipython']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys, os\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e69c68b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T20:18:15.855391Z",
     "start_time": "2023-05-15T20:18:08.580601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# packages in environment at /Users/brucecottman/anaconda3:',\n",
       " '#',\n",
       " '# Name                    Version                   Build  Channel',\n",
       " 'abseil-cpp                20211102.0           h96cf925_1    conda-forge',\n",
       " 'alabaster                 0.7.12             pyhd3eb1b0_0  ',\n",
       " 'altair                    4.2.2              pyhd8ed1ab_0    conda-forge',\n",
       " 'anaconda-client           1.11.2          py310hecd8cb5_0  ',\n",
       " 'anaconda-navigator        2.4.0           py310hecd8cb5_0  ',\n",
       " 'anaconda-project          0.11.1          py310hecd8cb5_0  ',\n",
       " 'anyio                     3.5.0           py310hecd8cb5_0  ',\n",
       " 'appdirs                   1.4.4              pyhd3eb1b0_0  ',\n",
       " 'applaunchservices         0.3.0           py310hecd8cb5_0  ',\n",
       " 'appnope                   0.1.2           py310hecd8cb5_1001  ',\n",
       " 'appscript                 1.1.2           py310hca72f7f_0  ',\n",
       " 'argon2-cffi               21.3.0             pyhd3eb1b0_0  ',\n",
       " 'argon2-cffi-bindings      21.2.0          py310hca72f7f_0  ',\n",
       " 'arrow                     1.2.3           py310hecd8cb5_1  ',\n",
       " 'arrow-cpp                 11.0.0          py310hfdcd655_0  ',\n",
       " 'astroid                   2.14.2          py310hecd8cb5_0  ',\n",
       " 'astropy                   5.1             py310h4e76f89_0  ',\n",
       " 'asttokens                 2.0.5              pyhd3eb1b0_0  ',\n",
       " 'atomicwrites              1.4.0                      py_0  ',\n",
       " 'attrs                     22.1.0          py310hecd8cb5_0  ',\n",
       " 'automat                   20.2.0                     py_0  ',\n",
       " 'autopep8                  1.6.0              pyhd3eb1b0_1  ',\n",
       " 'aws-c-common              0.4.57               hb1e8313_1  ',\n",
       " 'aws-c-event-stream        0.1.6                h23ab428_5  ',\n",
       " 'aws-checksums             0.1.9                hb1e8313_0  ',\n",
       " 'aws-sdk-cpp               1.8.185              he271ece_0  ',\n",
       " 'babel                     2.11.0          py310hecd8cb5_0  ',\n",
       " 'backcall                  0.2.0              pyhd3eb1b0_0  ',\n",
       " 'backports                 1.1                pyhd3eb1b0_0  ',\n",
       " 'backports.functools_lru_cache 1.6.4              pyhd3eb1b0_0  ',\n",
       " 'backports.tempfile        1.0                pyhd3eb1b0_1  ',\n",
       " 'backports.weakref         1.0.post1                  py_1  ',\n",
       " 'bcrypt                    3.2.0           py310hca72f7f_1  ',\n",
       " 'beautifulsoup4            4.11.1          py310hecd8cb5_0  ',\n",
       " 'binaryornot               0.4.4              pyhd3eb1b0_1  ',\n",
       " 'black                     22.6.0          py310hecd8cb5_0  ',\n",
       " 'blas                      1.0                    openblas  ',\n",
       " 'bleach                    4.1.0              pyhd3eb1b0_0  ',\n",
       " 'blinker                   1.6.2              pyhd8ed1ab_0    conda-forge',\n",
       " 'blosc                     1.21.3               hcec6c5f_0  ',\n",
       " 'bokeh                     2.4.3           py310hecd8cb5_0  ',\n",
       " 'boltons                   23.0.0          py310hecd8cb5_0  ',\n",
       " 'boost-cpp                 1.70.0               hd59e818_1    conda-forge',\n",
       " 'bottleneck                1.3.5           py310h4e76f89_0  ',\n",
       " 'brotli                    1.0.9                hca72f7f_7  ',\n",
       " 'brotli-bin                1.0.9                hca72f7f_7  ',\n",
       " 'brotlipy                  0.7.0           py310hca72f7f_1002  ',\n",
       " 'brunsli                   0.1                  h23ab428_0  ',\n",
       " 'bzip2                     1.0.8                h1de35cc_0  ',\n",
       " 'c-ares                    1.18.1               hca72f7f_0  ',\n",
       " 'ca-certificates           2022.12.7            h033912b_0    conda-forge',\n",
       " 'cachetools                5.3.0              pyhd8ed1ab_0    conda-forge',\n",
       " 'catalogue                 2.0.8           py310h2ec42d9_1    conda-forge',\n",
       " 'cctools                   949.0.1             h9abeeb2_25  ',\n",
       " 'cctools_osx-64            949.0.1             hc7db93f_25  ',\n",
       " 'certifi                   2022.12.7          pyhd8ed1ab_0    conda-forge',\n",
       " 'cffi                      1.15.1          py310h6c40b1e_3  ',\n",
       " 'cfitsio                   3.470                hbd21bf8_7  ',\n",
       " 'chardet                   4.0.0           py310hecd8cb5_1003  ',\n",
       " 'charls                    2.2.0                h23ab428_0  ',\n",
       " 'charset-normalizer        2.0.4              pyhd3eb1b0_0  ',\n",
       " 'click                     8.0.4           py310hecd8cb5_0  ',\n",
       " 'cloudpickle               2.0.0              pyhd3eb1b0_0  ',\n",
       " 'clyent                    1.2.2           py310hecd8cb5_1  ',\n",
       " 'colorama                  0.4.6           py310hecd8cb5_0  ',\n",
       " 'colorcet                  3.0.1           py310hecd8cb5_0  ',\n",
       " 'comm                      0.1.2           py310hecd8cb5_0  ',\n",
       " 'conda                     23.3.1          py310hecd8cb5_0  ',\n",
       " 'conda-build               3.24.0          py310hecd8cb5_0  ',\n",
       " 'conda-content-trust       0.1.3           py310hecd8cb5_0  ',\n",
       " 'conda-pack                0.6.0              pyhd3eb1b0_0  ',\n",
       " 'conda-package-handling    2.0.2           py310hecd8cb5_0  ',\n",
       " 'conda-package-streaming   0.7.0           py310hecd8cb5_0  ',\n",
       " 'conda-repo-cli            1.0.41          py310hecd8cb5_0  ',\n",
       " 'conda-token               0.4.0              pyhd3eb1b0_0  ',\n",
       " 'conda-verify              3.4.2                      py_1  ',\n",
       " 'constantly                15.1.0          py310hecd8cb5_0  ',\n",
       " 'contourpy                 1.0.5           py310haf03e11_0  ',\n",
       " 'cookiecutter              1.7.3              pyhd3eb1b0_0  ',\n",
       " 'cryptography              39.0.1          py310hf6deb26_0  ',\n",
       " 'cssselect                 1.1.0              pyhd3eb1b0_0  ',\n",
       " 'curl                      7.87.0               h6c40b1e_0  ',\n",
       " 'cycler                    0.11.0             pyhd3eb1b0_0  ',\n",
       " 'cymem                     2.0.7           py310h7a76584_1    conda-forge',\n",
       " 'cython-blis               0.7.9           py310h936d966_1    conda-forge',\n",
       " 'cytoolz                   0.12.0          py310hca72f7f_0  ',\n",
       " 'dask                      2022.7.0        py310hecd8cb5_0  ',\n",
       " 'dask-core                 2022.7.0        py310hecd8cb5_0  ',\n",
       " 'dataclasses               0.8                pyhc8e2a94_3    conda-forge',\n",
       " 'datashader                0.14.4          py310hecd8cb5_0  ',\n",
       " 'datashape                 0.5.4           py310hecd8cb5_1  ',\n",
       " 'debugpy                   1.5.1           py310he9d5cce_0  ',\n",
       " 'decorator                 5.1.1              pyhd3eb1b0_0  ',\n",
       " 'defusedxml                0.7.1              pyhd3eb1b0_0  ',\n",
       " 'diff-match-patch          20200713           pyhd3eb1b0_0  ',\n",
       " 'dill                      0.3.6           py310hecd8cb5_0  ',\n",
       " 'distributed               2022.7.0        py310hecd8cb5_0  ',\n",
       " 'docstring-to-markdown     0.11            py310hecd8cb5_0  ',\n",
       " 'docutils                  0.18.1          py310hecd8cb5_3  ',\n",
       " 'entrypoints               0.4             py310hecd8cb5_0  ',\n",
       " 'et_xmlfile                1.1.0           py310hecd8cb5_0  ',\n",
       " 'executing                 0.8.3              pyhd3eb1b0_0  ',\n",
       " 'filelock                  3.9.0           py310hecd8cb5_0  ',\n",
       " 'flake8                    6.0.0           py310hecd8cb5_0  ',\n",
       " 'flask                     2.2.2           py310hecd8cb5_0  ',\n",
       " 'flit-core                 3.6.0              pyhd3eb1b0_0  ',\n",
       " 'fonttools                 4.25.0             pyhd3eb1b0_0  ',\n",
       " 'freetype                  2.12.1               hd8bbffd_0  ',\n",
       " 'fsspec                    2022.11.0       py310hecd8cb5_0  ',\n",
       " 'future                    0.18.3          py310hecd8cb5_0  ',\n",
       " 'gensim                    4.3.0           py310h3ea8b11_0  ',\n",
       " 'gettext                   0.21.0               h7535e17_0  ',\n",
       " 'gflags                    2.2.2             hb1e8313_1004    conda-forge',\n",
       " 'giflib                    5.2.1                h6c40b1e_3  ',\n",
       " 'gitdb                     4.0.10             pyhd8ed1ab_0    conda-forge',\n",
       " 'gitpython                 3.1.31             pyhd8ed1ab_0    conda-forge',\n",
       " 'glib                      2.69.1               hfff2838_2  ',\n",
       " 'glob2                     0.7                pyhd3eb1b0_0  ',\n",
       " 'glog                      0.5.0                h25b26a9_0    conda-forge',\n",
       " 'gmp                       6.2.1                he9d5cce_3  ',\n",
       " 'gmpy2                     2.1.2           py310hd5de756_0  ',\n",
       " 'greenlet                  2.0.1           py310hcec6c5f_0  ',\n",
       " 'grpc-cpp                  1.46.1               h64d96ca_1  ',\n",
       " 'gst-plugins-base          1.14.1               hcec6c5f_1  ',\n",
       " 'gstreamer                 1.14.1               h6c40b1e_1  ',\n",
       " 'h5py                      3.7.0           py310h6c517f8_0  ',\n",
       " 'hdf5                      1.10.6               h10fe05b_1  ',\n",
       " 'heapdict                  1.0.1              pyhd3eb1b0_0  ',\n",
       " 'holoviews                 1.15.4          py310hecd8cb5_0  ',\n",
       " 'huggingface_hub           0.10.1          py310hecd8cb5_0  ',\n",
       " 'hvplot                    0.8.2           py310hecd8cb5_0  ',\n",
       " 'hyperlink                 21.0.0             pyhd3eb1b0_0  ',\n",
       " 'icu                       58.2                 h0a44026_3  ',\n",
       " 'idna                      3.4             py310hecd8cb5_0  ',\n",
       " 'imagecodecs               2021.8.26       py310hf5cf8d7_2  ',\n",
       " 'imageio                   2.26.0          py310hecd8cb5_0  ',\n",
       " 'imagesize                 1.4.1           py310hecd8cb5_0  ',\n",
       " 'imbalanced-learn          0.10.1          py310hecd8cb5_0  ',\n",
       " 'importlib-metadata        4.11.3          py310hecd8cb5_0  ',\n",
       " 'importlib_metadata        4.11.3               hd3eb1b0_0  ',\n",
       " 'incremental               21.3.0             pyhd3eb1b0_0  ',\n",
       " 'inflection                0.5.1           py310hecd8cb5_0  ',\n",
       " 'iniconfig                 1.1.1              pyhd3eb1b0_0  ',\n",
       " 'intake                    0.6.7           py310hecd8cb5_0  ',\n",
       " 'intervaltree              3.1.0              pyhd3eb1b0_0  ',\n",
       " 'ipykernel                 6.19.2          py310h20db666_0  ',\n",
       " 'ipython                   8.10.0          py310hecd8cb5_0  ',\n",
       " 'ipython_genutils          0.2.0              pyhd3eb1b0_1  ',\n",
       " 'ipywidgets                7.6.5              pyhd3eb1b0_1  ',\n",
       " 'isort                     5.9.3              pyhd3eb1b0_0  ',\n",
       " 'itemadapter               0.3.0              pyhd3eb1b0_0  ',\n",
       " 'itemloaders               1.0.4              pyhd3eb1b0_1  ',\n",
       " 'itsdangerous              2.0.1              pyhd3eb1b0_0  ',\n",
       " 'jedi                      0.18.1          py310hecd8cb5_1  ',\n",
       " 'jellyfish                 0.9.0           py310hca72f7f_0  ',\n",
       " 'jinja2                    3.1.2           py310hecd8cb5_0  ',\n",
       " 'jinja2-time               0.2.0              pyhd3eb1b0_3  ',\n",
       " 'jmespath                  0.10.0             pyhd3eb1b0_0  ',\n",
       " 'joblib                    1.1.1           py310hecd8cb5_0  ',\n",
       " 'jpeg                      9e                   h6c40b1e_1  ',\n",
       " 'jq                        1.6               h9ed2024_1000  ',\n",
       " 'json5                     0.9.6              pyhd3eb1b0_0  ',\n",
       " 'jsonpatch                 1.32               pyhd3eb1b0_0  ',\n",
       " 'jsonpointer               2.1                pyhd3eb1b0_0  ',\n",
       " 'jsonschema                4.17.3          py310hecd8cb5_0  ',\n",
       " 'jupyter                   1.0.0           py310hecd8cb5_8  ',\n",
       " 'jupyter_client            7.3.4           py310hecd8cb5_0  ',\n",
       " 'jupyter_console           6.6.2           py310hecd8cb5_0  ',\n",
       " 'jupyter_core              5.2.0           py310hecd8cb5_0  ',\n",
       " 'jupyter_server            1.23.4          py310hecd8cb5_0  ',\n",
       " 'jupyterlab                3.5.3           py310hecd8cb5_0  ',\n",
       " 'jupyterlab_pygments       0.1.2                      py_0  ',\n",
       " 'jupyterlab_server         2.19.0          py310hecd8cb5_0  ',\n",
       " 'jupyterlab_widgets        1.0.0              pyhd3eb1b0_1  ',\n",
       " 'jxrlib                    1.1                  haf1e3a3_2  ',\n",
       " 'keyring                   23.4.0          py310hecd8cb5_0  ',\n",
       " 'kiwisolver                1.4.4           py310hcec6c5f_0  ',\n",
       " 'krb5                      1.19.4               hdba6334_0  ',\n",
       " 'langcodes                 3.3.0              pyhd8ed1ab_0    conda-forge',\n",
       " 'lazy-object-proxy         1.6.0           py310hca72f7f_0  ',\n",
       " 'lcms2                     2.12                 hf1fd2bf_0  ',\n",
       " 'ld64                      530                 h20443b4_25  ',\n",
       " 'ld64_osx-64               530                 h70f3046_25  ',\n",
       " 'ldid                      2.1.2                h2d21305_2  ',\n",
       " 'lerc                      3.0                  he9d5cce_0  ',\n",
       " 'libaec                    1.0.4                hb1e8313_1  ',\n",
       " 'libarchive                3.6.2                h65c5294_0  ',\n",
       " 'libbrotlicommon           1.0.9                hca72f7f_7  ',\n",
       " 'libbrotlidec              1.0.9                hca72f7f_7  ',\n",
       " 'libbrotlienc              1.0.9                hca72f7f_7  ',\n",
       " 'libclang                  12.0.0          default_hbc2896b_2  ',\n",
       " 'libcurl                   7.87.0               ha585b31_0  ',\n",
       " 'libcxx                    14.0.6               h9765a3e_0  ',\n",
       " 'libdeflate                1.17                 hb664fd8_0  ',\n",
       " 'libedit                   3.1.20221030         h6c40b1e_0  ',\n",
       " 'libev                     4.33                 h9ed2024_1  ',\n",
       " 'libevent                  2.1.10               h815e4d9_4    conda-forge',\n",
       " 'libffi                    3.4.2                hecd8cb5_6  ',\n",
       " 'libgfortran               5.0.0           11_3_0_hecd8cb5_28  ',\n",
       " 'libgfortran5              11.3.0              h9dfd629_28  ',\n",
       " 'libiconv                  1.16                 hca72f7f_2  ',\n",
       " 'liblief                   0.12.3               hcec6c5f_0  ',\n",
       " 'libllvm11                 11.1.0               h46f1229_6  ',\n",
       " 'libllvm12                 12.0.0               h9b2ccf5_3  ',\n",
       " 'libllvm14                 14.0.6               h91fad77_2  ',\n",
       " 'libnghttp2                1.46.0               ha29bfda_0  ',\n",
       " 'libopenblas               0.3.21               h54e7dc3_0  ',\n",
       " 'libpng                    1.6.39               h6c40b1e_0  ',\n",
       " 'libpq                     12.9                 h1c9f633_3  ',\n",
       " 'libprotobuf               3.20.3               hfff2838_0  ',\n",
       " 'libsodium                 1.0.18               h1de35cc_0  ',\n",
       " 'libspatialindex           1.9.3                h23ab428_0  ',\n",
       " 'libssh2                   1.10.0               h0a4fc7d_0  ',\n",
       " 'libthrift                 0.15.0               h054ceb0_0  ',\n",
       " 'libtiff                   4.5.0                hcec6c5f_2  ',\n",
       " 'libuv                     1.44.2               h6c40b1e_0  ',\n",
       " 'libwebp                   1.2.4                hf6ce154_1  ',\n",
       " 'libwebp-base              1.2.4                h6c40b1e_1  ',\n",
       " 'libxml2                   2.9.14               hbf8cd5e_0  ',\n",
       " 'libxslt                   1.1.35               h5b33f42_0  ',\n",
       " 'libzopfli                 1.0.3                hb1e8313_0  ',\n",
       " 'llvm-openmp               14.0.6               h0dcd299_0  ',\n",
       " 'llvmlite                  0.39.1          py310h8346a28_0  ',\n",
       " 'locket                    1.0.0           py310hecd8cb5_0  ',\n",
       " 'lxml                      4.9.1           py310h65b224f_0  ',\n",
       " 'lz4                       3.1.3           py310hca72f7f_0  ',\n",
       " 'lz4-c                     1.9.4                hcec6c5f_0  ',\n",
       " 'lzo                       2.10                 haf1e3a3_2  ',\n",
       " 'markdown                  3.4.1           py310hecd8cb5_0  ',\n",
       " 'markdown-it-py            2.2.0              pyhd8ed1ab_0    conda-forge',\n",
       " 'markupsafe                2.1.1           py310hca72f7f_0  ',\n",
       " 'matplotlib                3.7.0           py310hecd8cb5_0  ',\n",
       " 'matplotlib-base           3.7.0           py310ha533b9c_0  ',\n",
       " 'matplotlib-inline         0.1.6           py310hecd8cb5_0  ',\n",
       " 'mccabe                    0.7.0              pyhd3eb1b0_0  ',\n",
       " 'mdurl                     0.1.0              pyhd8ed1ab_0    conda-forge',\n",
       " 'mistune                   0.8.4           py310hca72f7f_1000  ',\n",
       " 'mock                      4.0.3              pyhd3eb1b0_0  ',\n",
       " 'mpc                       1.1.0                h6ef4df4_1  ',\n",
       " 'mpfr                      4.0.2                h9066e36_1  ',\n",
       " 'mpmath                    1.2.1                    pypi_0    pypi',\n",
       " 'msgpack-python            1.0.3           py310haf03e11_0  ',\n",
       " 'multipledispatch          0.6.0           py310hecd8cb5_0  ',\n",
       " 'munkres                   1.1.4                      py_0  ',\n",
       " 'murmurhash                1.0.9           py310h7a76584_1    conda-forge',\n",
       " 'mypy_extensions           0.4.3           py310hecd8cb5_1  ',\n",
       " 'navigator-updater         0.3.0           py310hecd8cb5_0  ',\n",
       " 'nbclassic                 0.5.2           py310hecd8cb5_0  ',\n",
       " 'nbclient                  0.5.13          py310hecd8cb5_0  ',\n",
       " 'nbconvert                 6.5.4           py310hecd8cb5_0  ',\n",
       " 'nbformat                  5.7.0           py310hecd8cb5_0  ',\n",
       " 'ncurses                   6.4                  hcec6c5f_0  ',\n",
       " 'nest-asyncio              1.5.6           py310hecd8cb5_0  ',\n",
       " 'networkx                  2.8.4           py310hecd8cb5_0  ',\n",
       " 'ninja                     1.10.2               hecd8cb5_5  ',\n",
       " 'ninja-base                1.10.2               haf03e11_5  ',\n",
       " 'nltk                      3.7                pyhd3eb1b0_0  ',\n",
       " 'notebook                  6.5.2           py310hecd8cb5_0  ',\n",
       " 'notebook-shim             0.2.2           py310hecd8cb5_0  ',\n",
       " 'nspr                      4.33                 he9d5cce_0  ',\n",
       " 'nss                       3.74                 h47edf6a_0  ',\n",
       " 'numba                     0.56.4          py310h3ea8b11_0  ',\n",
       " 'numexpr                   2.8.4           py310he50c29a_0  ',\n",
       " 'numpy                     1.23.5          py310he50c29a_0  ',\n",
       " 'numpy-base                1.23.5          py310h992e150_0  ',\n",
       " 'numpydoc                  1.5.0           py310hecd8cb5_0  ',\n",
       " 'oniguruma                 6.9.7.1              h9ed2024_0  ',\n",
       " 'openjpeg                  2.4.0                h66ea3da_0  ',\n",
       " 'openpyxl                  3.0.10          py310hca72f7f_0  ',\n",
       " 'openssl                   1.1.1t               hfd90126_0    conda-forge',\n",
       " 'orc                       1.7.4                h995b336_1  ',\n",
       " 'packaging                 22.0            py310hecd8cb5_0  ',\n",
       " 'pandas                    1.5.3           py310h3ea8b11_0  ',\n",
       " 'pandocfilters             1.5.0              pyhd3eb1b0_0  ',\n",
       " 'panel                     0.14.3          py310hecd8cb5_0  ',\n",
       " 'param                     1.12.3          py310hecd8cb5_0  ',\n",
       " 'parsel                    1.6.0           py310hecd8cb5_0  ',\n",
       " 'parso                     0.8.3              pyhd3eb1b0_0  ',\n",
       " 'partd                     1.2.0              pyhd3eb1b0_1  ',\n",
       " 'patch                     2.7.6             h1de35cc_1001  ',\n",
       " 'pathlib                   1.0.1              pyhd3eb1b0_1  ',\n",
       " 'pathspec                  0.10.3          py310hecd8cb5_0  ',\n",
       " 'pathy                     0.10.1             pyhd8ed1ab_0    conda-forge',\n",
       " 'patsy                     0.5.3           py310hecd8cb5_0  ',\n",
       " 'pcre                      8.45                 h23ab428_0  ',\n",
       " 'pep8                      1.7.1           py310hecd8cb5_1  ',\n",
       " 'pexpect                   4.8.0              pyhd3eb1b0_3  ',\n",
       " 'pickleshare               0.7.5           pyhd3eb1b0_1003  ',\n",
       " 'pillow                    9.4.0           py310hcec6c5f_0  ',\n",
       " 'pip                       22.3.1          py310hecd8cb5_0  ',\n",
       " 'pkginfo                   1.9.6           py310hecd8cb5_0  ',\n",
       " 'platformdirs              2.5.2           py310hecd8cb5_0  ',\n",
       " 'plotly                    5.9.0           py310hecd8cb5_0  ',\n",
       " 'pluggy                    1.0.0           py310hecd8cb5_1  ',\n",
       " 'ply                       3.11            py310hecd8cb5_0  ',\n",
       " 'pooch                     1.4.0              pyhd3eb1b0_0  ',\n",
       " 'poyo                      0.5.0              pyhd3eb1b0_0  ',\n",
       " 'preshed                   3.0.8           py310h7a76584_1    conda-forge',\n",
       " 'prometheus_client         0.14.1          py310hecd8cb5_0  ',\n",
       " 'prompt-toolkit            3.0.36          py310hecd8cb5_0  ',\n",
       " 'prompt_toolkit            3.0.36               hd3eb1b0_0  ',\n",
       " 'protego                   0.1.16                     py_0  ',\n",
       " 'protobuf                  3.20.3          py310h7a76584_1    conda-forge',\n",
       " 'psutil                    5.9.0           py310hca72f7f_0  ',\n",
       " 'ptyprocess                0.7.0              pyhd3eb1b0_2  ',\n",
       " 'pure_eval                 0.2.2              pyhd3eb1b0_0  ',\n",
       " 'py                        1.11.0             pyhd3eb1b0_0  ',\n",
       " 'py-lief                   0.12.3          py310hcec6c5f_0  ',\n",
       " 'pyarrow                   11.0.0          py310he65a03e_0  ',\n",
       " 'pyasn1                    0.4.8              pyhd3eb1b0_0  ',\n",
       " 'pyasn1-modules            0.2.8                      py_0  ',\n",
       " 'pycodestyle               2.10.0          py310hecd8cb5_0  ',\n",
       " 'pycosat                   0.6.4           py310hca72f7f_0  ',\n",
       " 'pycparser                 2.21               pyhd3eb1b0_0  ',\n",
       " 'pyct                      0.5.0           py310hecd8cb5_0  ',\n",
       " 'pycurl                    7.45.1                   pypi_0    pypi',\n",
       " 'pydantic                  1.10.7          py310h90acd4f_0    conda-forge',\n",
       " 'pydeck                    0.8.0              pyhd8ed1ab_0    conda-forge',\n",
       " 'pydispatcher              2.0.5           py310hecd8cb5_2  ',\n",
       " 'pydocstyle                6.3.0           py310hecd8cb5_0  ',\n",
       " 'pyerfa                    2.0.0           py310hca72f7f_0  ',\n",
       " 'pyflakes                  3.0.1           py310hecd8cb5_0  ',\n",
       " 'pygments                  2.11.2             pyhd3eb1b0_0  ',\n",
       " 'pyhamcrest                2.0.2              pyhd3eb1b0_2  ',\n",
       " 'pyjwt                     2.4.0           py310hecd8cb5_0  ',\n",
       " 'pylint                    2.16.2          py310hecd8cb5_0  ',\n",
       " 'pylint-venv               2.3.0           py310hecd8cb5_0  ',\n",
       " 'pyls-spyder               0.4.0              pyhd3eb1b0_0  ',\n",
       " 'pympler                   1.0.1              pyhd8ed1ab_0    conda-forge',\n",
       " 'pyobjc-core               9.0             py310h9205ec4_1  ',\n",
       " 'pyobjc-framework-cocoa    9.0             py310h9205ec4_0  ',\n",
       " 'pyobjc-framework-coreservices 9.0             py310h46256e1_0  ',\n",
       " 'pyobjc-framework-fsevents 9.0             py310hecd8cb5_0  ',\n",
       " 'pyodbc                    4.0.34          py310he9d5cce_0  ',\n",
       " 'pyopenssl                 23.0.0          py310hecd8cb5_0  ',\n",
       " 'pyparsing                 3.0.9           py310hecd8cb5_0  ',\n",
       " 'pyqt                      5.15.7          py310he9d5cce_0  ',\n",
       " 'pyqt5-sip                 12.11.0                  pypi_0    pypi',\n",
       " 'pyqtwebengine             5.15.7          py310he9d5cce_0  ',\n",
       " 'pyrsistent                0.18.0          py310hca72f7f_0  ',\n",
       " 'pysocks                   1.7.1           py310hecd8cb5_0  ',\n",
       " 'pytables                  3.7.0           py310h59775c6_1  ',\n",
       " 'pytest                    7.1.2           py310hecd8cb5_0  ',\n",
       " 'python                    3.10.9               h218abb5_1  ',\n",
       " 'python-dateutil           2.8.2              pyhd3eb1b0_0  ',\n",
       " 'python-fastjsonschema     2.16.2          py310hecd8cb5_0  ',\n",
       " 'python-libarchive-c       2.9                pyhd3eb1b0_1  ',\n",
       " 'python-lsp-black          1.2.1           py310hecd8cb5_0  ',\n",
       " 'python-lsp-jsonrpc        1.0.0              pyhd3eb1b0_0  ',\n",
       " 'python-lsp-server         1.7.1           py310hecd8cb5_0  ',\n",
       " 'python-slugify            5.0.2              pyhd3eb1b0_0  ',\n",
       " 'python-snappy             0.6.1           py310hcec6c5f_0  ',\n",
       " 'python-tzdata             2023.3             pyhd8ed1ab_0    conda-forge',\n",
       " 'python.app                3               py310hca72f7f_0  ',\n",
       " 'python_abi                3.10                    2_cp310    conda-forge',\n",
       " 'pytoolconfig              1.2.5           py310hecd8cb5_1  ',\n",
       " 'pytorch                   1.12.1          cpu_py310h64f2f56_1  ',\n",
       " 'pytz                      2022.7          py310hecd8cb5_0  ',\n",
       " 'pytz-deprecation-shim     0.1.0.post0     py310h2ec42d9_3    conda-forge',\n",
       " 'pyviz_comms               2.0.2              pyhd3eb1b0_0  ',\n",
       " 'pywavelets                1.4.1           py310h6c40b1e_0  ',\n",
       " 'pyyaml                    6.0             py310h6c40b1e_1  ',\n",
       " 'pyzmq                     23.2.0          py310he9d5cce_0  ',\n",
       " 'qdarkstyle                3.0.2              pyhd3eb1b0_0  ',\n",
       " 'qstylizer                 0.2.2           py310hecd8cb5_0  ',\n",
       " 'qt-main                   5.15.2               h719ae48_7  ',\n",
       " 'qt-webengine              5.15.9               h90a370e_4  ',\n",
       " 'qtawesome                 1.2.2           py310hecd8cb5_0  ',\n",
       " 'qtconsole                 5.4.0           py310hecd8cb5_0  ',\n",
       " 'qtpy                      2.2.0           py310hecd8cb5_0  ',\n",
       " 'qtwebkit                  5.212                h24dc246_4  ',\n",
       " 'queuelib                  1.5.0           py310hecd8cb5_0  ',\n",
       " 're2                       2022.04.01           h96cf925_0    conda-forge',\n",
       " 'readline                  8.2                  hca72f7f_0  ',\n",
       " 'regex                     2022.7.9        py310hca72f7f_0  ',\n",
       " 'requests                  2.28.1          py310hecd8cb5_0  ',\n",
       " 'requests-file             1.5.1              pyhd3eb1b0_0  ',\n",
       " 'requests-toolbelt         0.9.1              pyhd3eb1b0_0  ',\n",
       " 'rich                      13.2.0             pyhd8ed1ab_1    conda-forge',\n",
       " 'ripgrep                   13.0.0               hc2228c6_0  ',\n",
       " 'rope                      1.7.0           py310hecd8cb5_0  ',\n",
       " 'rtree                     1.0.1           py310hecd8cb5_0  ',\n",
       " 'ruamel.yaml               0.17.21         py310hca72f7f_0  ',\n",
       " 'ruamel.yaml.clib          0.2.6           py310hca72f7f_1  ',\n",
       " 'ruamel_yaml               0.17.21         py310hca72f7f_0  ',\n",
       " 'scikit-image              0.19.3          py310hcec6c5f_1  ',\n",
       " 'scikit-learn              1.2.1           py310hcec6c5f_0  ',\n",
       " 'scipy                     1.10.0          py310ha516a68_1  ',\n",
       " 'scrapy                    2.8.0           py310hecd8cb5_0  ',\n",
       " 'seaborn                   0.12.2          py310hecd8cb5_0  ',\n",
       " 'send2trash                1.8.0              pyhd3eb1b0_1  ',\n",
       " 'service_identity          18.1.0             pyhd3eb1b0_1  ',\n",
       " 'setuptools                65.6.3          py310hecd8cb5_0  ',\n",
       " 'shellingham               1.5.1              pyhd8ed1ab_0    conda-forge',\n",
       " 'sip                       6.6.2           py310he9d5cce_0  ',\n",
       " 'six                       1.16.0             pyhd3eb1b0_1  ',\n",
       " 'smart_open                5.2.1           py310hecd8cb5_0  ',\n",
       " 'smmap                     3.0.5              pyh44b312d_0    conda-forge',\n",
       " 'snappy                    1.1.9                he9d5cce_0  ',\n",
       " 'sniffio                   1.2.0           py310hecd8cb5_1  ',\n",
       " 'snowballstemmer           2.2.0              pyhd3eb1b0_0  ',\n",
       " 'sortedcontainers          2.4.0              pyhd3eb1b0_0  ',\n",
       " 'soupsieve                 2.3.2.post1     py310hecd8cb5_0  ',\n",
       " 'spacy                     3.3.1           py310h7ff4b7e_0  ',\n",
       " 'spacy-legacy              3.0.12             pyhd8ed1ab_0    conda-forge',\n",
       " 'spacy-loggers             1.0.4              pyhd8ed1ab_0    conda-forge',\n",
       " 'sphinx                    5.0.2           py310hecd8cb5_0  ',\n",
       " 'sphinxcontrib-applehelp   1.0.2              pyhd3eb1b0_0  ',\n",
       " 'sphinxcontrib-devhelp     1.0.2              pyhd3eb1b0_0  ',\n",
       " 'sphinxcontrib-htmlhelp    2.0.0              pyhd3eb1b0_0  ',\n",
       " 'sphinxcontrib-jsmath      1.0.1              pyhd3eb1b0_0  ',\n",
       " 'sphinxcontrib-qthelp      1.0.3              pyhd3eb1b0_0  ',\n",
       " 'sphinxcontrib-serializinghtml 1.1.5              pyhd3eb1b0_0  ',\n",
       " 'spyder                    5.4.1           py310hecd8cb5_0  ',\n",
       " 'spyder-kernels            2.4.1           py310hecd8cb5_0  ',\n",
       " 'sqlalchemy                1.4.39          py310hca72f7f_0  ',\n",
       " 'sqlite                    3.40.1               h880c91c_0  ',\n",
       " 'srsly                     2.4.6           py310h7a76584_0    conda-forge',\n",
       " 'stack_data                0.2.0              pyhd3eb1b0_0  ',\n",
       " 'statsmodels               0.13.5          py310h7b7cdfe_1  ',\n",
       " 'streamlit                 1.22.0             pyhd8ed1ab_2    conda-forge',\n",
       " 'sympy                     1.11.1          py310hecd8cb5_0  ',\n",
       " 'tabulate                  0.8.10          py310hecd8cb5_0  ',\n",
       " 'tapi                      1000.10.8            ha1b3eb9_0  ',\n",
       " 'tbb                       2021.7.0             ha357a0b_0  ',\n",
       " 'tbb4py                    2021.7.0        py310ha357a0b_0  ',\n",
       " 'tblib                     1.7.0              pyhd3eb1b0_0  ',\n",
       " 'tenacity                  8.0.1           py310hecd8cb5_1  ',\n",
       " 'terminado                 0.17.1          py310hecd8cb5_0  ',\n",
       " 'text-unidecode            1.3                pyhd3eb1b0_0  ',\n",
       " 'textdistance              4.2.1              pyhd3eb1b0_0  ',\n",
       " 'thinc                     8.0.15          py310h7ff4b7e_0  ',\n",
       " 'threadpoolctl             2.2.0              pyh0d69192_0  ',\n",
       " 'three-merge               0.1.1              pyhd3eb1b0_0  ',\n",
       " 'tifffile                  2021.7.2           pyhd3eb1b0_2  ',\n",
       " 'tinycss2                  1.2.1           py310hecd8cb5_0  ',\n",
       " 'tk                        8.6.12               h5d9f67b_0  ',\n",
       " 'tldextract                3.2.0              pyhd3eb1b0_0  ',\n",
       " 'tokenizers                0.11.4          py310h8776b5c_1  ',\n",
       " 'toml                      0.10.2             pyhd3eb1b0_0  ',\n",
       " 'tomli                     2.0.1           py310hecd8cb5_0  ',\n",
       " 'tomlkit                   0.11.1          py310hecd8cb5_0  ',\n",
       " 'toolz                     0.12.0          py310hecd8cb5_0  ',\n",
       " 'tornado                   6.1             py310hca72f7f_0  ',\n",
       " 'tqdm                      4.64.1          py310hecd8cb5_0  ',\n",
       " 'traitlets                 5.7.1           py310hecd8cb5_0  ',\n",
       " 'transformers              4.24.0          py310hecd8cb5_0  ',\n",
       " 'twisted                   22.2.0          py310hca72f7f_1  ',\n",
       " 'typer                     0.4.2              pyhd8ed1ab_0    conda-forge',\n",
       " 'typing-extensions         4.4.0           py310hecd8cb5_0  ',\n",
       " 'typing_extensions         4.4.0           py310hecd8cb5_0  ',\n",
       " 'tzdata                    2022g                h04d1e81_0  ',\n",
       " 'tzlocal                   4.3             py310h2ec42d9_0    conda-forge',\n",
       " 'ujson                     5.4.0           py310he9d5cce_0  ',\n",
       " 'unidecode                 1.2.0              pyhd3eb1b0_0  ',\n",
       " 'unixodbc                  2.3.11               hb456775_0  ',\n",
       " 'urllib3                   1.26.14         py310hecd8cb5_0  ',\n",
       " 'utf8proc                  2.6.1                h9ed2024_0  ',\n",
       " 'validators                0.20.0             pyhd8ed1ab_0    conda-forge',\n",
       " 'w3lib                     1.21.0             pyhd3eb1b0_0  ',\n",
       " 'wasabi                    0.10.1             pyhd8ed1ab_1    conda-forge',\n",
       " 'watchdog                  2.1.6           py310h999c104_0  ',\n",
       " 'wcwidth                   0.2.5              pyhd3eb1b0_0  ',\n",
       " 'webencodings              0.5.1           py310hecd8cb5_1  ',\n",
       " 'websocket-client          0.58.0          py310hecd8cb5_4  ',\n",
       " 'werkzeug                  2.2.2           py310hecd8cb5_0  ',\n",
       " 'whatthepatch              1.0.2           py310hecd8cb5_0  ',\n",
       " 'wheel                     0.38.4          py310hecd8cb5_0  ',\n",
       " 'widgetsnbextension        3.5.2           py310hecd8cb5_0  ',\n",
       " 'wrapt                     1.14.1          py310hca72f7f_0  ',\n",
       " 'wurlitzer                 3.0.2           py310hecd8cb5_0  ',\n",
       " 'xarray                    2022.11.0       py310hecd8cb5_0  ',\n",
       " 'xlwings                   0.29.1          py310hecd8cb5_0  ',\n",
       " 'xz                        5.2.10               h6c40b1e_1  ',\n",
       " 'yaml                      0.2.5                haf1e3a3_0  ',\n",
       " 'yapf                      0.31.0             pyhd3eb1b0_0  ',\n",
       " 'zeromq                    4.3.4                h23ab428_0  ',\n",
       " 'zfp                       0.5.5                he9d5cce_6  ',\n",
       " 'zict                      2.1.0           py310hecd8cb5_0  ',\n",
       " 'zipp                      3.11.0          py310hecd8cb5_0  ',\n",
       " 'zlib                      1.2.13               h4dc903c_0  ',\n",
       " 'zope                      1.0             py310hecd8cb5_1  ',\n",
       " 'zope.interface            5.4.0           py310hca72f7f_0  ',\n",
       " 'zstandard                 0.19.0          py310h6c40b1e_0  ',\n",
       " 'zstd                      1.5.2                hcb37349_0  ']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "packages = !conda list\n",
    "packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5150b85a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T20:18:17.224371Z",
     "start_time": "2023-05-15T20:18:15.859753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package               Version\n",
      "--------------------- -----------\n",
      "altair                4.2.2\n",
      "attrs                 23.1.0\n",
      "blinker               1.6.2\n",
      "cachetools            5.3.0\n",
      "certifi               2022.12.7\n",
      "charset-normalizer    3.1.0\n",
      "click                 8.1.3\n",
      "decorator             5.1.1\n",
      "entrypoints           0.4\n",
      "gitdb                 4.0.10\n",
      "GitPython             3.1.31\n",
      "idna                  3.4\n",
      "importlib-metadata    6.6.0\n",
      "Jinja2                3.1.2\n",
      "jsonschema            4.17.3\n",
      "markdown-it-py        2.2.0\n",
      "MarkupSafe            2.1.2\n",
      "mdurl                 0.1.2\n",
      "numpy                 1.24.3\n",
      "packaging             23.1\n",
      "pandas                2.0.1\n",
      "Pillow                9.5.0\n",
      "pip                   22.3.1\n",
      "protobuf              3.20.3\n",
      "pyarrow               12.0.0\n",
      "pydeck                0.8.1b0\n",
      "Pygments              2.15.1\n",
      "Pympler               1.0.1\n",
      "pyrsistent            0.19.3\n",
      "python-dateutil       2.8.2\n",
      "pytz                  2023.3\n",
      "pytz-deprecation-shim 0.1.0.post0\n",
      "requests              2.30.0\n",
      "rich                  13.3.5\n",
      "setuptools            65.5.0\n",
      "six                   1.16.0\n",
      "smmap                 5.0.0\n",
      "tenacity              8.2.2\n",
      "toml                  0.10.2\n",
      "toolz                 0.12.0\n",
      "tornado               6.3.1\n",
      "typing_extensions     4.5.0\n",
      "tzdata                2023.3\n",
      "tzlocal               4.3\n",
      "urllib3               2.0.2\n",
      "validators            0.20.0\n",
      "zipp                  3.15.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "028d6669",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T20:21:15.208573Z",
     "start_time": "2023-05-15T20:21:15.035805Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scrapy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7s/x40lc7k52vg70w0xtdts0w280000gn/T/ipykernel_12389/1210232472.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scrapy'"
     ]
    }
   ],
   "source": [
    "import scrapy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f250fa75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd1fd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0842e508",
   "metadata": {},
   "source": [
    "## step 1: get_links of a site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5bf198f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T14:59:14.742403Z",
     "start_time": "2023-05-13T14:59:14.550383Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_links(top_url=\"https://www.modular.com/\") :\n",
    "    # Get the HTML of the homepage\n",
    "    response = requests.get(top_url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all of the links on the homepage\n",
    "    links = soup.find_all(\"a\")\n",
    "\n",
    "    # Create a list to store the URLs of all the pages\n",
    "    urls = []\n",
    "    for link in links:\n",
    "        url = link[\"href\"]\n",
    "        if url.startswith(\"/\"):\n",
    "            new_url = (top_url + url)\n",
    "            urls.append(new_url)\n",
    "#        print(new_url)\n",
    "    return(urls)\n",
    "\n",
    "    \n",
    "#get_links(\"https://www.modular.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf8dd58",
   "metadata": {},
   "source": [
    "## step 2: scrape_link; transform_links_to_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15290770",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T17:14:58.997637Z",
     "start_time": "2023-05-13T17:14:58.931785Z"
    }
   },
   "outputs": [],
   "source": [
    "# Python code to scrape a list of links for text and transform it into a text corpus:\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define a function to transform a list of links into a text corpus\n",
    "def transform_links_to_corpus(links):\n",
    "    # Create a list to store the text\n",
    "    corpus = []\n",
    "\n",
    "    # Iterate over the links and scrape each link\n",
    "    for link in links:\n",
    "        text = scrape_link(link)\n",
    "        corpus.extend(text)\n",
    "\n",
    "    # Return the corpus\n",
    "    return corpus\n",
    "\n",
    "# Define a function to scrape a link for text\n",
    "def scrape_link(link):\n",
    "    # Get the HTML of the page\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all of the text on the page\n",
    "    text = soup.find_all(text=True)\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # Return the text\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69e1d00d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T17:17:07.848796Z",
     "start_time": "2023-05-13T17:17:02.483328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modular: AI development starts here\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuWATCH OUR 2023 PRODUCT KEYNOTEThe future of AI development starts hereJoin our DiscordWatch Keynote SummaryPlatformENGINEMOJO🔥The next generation AI developer platform\n",
      "The fastest unified AI inference engine in the world.\n",
      "\n",
      "A new programming language for all AI developers.Get startedLearn more\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ai Frameworks\n",
      "\n",
      "\n",
      "\n",
      "Clouds\n",
      "\n",
      "\n",
      "\n",
      "SOFTMAX.py\n",
      "\n",
      "\n",
      "pythonMojo 🔥\n",
      "\n",
      "\n",
      "def softmax(lst):\n",
      "  norm = np.exp(lst - np.max(lst))\n",
      "  return norm / norm.sum()def softmax(lst):\n",
      "  norm = np.exp(lst - np.max(lst))\n",
      "  return norm / norm.sum()\n",
      "\n",
      "struct NDArray:\n",
      "  def max(self) -> NDArray:\n",
      "    return self.pmap(SIMD.max)\n",
      "\n",
      "struct SIMD[type: DType, width: Int]:\n",
      "  def max(self, rhs: Self) -> Self:\n",
      "    return (self >= rhs).select(self, rhs)Modular engine performance across hardware typesintelMore than2xFaster on FLOAT32AMDMore than3xFaster on FLOAT32GravitonMore than4xFaster on FLOAT32Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "devicesModular engine performance across hardware typesintelMore than2xFaster on FLOAT32AMDMore than3xFaster on FLOAT32GravitonMore than4xFaster on FLOAT32\n",
      "\n",
      "\n",
      "\n",
      "file_name.py\n",
      "\n",
      "\n",
      "pythonMojo 🔥\n",
      "\n",
      "\n",
      "def softmax(lst):\n",
      "  norm = np.exp(lst - np.max(lst))\n",
      "  return norm / norm.sum()def softmax(lst):\n",
      "  norm = np.exp(lst - np.max(lst))\n",
      "  return norm / norm.sum()\n",
      "\n",
      "struct NDArray:\n",
      "  def max(self) -> NDArray:\n",
      "    return self.pmap(SIMD.max)\n",
      "\n",
      "struct SIMD[type: DType, width: Int]:\n",
      "  def max(self, rhs: Self) -> Self:\n",
      "    return (self >= rhs).select(self, rhs)Discover how our revolutionary infrastructure makes AI more usable, scalable, high-performant, and cost-effective.The Modular Engine unifies AI frameworks and hardware and delivers unparalleled performance and cost savings.Mojo combines the usability of Python, with the performance of C, unlocking unparalleled programmability of hardware.Our unified, extensible platform superpowers your AIModular is an integrated, composable suite of tools that simplifies your AI infrastructure so your team can develop, deploy, and innovate faster.\n",
      "\n",
      "\n",
      "\n",
      "Clouds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ai Frameworks\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Devices01Model deploymentThe world’s fastest unified inference engineModular’s inference engine unifies AI industry frameworks and hardware, enabling you to deploy to any cloud or on-prem environment with minimal code changes – unlocking unmatched usability, performance, and portability.Learn moreRead the docsCOMpute portabilityRun your modelsanywhere, reduce costsSeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models. Avoid lock-in and take advantage of cloud price efficiencies and performance improvements without migration costs.Learn more02Programmability & ExtensibilityMojo 🔥 — a new programming language for all AI developersMojo is a programming language that combines the usability of Python with the performance of C, unlocking unparalleled programmability of AI hardware and extensibility of AI models.Learn moreRead the docs\n",
      "\n",
      "\n",
      "\n",
      "SOftmax.🔥def softmax(lst):\n",
      "  norm = np.exp(lst - np.max(lst))\n",
      "  return norm / norm.sum()\n",
      "\n",
      "struct NDArray:\n",
      "  def max(self) -> NDArray:\n",
      "    return self.pmap(SIMD.max)\n",
      "\n",
      "struct SIMD[type: DType, width: Int]:\n",
      "  def max(self, rhs: Self) -> Self:\n",
      "    return (self >= rhs).select(self, rhs)model ScalabilityDeploy the largest models in the world on our stackThe Modular Compute Platform dynamically partitions models with billions of parameters and distributes their execution across multiple machines, enabling unparalleled efficiency, scale, and reliability for the largest workloads.Contact usLLaMA\n",
      "\n",
      "Gopher\n",
      "\n",
      "T5\n",
      "\n",
      "Jurassic\n",
      "\n",
      "WORLD CLASS ENTERPRISE & COMMUNITY SUPPORTGet help from the people who know Modular bestAs a community member, you can chat with the Modular team directly on Discord, and as an enterprise customer, you get direct support from industry experts to keep you running and enable you to scale to your next challenges.Chat with us now\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "General\n",
      "\n",
      "\n",
      "ModularToday at 4:17PMHow can we help you?Deploy on the fastest unified infrastructure on the planetModular unlocks state-of-the-art latency, efficiency, and throughput, helping you productionize larger models and realize massive cost savings on your cloud bill.Queries per Second *125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qps* ModelDLRM RMC1InstanceAWS c6g.4xlarge(Graviton2)Batch Size1Don’t believe us? Put us to the test.Explore our performanceLanguageRun Test\n",
      "\n",
      "Computer VisionRun Test\n",
      "\n",
      "RecommendationRun Test\n",
      "\n",
      "LAUNCHING IN 2023Modular's cloud  compute platformJoin the waiting list01.TRAINING AT SCALENotebooks for training on the largest compute clusters using Python & Mojo 🔥 for highly optimized workloads.02.MANAGED & BYOCUtilize our managed environment, or Bring your own cloud (BYOC), for seamless workload management.03.PERFORMANCE & METRICSDetailed machine performance and metrics data to provide end-to-end insight into your AI workloads.04.DEVELOPER FIRST UI & CLILeverage our easy-to-use web UI or CLI tooling to seamlessly manage your training and deployment workflows.05.SECURITY & ENCRYPTIONEnterprise security & encryption for your data to be secured at rest and in transit on your data stores.Why Modular?Built by the world’s AI experts,Our team has built most of the world’s existing AI infrastructure, including TensorFlow, PyTorch, TPUs, and MLIR, and launched software like Swift and LLVM. Now we’re focused on rebuilding AI infrastructure for the world.Reinvented from the ground upTo unlock the next wave of AI innovation, we need a “first principles” approach to the lowest layers of the AI stack. We can’t pile on more and more layers of complexity on top of already over-complicated existing solutions.Built with generality in mindNatively multi-model, multi-framework, multi-hardware, and multi-cloud — our infrastructure scales from the largest clusters down to the smallest edge devices and in-between.Infrastructure that just works We build technology that meets you where you are at. You shouldn’t have to rewrite your models or application code, grapple with confusing converters, or be a hardware expert to take advantage of state-of-the-art technology.Built for youMove beyond Big Tech’s trickle-down infrastructure. Get direct access to industry experts that will help solve any issue you have with our infrastructure and make sure we’re meeting your SLA/SLOs.Ready to get started?Sign up to gain early access to Modular’s infrastructure.Request accessAPI References, Tutorials, & MoreRead the docs\n",
      "\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Inference Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuThe world's fastest unified AI inference engine. Get  models into production, faster.The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions. Bring your model as-is and deploy it anywhere, across server and edge, with unparalleled usability and performance.Get startedSee our performanceengine P99 Latency: 12.1 ms *P50P90P95P99TensorFlowPyTorchModular Engine* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size101UnificationTrain in any framework, deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude.Cloud & On-PremFrameworksmodular EngineServer & edgeFramework optionalityEasily deploy models trained in any framework, such as TensorFlow or PyTorch, without retraining, conversions or pre-optimization steps, using a unified set of APIs. There are no tricks, no hacks - the Engine just works incredibly fast.Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models. Avoid lock-in and take advantage of price efficiencies and performance improvements without migration costs.02PerformanceMaximize performance, minimize costsReduce latency, increase throughput, and improve resource efficiency across CPUs, GPUs, and accelerators. Productionize larger models and significantly reduce your computing costs.Explore our performance dashboardQueries per Second *125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences *$ 0.12TensorFlow$0.89PyTorch$0.54Modular Engine$0.12* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size1MODULAR ENGINE SPEED-UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family  vs  vs  vs  vs  vs  vsLanguage Model3x3.2x5.3x1.4x2.1x4xRecommender Models6.5x5x7.5x1.1x1.2x4.3xVision Models2.1x2.2x1.7x1.5x1.5x1.3xCompute TypeIntel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)Intel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)ResultsAWS Compute Instances. TensorFlow & PyTorch listed by logo. Full performance & methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again. Run any model, including support for all native framework operators, dynamic shapes, low-precision, and your existing custom operators.DLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseBERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases. Our tools are... well... modular. They integrate with industry-standard infrastructure and open-source tools to minimize migration cost.Request accessseamless integration with popular libraries and tools01.Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular's off-the-shelf NVIDIA Triton and TensorFlow-Serving builds.02.Choose your cloudDeploy the engine on-prem, in your own VPC on any major cloud provider, or get up and running quicker with out hosted solutions.03.METRICS & MONITORINGThe Modular Inference Engine works with industry-standard open-source tooling like Prometheus and Grafana.Ready to try a preview?Contact us to get early-access to the Modular Inference Engine.Request accessAPI References, Tutorials, & MoreRead the Modular Inference Engine docs\n",
      "\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Inference Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuThe world's fastest unified AI inference engine. Get  models into production, faster.The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions. Bring your model as-is and deploy it anywhere, across server and edge, with unparalleled usability and performance.Get startedSee our performanceengine P99 Latency: 12.1 ms *P50P90P95P99TensorFlowPyTorchModular Engine* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size101UnificationTrain in any framework, deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude.Cloud & On-PremFrameworksmodular EngineServer & edgeFramework optionalityEasily deploy models trained in any framework, such as TensorFlow or PyTorch, without retraining, conversions or pre-optimization steps, using a unified set of APIs. There are no tricks, no hacks - the Engine just works incredibly fast.Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models. Avoid lock-in and take advantage of price efficiencies and performance improvements without migration costs.02PerformanceMaximize performance, minimize costsReduce latency, increase throughput, and improve resource efficiency across CPUs, GPUs, and accelerators. Productionize larger models and significantly reduce your computing costs.Explore our performance dashboardQueries per Second *125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences *$ 0.12TensorFlow$0.89PyTorch$0.54Modular Engine$0.12* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size1MODULAR ENGINE SPEED-UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family  vs  vs  vs  vs  vs  vsLanguage Model3x3.2x5.3x1.4x2.1x4xRecommender Models6.5x5x7.5x1.1x1.2x4.3xVision Models2.1x2.2x1.7x1.5x1.5x1.3xCompute TypeIntel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)Intel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)ResultsAWS Compute Instances. TensorFlow & PyTorch listed by logo. Full performance & methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again. Run any model, including support for all native framework operators, dynamic shapes, low-precision, and your existing custom operators.DLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseBERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases. Our tools are... well... modular. They integrate with industry-standard infrastructure and open-source tools to minimize migration cost.Request accessseamless integration with popular libraries and tools01.Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular's off-the-shelf NVIDIA Triton and TensorFlow-Serving builds.02.Choose your cloudDeploy the engine on-prem, in your own VPC on any major cloud provider, or get up and running quicker with out hosted solutions.03.METRICS & MONITORINGThe Modular Inference Engine works with industry-standard open-source tooling like Prometheus and Grafana.Ready to try a preview?Contact us to get early-access to the Modular Inference Engine.Request accessAPI References, Tutorials, & MoreRead the Modular Inference Engine docs\n",
      "\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Mojo 🔥: Programming language for all of AI\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuMojo 🔥 — a new programming language for all AI developers.Mojo combines the usability of Python with the performance of C, unlocking unparalleled programmability of AI hardware and extensibility of AI models.Get started with MojoRead the docs\n",
      "\n",
      "\n",
      "\n",
      "SOFTMAX.PYMojo 🔥\n",
      "\n",
      "\n",
      "pythondef softmax(lst):\n",
      "  norm = np.exp(lst - np.max(lst))\n",
      "  return norm / norm.sum()def softmax(lst):\n",
      "  norm = np.exp(lst - np.max(lst))\n",
      "  return norm / norm.sum()\n",
      "\n",
      "struct NDArray:\n",
      "  def max(self) -> NDArray:\n",
      "    return self.pmap(SIMD.max)\n",
      "\n",
      "struct SIMD[type: DType, width: Int]:\n",
      "  def max(self, rhs: Self) -> Self:\n",
      "    return (self >= rhs).select(self, rhs)01Usability & ProgrammabilityWrite everything in one languageWrite Python or scale all the way down to the metal. Program the multitude of low-level AI hardware. No C++ or CUDA required.Take a tour of Mojo\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def sort(v: ArraySlice[Int]):\n",
      "  for i in range(len(v)):\n",
      "    for j in range(len(v) - i - 1):\n",
      "      if v[j] > v[j + 1]:\n",
      "        swap(v[j], v[j + 1])FILE_NAME.🔥\n",
      "struct MyPair:\n",
      "  var first: Int\n",
      "  var second: F32\n",
      "  \n",
      "  def __init__(self, first: Int, second: F32):\n",
      "    self.first = first\n",
      "    self.second = secondFILE_NAME.🔥\n",
      "def reorder_and_process(owned x: HugeArray):\n",
      "  sort(x)\t# Update in place\n",
      "  \n",
      "  give_away(x^)\t# Transfer ownership\n",
      "  \n",
      "  print(x[0])\t# Error: ‘x’ moved away!FILE_NAME.🔥\n",
      "def exp[dt: DType, elts: Int]\n",
      "    (x: SIMD[dt, elts]) -> SIMD[dt, elts]:\n",
      "  x = clamp(x, -88.3762626647, 88.37626266)\n",
      "  k = floor(x * INV_LN2 + 0.5)\n",
      "  r = k * NEG_LN2 + x\n",
      "  return ldexp(_exp_taylor(r), k)FILE_NAME.🔥\n",
      "def exp_buffer[dt: DType](data: ArraySlice[dt]):\n",
      "\n",
      "  # Search for the best vector length\n",
      "  alias vector_len = autotune(1, 4, 8, 16, 32)\n",
      "  \n",
      "  # Use it as the vectorization length\n",
      "  vectorize[exp[dt, vector_len]](data)Features include:Progressive TypesLeverage types for better performance and error checking.Zero Cost AbstractionsTake control of storage by inline-allocating values into structures.Ownership + borrow checkerTake advantage of memory safety without the rough edges.Portable parametric algorithmsLeverage compile-time meta-programming to write hardware-agnostic algorithms and reduce boilerplate.LANGUAGE INTEGRATED Auto-tuningAutomatically find the best values for your parameters to take advantage of target hardware.As well as:The full power of MLIRParallel heterogenous runtimeFast compile times\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def sort(v: ArraySlice[Int]):\n",
      "  for i in range(len(v)):\n",
      "    for j in range(len(v) - i - 1):\n",
      "      if v[j] > v[j + 1]:\n",
      "        swap(v[j], v[j + 1])Features include:Progressive TypesLeverage types for better performance and error checking.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "struct MyPair:\n",
      "  var first: Int\n",
      "  var second: F32\n",
      "  \n",
      "  def __init__(self, first: Int, second: F32):\n",
      "    self.first = first\n",
      "    self.second = secondFeatures include:Zero Cost AbstractionsTake control of storage by inline-allocating values into structures.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def reorder_and_process(owned x: HugeArray):\n",
      "  sort(x)\t# Update in place\n",
      "  \n",
      "  give_away(x^)\t# Transfer ownership\n",
      "  \n",
      "  print(x[0])\t# Error: ‘x’ moved away!Features include:Ownership + borrow checkerTake advantage of memory safety without the rough edges.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def exp[dt: DType, elts: Int]\n",
      "    (x: SIMD[dt, elts]) -> SIMD[dt, elts]:\n",
      "  x = clamp(x, -88.3762626647, 88.37626266)\n",
      "  k = floor(x * INV_LN2 + 0.5)\n",
      "  r = k * NEG_LN2 + x\n",
      "  return ldexp(_exp_taylor(r), k)Features include:Portable parametric algorithmsLeverage compile-time meta-programming to write hardware-agnostic algorithms and reduce boilerplate.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def exp_buffer[dt: DType](data: ArraySlice[dt]):\n",
      "\n",
      "  # Search for the best vector length\n",
      "  alias vector_len = autotune(1, 4, 8, 16, 32)\n",
      "  \n",
      "  # Use it as the vectorization length\n",
      "  vectorize[exp[dt, vector_len]](data)Features include:LANGUAGE INTEGRATED Auto-tuningAutomatically find the best values for your parameters to take advantage of target hardware.02PerformanceUnlock Python performanceUtilize the full power of the hardware, including multiple cores, vector units, and exotic accelerator units, with the world's most advanced compiler and heterogenous runtime. Achieve performance on par with C++ and CUDA without the complexity.Play with MojoParallelizationMojo leverages MLIR, which enables Mojo developers to take advantage of vectors, threads, and AI hardware units.PYTHONSingle-threaded executionMojo 🔥Parallel processing across multiple coresLanguagesTime (S) *Speedup vs PythonPython 3.10.91027 s1xPypy46.1 s22xScalar C++0.20 s5000xMojo 🔥0.03 s35000x* AlgorithmMandelbrotInstanceAWS r7iz.metal-16xlIntel Xeon03InteroperabilityAccess the entire Python ecosystemExperience true interoperability with the Python ecosystem. Seamlessly intermix arbitrary libraries like Numpy and Matplotlib and your custom code with Mojo.Read the programming manual\n",
      "\n",
      "\n",
      "\n",
      "MAKE_PLOT.🔥def make_plot(m: Matrix):\n",
      "  plt = Python.import_module(\"matplotlib.pyplot\")\n",
      "  fig = plt.figure(1, [10, 10 * yn // xn], 64)\n",
      "  ax = fig.add_axes([0.0, 0.0, 1.0, 1.0], False, 1)\n",
      "  plt.imshow(image)\n",
      "  plt.show()\n",
      "\n",
      "make_plot(compute_mandelbrot())Mojo 🔥04ExtensibilityUpgrade your models and the Modular stackEasily extend your models with pre and post-processing operations, or replace operations with custom ones. Take advantage of kernel fusion, graph rewrites, shape functions, and more.Model extensibilityMojo can upgrade the existing operations in your model.Input layerHidden layersOutput layer05GET STARTED NOWTry Mojo 🔥 out right now in our PlaygroundMojo is still a work in progress, but it's available to try today in our JupyterHub-based Playground. Run through tutorials and write your own Mojo code.Sign up for accessMojo 🔥01.EASY TO GET STARTEDWe have plenty of easy-to-use Jupyter notebooks to help you get started learning Mojo 🔥.02.Unleash your mojoOur docs will help you quickly discover why Mojo is such a powerful extension to Python, and the future of AI programming.03.JOIN the mojo COMMUNITYCome and chat with us on our Discord, and help shape the future of the language as we continue to develop it.Ready to play with Mojo?Reach out to gain access to the Mojo Playground.Request accessAPI Reference, Tutorials, & MoreRead the Mojo docs\n",
      "\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Mojo 🔥: Programming language for all of AI\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuMojo 🔥 — a new programming language for all AI developers.Mojo combines the usability of Python with the performance of C, unlocking unparalleled programmability of AI hardware and extensibility of AI models.Get started with MojoRead the docs\n",
      "\n",
      "\n",
      "\n",
      "SOFTMAX.PYMojo 🔥\n",
      "\n",
      "\n",
      "pythondef softmax(lst):\n",
      "  norm = np.exp(lst - np.max(lst))\n",
      "  return norm / norm.sum()def softmax(lst):\n",
      "  norm = np.exp(lst - np.max(lst))\n",
      "  return norm / norm.sum()\n",
      "\n",
      "struct NDArray:\n",
      "  def max(self) -> NDArray:\n",
      "    return self.pmap(SIMD.max)\n",
      "\n",
      "struct SIMD[type: DType, width: Int]:\n",
      "  def max(self, rhs: Self) -> Self:\n",
      "    return (self >= rhs).select(self, rhs)01Usability & ProgrammabilityWrite everything in one languageWrite Python or scale all the way down to the metal. Program the multitude of low-level AI hardware. No C++ or CUDA required.Take a tour of Mojo\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def sort(v: ArraySlice[Int]):\n",
      "  for i in range(len(v)):\n",
      "    for j in range(len(v) - i - 1):\n",
      "      if v[j] > v[j + 1]:\n",
      "        swap(v[j], v[j + 1])FILE_NAME.🔥\n",
      "struct MyPair:\n",
      "  var first: Int\n",
      "  var second: F32\n",
      "  \n",
      "  def __init__(self, first: Int, second: F32):\n",
      "    self.first = first\n",
      "    self.second = secondFILE_NAME.🔥\n",
      "def reorder_and_process(owned x: HugeArray):\n",
      "  sort(x)\t# Update in place\n",
      "  \n",
      "  give_away(x^)\t# Transfer ownership\n",
      "  \n",
      "  print(x[0])\t# Error: ‘x’ moved away!FILE_NAME.🔥\n",
      "def exp[dt: DType, elts: Int]\n",
      "    (x: SIMD[dt, elts]) -> SIMD[dt, elts]:\n",
      "  x = clamp(x, -88.3762626647, 88.37626266)\n",
      "  k = floor(x * INV_LN2 + 0.5)\n",
      "  r = k * NEG_LN2 + x\n",
      "  return ldexp(_exp_taylor(r), k)FILE_NAME.🔥\n",
      "def exp_buffer[dt: DType](data: ArraySlice[dt]):\n",
      "\n",
      "  # Search for the best vector length\n",
      "  alias vector_len = autotune(1, 4, 8, 16, 32)\n",
      "  \n",
      "  # Use it as the vectorization length\n",
      "  vectorize[exp[dt, vector_len]](data)Features include:Progressive TypesLeverage types for better performance and error checking.Zero Cost AbstractionsTake control of storage by inline-allocating values into structures.Ownership + borrow checkerTake advantage of memory safety without the rough edges.Portable parametric algorithmsLeverage compile-time meta-programming to write hardware-agnostic algorithms and reduce boilerplate.LANGUAGE INTEGRATED Auto-tuningAutomatically find the best values for your parameters to take advantage of target hardware.As well as:The full power of MLIRParallel heterogenous runtimeFast compile times\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def sort(v: ArraySlice[Int]):\n",
      "  for i in range(len(v)):\n",
      "    for j in range(len(v) - i - 1):\n",
      "      if v[j] > v[j + 1]:\n",
      "        swap(v[j], v[j + 1])Features include:Progressive TypesLeverage types for better performance and error checking.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "struct MyPair:\n",
      "  var first: Int\n",
      "  var second: F32\n",
      "  \n",
      "  def __init__(self, first: Int, second: F32):\n",
      "    self.first = first\n",
      "    self.second = secondFeatures include:Zero Cost AbstractionsTake control of storage by inline-allocating values into structures.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def reorder_and_process(owned x: HugeArray):\n",
      "  sort(x)\t# Update in place\n",
      "  \n",
      "  give_away(x^)\t# Transfer ownership\n",
      "  \n",
      "  print(x[0])\t# Error: ‘x’ moved away!Features include:Ownership + borrow checkerTake advantage of memory safety without the rough edges.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def exp[dt: DType, elts: Int]\n",
      "    (x: SIMD[dt, elts]) -> SIMD[dt, elts]:\n",
      "  x = clamp(x, -88.3762626647, 88.37626266)\n",
      "  k = floor(x * INV_LN2 + 0.5)\n",
      "  r = k * NEG_LN2 + x\n",
      "  return ldexp(_exp_taylor(r), k)Features include:Portable parametric algorithmsLeverage compile-time meta-programming to write hardware-agnostic algorithms and reduce boilerplate.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def exp_buffer[dt: DType](data: ArraySlice[dt]):\n",
      "\n",
      "  # Search for the best vector length\n",
      "  alias vector_len = autotune(1, 4, 8, 16, 32)\n",
      "  \n",
      "  # Use it as the vectorization length\n",
      "  vectorize[exp[dt, vector_len]](data)Features include:LANGUAGE INTEGRATED Auto-tuningAutomatically find the best values for your parameters to take advantage of target hardware.02PerformanceUnlock Python performanceUtilize the full power of the hardware, including multiple cores, vector units, and exotic accelerator units, with the world's most advanced compiler and heterogenous runtime. Achieve performance on par with C++ and CUDA without the complexity.Play with MojoParallelizationMojo leverages MLIR, which enables Mojo developers to take advantage of vectors, threads, and AI hardware units.PYTHONSingle-threaded executionMojo 🔥Parallel processing across multiple coresLanguagesTime (S) *Speedup vs PythonPython 3.10.91027 s1xPypy46.1 s22xScalar C++0.20 s5000xMojo 🔥0.03 s35000x* AlgorithmMandelbrotInstanceAWS r7iz.metal-16xlIntel Xeon03InteroperabilityAccess the entire Python ecosystemExperience true interoperability with the Python ecosystem. Seamlessly intermix arbitrary libraries like Numpy and Matplotlib and your custom code with Mojo.Read the programming manual\n",
      "\n",
      "\n",
      "\n",
      "MAKE_PLOT.🔥def make_plot(m: Matrix):\n",
      "  plt = Python.import_module(\"matplotlib.pyplot\")\n",
      "  fig = plt.figure(1, [10, 10 * yn // xn], 64)\n",
      "  ax = fig.add_axes([0.0, 0.0, 1.0, 1.0], False, 1)\n",
      "  plt.imshow(image)\n",
      "  plt.show()\n",
      "\n",
      "make_plot(compute_mandelbrot())Mojo 🔥04ExtensibilityUpgrade your models and the Modular stackEasily extend your models with pre and post-processing operations, or replace operations with custom ones. Take advantage of kernel fusion, graph rewrites, shape functions, and more.Model extensibilityMojo can upgrade the existing operations in your model.Input layerHidden layersOutput layer05GET STARTED NOWTry Mojo 🔥 out right now in our PlaygroundMojo is still a work in progress, but it's available to try today in our JupyterHub-based Playground. Run through tutorials and write your own Mojo code.Sign up for accessMojo 🔥01.EASY TO GET STARTEDWe have plenty of easy-to-use Jupyter notebooks to help you get started learning Mojo 🔥.02.Unleash your mojoOur docs will help you quickly discover why Mojo is such a powerful extension to Python, and the future of AI programming.03.JOIN the mojo COMMUNITYCome and chat with us on our Discord, and help shape the future of the language as we continue to develop it.Ready to play with Mojo?Reach out to gain access to the Mojo Playground.Request accessAPI Reference, Tutorials, & MoreRead the Mojo docs\n",
      "\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Hardware Developers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuUnlock your hardware design with software that provides generality and usability for AI developers.Modular's software stack will take care of all upstream integrations with AI frameworks, graph optimizations, and more, so you can focus on the differentiating features of your hardware. Own your code generation, performance and feature set. It's still early, but we're excited about the future.Contact us nowLearn how it works01BenefitsIntegrating with the Modular stack gets you:01.Access to all AI frameworksEffortlessly extend your customer reach to all popular AI frameworks.02.Better performanceAutofusion and graph optimizations boost your hardware performance.03.Full compatibilityWe support the ever-changing AI ecosystem, including the long-tail of operators and models.04.Market DifferentiationYou own your performance and can utilize the full capabilities of your hardware.05.Faster time to marketYour hardware “just works” often with only a few weeks of development.02How it worksIntegration is simple\n",
      "\n",
      "\n",
      "FrameworksModular handles integration & packagingend-user tools\n",
      "\n",
      "\n",
      "Modular engineModular handles offload, kernel fusion, compilation,, caching, & developer tools\n",
      "\n",
      "\n",
      "Your Compiler + KernelsYou provide LLVM or MLIR code generation, and extend the stack with Mojo 🔥 kernelsyour HardwareYou design the hardware and have in-house expertise03Modern AI EngineModular handles framework support and end-user toolingModular handles the ever-changing world of AI frameworks, models, and operators, providing you with a single cross-framework integration point for your hardware stack.Full framework, model, and op supportIntegration with TensorFlow, PyTorch, plus variants like ONNX and TorchScriptFull generality of models, including dynamic shapes, sparsity, custom ops, etc.Thousands of long-tail operators needed for compatibilityCompiler transformations and developer toolingKernel fusion and other performance optimizationsAutomatic graph partitioning for distributed inferenceStandardized and hackable tools04IntegrationPlug your hardware in at the graph or code generation levelBring your own code gen backend for CPU, GPU, or DSPs, and everything just works. For CGRA, FPGA, or other exotic hardware, start with our standardized operator set and extend the system to your needs.Focus your effort on ML operators you care aboutModular provides a library of customizable kernels and microkernels written in Mojo 🔥Focus on the subset of the problem for your hardwareEverything else just works — we provide fallback legacy long-tail kernels for compatibilityExtend the systemas neededAdd new Mojo 🔥 kernels if you don’t find what you’re looking for, and enable your customers to the sameUse Mojo 🔥 to directly inject MLIR, C/C++ or assembly code as neededLeverage standardized operators and tools to write high-level graph transformationsInterested in partnering with us?Contact us to discuss how we can work together.Contact UsAPI Reference, Guides, & MoreLearn more about our platform\n",
      "\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Blog\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuCompanyOur launch & what's nextMay 11, 2023Tim DavisCo-Founder & Chief Product OfficerTim DavisCo-Founder & Chief Product OfficerRead postFeatured postsProductA unified, extensible platform to superpower your AIMay 2, 2023\n",
      "Read postEngineeringThe world's fastest unified matrix multiplicationApril 20, 2023\n",
      "Read postBrowse all postsCompanyOur launch & what's nextMay 11, 2023|\n",
      "ProductA unified, extensible platform to superpower your AIMay 2, 2023|\n",
      "EngineeringThe world's fastest unified matrix multiplicationApril 20, 2023|\n",
      "EngineeringAI’s compute fragmentation: what matrix multiplication teaches usMarch 23, 2023|\n",
      "CompanyWe want to hear from youDecember 15, 2022|\n",
      "EngineeringIf AI serving tech can’t solve today’s problems, how do we scale into the future?December 8, 2022|\n",
      "EngineeringPart 2: Increasing development velocity of giant AI modelsNovember 10, 2022|\n",
      "CompanyModular is rebuilding AI in the face of a new economyNovember 8, 2022|\n",
      "DesignModular's Brand StoryAugust 18, 2022|\n",
      "EngineeringIncreasing development velocity of giant AI modelsAugust 12, 2022|\n",
      "CompanyThe Case for a Next-Generation AI Developer PlatformJune 30, 2022|\n",
      "CultureHow we workMay 21, 2022|\n",
      "CompanyThe future of AI depends on ModularityApril 26, 2022|\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Careers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuPlayJoin us in building the future of AISee open rolesRead about our cultureWe want to enable AI to be used by anyone, anywhere. Our ambitions are enormous, but working here will feel very familiar. You can change the world without giving up your lifeWhy Modular?Grow with the bestBuild with some of the industry's best AI leaders.Maximize how you workWe will always push the limits to create the best possible environment for our people and teams. Read how we work.Build AI for the worldBuild a next-generation developer platform, with production quality infrastructure, for the world.Have fun, live lifeRegular team onsites, local meetups & fun, strong team collaboration and more.Work & life, balanced1Leading medical, dental and vision packages2Strong compensation & equity packages3Generous maternity & paternity leave4401K Plan5Work wherever you want6Unlimited Vacation & PTO7Corporate perks & epic team fun8Great set upWorking at ModularWe believe in a thoughtful framework to family, compensation, growth, and mission - each of these elements is critical to anyone living a balanced and fulfilling life. We want to ensure that you have a place to achieve the right mix.We’re trusting & empoweringWe trust that you will hold our values and standards. This means we don't micromanage you.We write things downThis is key to being asynchronous. It allows real-time discussions to be more thoughtful and contextually driven.We have levelsWe acknowledge levels of experience upfront and have a transparent and well-defined leveling system.Learn about usI am truly impressed with the collective experience of the Modular team in building some of the industry’s most widely used AI systems and tools. And humbled and excited to be part of this team in our journey to build the next generation AI platform and infrastructure for the world.Amit AgarwalCloud Infrastructure LeadI picked modular because of the people and what they believe in and what they want to do. I want to be a part of something that makes a difference for the better.Paige BedwellProgram ManagerI joined because there is literally no better team on the planet to rebuild AI. It's a once in a lifetime opportunity.\n",
      "I'm building for the world, and working with the best.River RiddleAI Compiler EngineerWe are a set of world class engineers and leaders who really deeply understand this problem, and have solved it to varying degrees of success before. Now we are committed to solving it the right way.Aman LaChapelleAI Compiler EngineerThe team is incredible. They're very smart. They're experts in their field, and we're solving the hardest computational problems in the world.Abdul DakkakAI Compiler EngineerThe best part of working here is a strong commitment to culture. I work on the most challenging problems, have the freedom to do it anywhere, and have a huge impact on AI.Eric JohnsonProduct LeadJoin our teamCome and be part of a world-class team that is rebuilding AI for everyone. We welcome applications from all backgrounds and communities.\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuWe are world leaders in AI infrastructure. We contributed to so much of it, now we are reinventing it.We believe that AI is a net positive force in the world and will help transform it for the better. Our vision and mission are to reinvent AI infrastructure to advance humanity and our surroundingsRead our visionHow it startedChris Lattner and Tim Davis met at Google and felt AI was being held back by overly complex and fragmented infrastructure. Motivated by a desire to accelerate the impact of AI on the world by lifting the industry towards production-quality AI software, they founded Modular.Together with a team of the world's best AI infrastructure leaders - a mix of engineers, product managers, designers, and operational and infrastructure talent from the leading AI companies, we are reinventing and rebuilding AI for everyone.Our leadership teamChris LattnerCo-Founder & CEOTim DavisCo-Founder & Chief Product OfficerAmit AgarwalCloud Infrastructure LeadEric JohnsonProduct LeadMike EdwardsOperations LeadNick KreegerFramework Engineering LeadTatiana ShpeismanCompiler Engineering LeadMeet more of the teamBacked by the best investors in AIOur culture and values1Build it rightCustomers firstWe build technology to lift the world by solving our customers’ problems. We are clear that our customers always come first, and we always deliver on our promises.Build it rightWe build high-quality production software that displays technical mastery inside and out. We make our infrastructure the right way as we understand compounding technical debt.Drive resultsWhen our customers and their people succeed, our company succeeds. No matter their role, every employee contributes to our collective success. We all win when we drive results that actually matter.2Empower peopleOwnershipWe act on behalf of the entire organization and not just for ourselves and our local team. We operate on the assumption that each person is highly motivated and will drive their work with a bias towards action.TransparencyWe are transparent by having decisions, calendars, directions, and plans open to everyone in the company. Anyone can constructively ask tough questions and feel safe to have answers provided directly.Hire the best, never stop learningWe hire great people who seek to constantly grow themselves and others around them. Great people develop great people; they take coaching others seriously and look to raise the standards.Have fun, live lifeWe believe people do their best work when they are happy.3Be an incredible teamWin together, fail togetherChanging the world is a team sport. Individual wins, or mistakes, matter less than everyone winning, failing, learning, and growing together.Own inclusion, be diverseWe build for everyone, and we are open to everyone. We believe that the best results come from a team that reflects the world at large.Everyone has a voiceWe expect the best concept, design, plan, or direction to succeed regardless of someone’s “rank” in the company.Assume positive intentWe expect everyone to assume the best of others. We’re all human and often jump to conclusions; we want people to assume good intentions when we do.1Build products users love2Empower people3Be an incredible teamRead about our cultureCome reinvent AI with us\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuWe are world leaders in AI infrastructure. We contributed to so much of it, now we are reinventing it.We believe that AI is a net positive force in the world and will help transform it for the better. Our vision and mission are to reinvent AI infrastructure to advance humanity and our surroundingsRead our visionHow it startedChris Lattner and Tim Davis met at Google and felt AI was being held back by overly complex and fragmented infrastructure. Motivated by a desire to accelerate the impact of AI on the world by lifting the industry towards production-quality AI software, they founded Modular.Together with a team of the world's best AI infrastructure leaders - a mix of engineers, product managers, designers, and operational and infrastructure talent from the leading AI companies, we are reinventing and rebuilding AI for everyone.Our leadership teamChris LattnerCo-Founder & CEOTim DavisCo-Founder & Chief Product OfficerAmit AgarwalCloud Infrastructure LeadEric JohnsonProduct LeadMike EdwardsOperations LeadNick KreegerFramework Engineering LeadTatiana ShpeismanCompiler Engineering LeadMeet more of the teamBacked by the best investors in AIOur culture and values1Build it rightCustomers firstWe build technology to lift the world by solving our customers’ problems. We are clear that our customers always come first, and we always deliver on our promises.Build it rightWe build high-quality production software that displays technical mastery inside and out. We make our infrastructure the right way as we understand compounding technical debt.Drive resultsWhen our customers and their people succeed, our company succeeds. No matter their role, every employee contributes to our collective success. We all win when we drive results that actually matter.2Empower peopleOwnershipWe act on behalf of the entire organization and not just for ourselves and our local team. We operate on the assumption that each person is highly motivated and will drive their work with a bias towards action.TransparencyWe are transparent by having decisions, calendars, directions, and plans open to everyone in the company. Anyone can constructively ask tough questions and feel safe to have answers provided directly.Hire the best, never stop learningWe hire great people who seek to constantly grow themselves and others around them. Great people develop great people; they take coaching others seriously and look to raise the standards.Have fun, live lifeWe believe people do their best work when they are happy.3Be an incredible teamWin together, fail togetherChanging the world is a team sport. Individual wins, or mistakes, matter less than everyone winning, failing, learning, and growing together.Own inclusion, be diverseWe build for everyone, and we are open to everyone. We believe that the best results come from a team that reflects the world at large.Everyone has a voiceWe expect the best concept, design, plan, or direction to succeed regardless of someone’s “rank” in the company.Assume positive intentWe expect everyone to assume the best of others. We’re all human and often jump to conclusions; we want people to assume good intentions when we do.1Build products users love2Empower people3Be an incredible teamRead about our cultureCome reinvent AI with us\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Vision\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuEnable AI to be used by anyone, anywhereOur mission is to have real, positive impact in the world by reinventing the way AI technology is developed and deployed into production with a next-generation developer platformAI can change the world, but not until the core infrastructure upon which it is built is fixed and industry fragmentation healed. The opportunity cost is not measured in dollars alone. AI can truly save lives. It can improve dialogue within societies. It can better humanity, the environment, and our futures. We have no time to wait.Why we created ModularAfter working for years at the world’s largest technology companies, scaling the world's largest AI work loads, building the hardware that powers them, and deploying AI to billions of mobile phones and edge devices, we saw that fragmentation and technical complexity held back the impact to a privileged few. The rest of the world isn’t benefiting as it should be from this transformational technology.We aim to push the whole world of AI forward, not just a select few companies and products. To do that, we need to rethink the current AI systems and infrastructure from first principles to make it easy for anyone to leverage AI to solve the world’s most critical problems with software that just works. Modular and composable infrastructure that simplifies AI development and deployment is what the world needs.Learn About usOur goal is as enormous as it is profound. The only way to succeed is to build a different kind of company to achieve this.We have assembled the best AI software and hardware leaders, and are systematically rebuilding the AI software stack from the ground up.The software that powers AI was created by researchers for research. But that time is now over - AI is no longer a research projectThe next-generation ML system needs to be production-quality and meet developers where they are. AI shouldn’t be something you need to shape your application around. This is the only way to reduce fragmentation and unlock the next generation of hardware, data, and algorithmic innovations.It is time to incorporate the lessons learned into a single modular and composable system that integrates the best-known technologies from across the industry. It must be natively multi-framework, multi-cloud, and multi-hardware. It needs to combine the best performance with the best usability.Blog PostsCompanyMay 11, 2023Our launch & what's nextTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerProductMay 2, 2023A unified, extensible platform to superpower your AIChris Lattner,Co-Founder & CEOChris Lattner,Co-Founder & CEOTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerEric Johnson,Product LeadEric Johnson,Product LeadRosane Vallim,Product ManagerRosane Vallim,Product ManagerEngineeringApril 20, 2023The world's fastest unified matrix multiplicationAbdul Dakkak,AI Compiler EngineerAbdul Dakkak,AI Compiler EngineerChad Jarvis,AI Performance EngineerChad Jarvis,AI Performance EngineerEric Johnson,Product LeadEric Johnson,Product LeadHengjie Wang,AI Performance EngineerHengjie Wang,AI Performance EngineerIan Tramble,AI Performance EngineerIan Tramble,AI Performance EngineerEngineeringMarch 23, 2023AI’s compute fragmentation: what matrix multiplication teaches usEric Johnson,Product LeadEric Johnson,Product LeadAbdul Dakkak,AI Compiler EngineerAbdul Dakkak,AI Compiler EngineerChad Jarvis,AI Performance EngineerChad Jarvis,AI Performance EngineerCompanyDecember 15, 2022We want to hear from youRosane Vallim,Product ManagerRosane Vallim,Product ManagerCompanyApril 26, 2022The future of AI depends on ModularityChris Lattner,Co-Founder & CEOChris Lattner,Co-Founder & CEOTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerCompanyJune 30, 2022The Case for a Next-Generation AI Developer PlatformChris Lattner,Co-Founder & CEOChris Lattner,Co-Founder & CEOTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerEric Johnson,Product LeadEric Johnson,Product LeadEngineeringAugust 12, 2022Increasing development velocity of giant AI modelsRiver Riddle,AI Compiler EngineerRiver Riddle,AI Compiler EngineerEric Johnson,Product LeadEric Johnson,Product LeadEngineeringDecember 8, 2022If AI serving tech can’t solve today’s problems, how do we scale into the future?Amit Agarwal,Cloud Infrastructure LeadAmit Agarwal,Cloud Infrastructure LeadEric Johnson,Product LeadEric Johnson,Product LeadCultureMay 21, 2022How we workChris Lattner,Co-Founder & CEOChris Lattner,Co-Founder & CEOTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerCompanyNovember 8, 2022Modular is rebuilding AI in the face of a new economyChris Lattner,Co-Founder & CEOChris Lattner,Co-Founder & CEOTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerEngineeringNovember 10, 2022Part 2: Increasing development velocity of giant AI modelsAbdul Dakkak,AI Compiler EngineerAbdul Dakkak,AI Compiler EngineerEric Johnson,Product LeadEric Johnson,Product LeadRiver Riddle,AI Compiler EngineerRiver Riddle,AI Compiler EngineerDesignAugust 18, 2022Modular's Brand StoryTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerEric Johnson,Product LeadEric Johnson,Product LeadMatt Ellis,MetaLab Brand DirectorMatt Ellis,MetaLab Brand DirectorLearn more about us\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuMeet the team building thefuture of AI for the worldOur team brings experience from the largest and most sophisticated technology companies in the worldWe have built and contributed to foundational AI technologies like TensorFlow, PyTorch, TF Lite, XLA, TPUs, ONNXRuntime, Android, Apple Neural Engine, MLIR, LLVM, Clang, Swift and more. We are world-leading experts in compilers, runtimes, distributed computation, and hardware, and have deployed production workloads to billions of users and devices.Team membersChris LattnerCo-Founder & CEOChris LattnerCo-Founder & CEODistinguished Leader who founded and scaled critical infrastructure including LLVM, Clang, MLIR, Cloud TPUs and the Swift programming language. Chris built AI and core systems at multiple world leading technology companies including Apple, Google, SiFive and Tesla.clattner@modular.comRecent posts\n",
      "CloseTim DavisCo-Founder & Chief Product OfficerTim DavisCo-Founder & Chief Product OfficerRepeat Entrepreneur and Product Leader. Tim helped build, found and scale large parts of Google's AI infrastructure at Google Brain and Core Systems from APIs (TensorFlow), Compilers (XLA & MLIR) and runtimes for server (CPU/GPU/TPU) and TF Lite (Mobile/Micro/Web), Android ML & NNAPI, large model infrastructure & OSS for billions of users and devices. Loves running, building products to help people, and the world.tim@modular.comRecent posts\n",
      "CloseAmit AgarwalCloud Infrastructure LeadAmit AgarwalCloud Infrastructure LeadEngineering leader with 15+ years of experience building, shipping, and operating AI/ML, HPC, distributed computing frameworks, and cloud platforms, at the scale of millions of users and thousands of enterprises. Grew teams and scaled the design and implementation of deep learning frameworks, personalized speech recognition, and conversational AI services at Microsoft. Amit also scaled and optimized speech and computer vision runtimes, including GPU acceleration and ASICs. Amit enjoys hiking, playing billiards, and exploring the world with his family in his free time.Recent posts\n",
      "CloseEric JohnsonProduct LeadEric JohnsonProduct LeadProduct leader who has built and scaled AI applications and infrastructure. Eric led the TensorFlow API, Compiler, and Runtime teams at Google Brain and Core Systems, including the founding of TFRT and the productionization of JAX. He holds an MBA from Wharton and Computer Science MS from Penn and loves soccer, fitness, and the great outdoors.eric@modular.comRecent posts\n",
      "CloseMike EdwardsOperations LeadMike EdwardsOperations LeadMike has spent over 25 years working in the fields of IT, corporate operations, and software development - most recently at Apple. Mike volunteers his time serving as a Board member with the LLVM Foundation, focusing on finance and operations. Mike truly believes in the power of AI to help address some of the world’s greatest needs.Recent posts\n",
      "CloseNick KreegerFramework Engineering LeadNick KreegerFramework Engineering LeadSoftware Engineering lead with over 15 years of experience working at Google, Microsoft and a handful of startups. Nick has contributed to many technologies in Machine Learning such as TensorFlow.js, TensorFlow Lite/Micro, and ONNX/ONNXRuntime. Nick enjoys spending his free time with family and enjoying the Minnesotan outdoors.Recent posts\n",
      "CloseTatiana ShpeismanCompiler Engineering LeadTatiana ShpeismanCompiler Engineering LeadLeader in compilers, programming models, and AI systems. Before joining Modular, Tatiana led CPU and GPU compiler infrastructure for Google ML, co-founded MLIR, and was a Principal Engineer and Director of Programming Systems Research at Intel Labs. Tatiana has published ~40 research papers, holds ~50 US and international patents, and has served on numerous research conference programming committees, including being Co-Chair of CGO 2022.Recent posts\n",
      "CloseAbdul DakkakAI Compiler EngineerAbdul DakkakAI Compiler EngineerExpert in machine learning, compilers, programming languages, and accelerated computing. Before Modular, Abdul led the development of AI compilers for GPUs at Microsoft Research and the Mathematica Compiler at Wolfram Research. Abdul has developed open-source tools for accelerating real-world applications to optimize their performance across the hardware and software stack.Recent posts\n",
      "CloseAditya BhagwatAI Framework EngineerAditya BhagwatAI Framework EngineerAditya is a software engineer who is passionate about machine learning systems and enjoys crafting elegant software solutions to complex problems. At Modular, he’s working on building the next generation of frameworks enabled by the latest innovations in our stack. Before joining Modular, he was busy getting his master’s degree in AI from Carnegie Mellon University. In his free time, he enjoys listening to classical music, cooking and reading.Recent posts\n",
      "CloseAlex KirchhoffAI Performance EngineerAlex KirchhoffAI Performance EngineerAlex is a software engineer specializing in low-level systems performance. Alex previously worked on AI inference in firmware at Apple, and designed substantial portions of Xnor.ai’s inference stack. Alex also has a background in computer security and vulnerability research, with a focus in reverse engineering and binary exploitation. Alex cares about program correctness, understandability, and efficiency, and enjoys learning how things work as well as their failure modes. Alex holds a Bachelor of Science in Computer Science from the University of Washington with a minor in Mathematics.Recent posts\n",
      "CloseAlexandr NikitinAI Cloud EngineerAlexandr NikitinAI Cloud EngineerAlex is a software engineer with over 15 years of experience who is passionate about building efficient, fault-tolerant, and high-performance systems. Prior to joining Modular, he led the Einstein Platform ML Serving solution at Salesforce, which scaled to support hundreds of thousands of ML models and prior to that build extremely high performance ads systems. In his free time, Alex enjoys mountaineering, climbing, and trail running.Recent posts\n",
      "CloseAman LaChapelleAI Compiler EngineerAman LaChapelleAI Compiler EngineerAman specializes in building and deploying complex technologies on a variety of platforms. He has, and continues to design and build cutting-edge compiler and runtime stacks for novel accelerators, heterogeneous SoCs, and traditional server deployments at companies like Apple and SambaNova Systems. Aman cares deeply about democratizing state of the art technology.Recent posts\n",
      "CloseAndrew DingTechnical Program ManagerAndrew DingTechnical Program ManagerAndrew is an experienced technical program manager passionate about solving real-world problems that improve the lives of people through technology. Before Modular, he taught machine learning as a graduate student instructor at the University of California, Berkeley before working at LinkedIn and Plaid to scale and improve their reliability and ML infrastructure. In his spare time he enjoys playing Poker.Recent posts\n",
      "CloseArjun SurendranAI Framework EngineerArjun SurendranAI Framework EngineerArjun specializes in the intersection of Machine Learning and Software Engineering. Prior to joining Modular he was a Machine Learning Engineer on Adobe's On-Device Machine Learning team. Arjun is passionate about making things simpler and accessible to a wider audience, and enjoys tinkering with system level software and learning about programming languages internals.Recent posts\n",
      "CloseBlake HuangProgram Co-ordinatorBlake HuangProgram Co-ordinatorA recruiter and scheduling master who has had multiple roles at AT&T, Meta, and SiFive. Loves startup life and co-ordinating everything.Recent posts\n",
      "CloseBrendan DukeAI Framework EngineerBrendan DukeAI Framework EngineerBrendan is adept at building systems spanning the software and machine learning stack. Brendan started his career by writing firmware for the AMD Secure Processor. He then went on to complete his master’s in machine learning at the University of Guelph. He has since focused on state-of-the-art deep learning tech for the past 5 years. Most recently, Brendan designed a deep learning tech stack optimized to deploy AR experiences to the web on mobile devices while at Modiface. When away from the keyboard, Brendan enjoys spending time with his fiancée and family, and exploring Hamilton with his goldendoodle, Hank.Recent posts\n",
      "CloseBrian GesiakAI Compiler EngineerBrian GesiakAI Compiler EngineerExperienced compiler engineer with an interest in modern programming language design. Before joining Modular, Brian spent nearly a decade at Meta working on a variety of compiler projects, including LLVM, Clang, and the Move programming language. Brian believes that Modular has the opportunity to push forward the state of the art of programming languages and their user experience, and is thrilled to help build that future.Recent posts\n",
      "CloseChad JarvisAI Performance EngineerChad JarvisAI Performance EngineerChad has a strong background in low-level code optimization, parallel programming, and high performance computing. He has worked for more than 17 years in research and engineering in Europe and North America. He holds a PhD in particle physics and is one of the authors of the Higgs Boson discovery. Chad has a passion and focus for understanding things at a fundamental level. Prior to joining Modular he worked at Graphcore working closely with the hardware engineers to implement and optimize custom features of the GC hardware, and before that Simula Research Laboratory among many other distinguished research facilities. He enjoys spending his spare time with his family, travelling, collecting rare coins, and eating excellent food.Recent posts\n",
      "CloseChristopher NiesAI Cloud EngineerChristopher NiesAI Cloud EngineerSouthern California tech nerd turned Bay Area Cloud Engineer, now enjoying a healthy mix of both. Spent 5 years building Hearth’s infrastructure stack from the ground up, from the first Ruby on Rails model to Director of Backend Engineering. Likes Dungeons and Dragons, puzzles, and being near the ocean.Recent posts\n",
      "CloseDan MoldovanAI Framework EngineerDan MoldovanAI Framework EngineerDan has over 15 years of software engineering experience in a wide variety of fields and roles. Before Modular, Dan worked in teams such as Google Brain and TensorFlow, where he co-authored AutoGraph, led improvements to system architecture, graph representations and APIs, developed ML and TensorFlow training material, and collaborated with ML researchers. Dan is passionate about developing next generation programming languages for machine learning. Dan enjoys hiking, stargazing and traveling around the world.Recent posts\n",
      "CloseDeep DhillonAI Cloud EngineerDeep DhillonAI Cloud EngineerDeep is a passionate Cloud Infrastructure Engineer who enjoys building, automating and deploying highly scalable applications. He is a recent graduate from the University of Waterloo and before Modular, he worked at Google developing Kubernetes based database infrastructure for Google Distributed Cloud Hosted. In his free time, Deep enjoys travelling to new places, taking photos, and playing sports. Deep is now building cloud AI/ML infrastructure at Modular.Recent posts\n",
      "CloseFabian TschoppAI Framework EngineerFabian TschoppAI Framework EngineerFabian is adept at engineering AI infrastructure that enables AI for everyone since the early days of machine learning frameworks. Fabian designed the official OpenCL version of Caffe, while studying computer science and neural systems at ETH Zürich, working together with AMD and Intel. He joins Modular after most recently working on PyTorch, ONNX and PopART for Graphcore’s IPU AI accelerator hardware. Originally from Switzerland, Fabian now resides in Norway, where he enjoys spending time with his fiancée and daughter. When away from the keyboard, Fabian can be found rowing during summer and cross country skiing during winter.Recent posts\n",
      "CloseGoldie GaddeTechnical Program ManagerGoldie GaddeTechnical Program ManagerLead Technical Program Manager with 18 years of industry experience working at Google Brain and Cisco in a variety of roles and technologies from enabling Google’s revolutionary data centers to enabling ML for the world. Goldie has a consistent track record in solving problems that involve technical and organizational complexities. Prior to joining Modular, Goldie was the lead TPM for TensorFlow & Keras APIs at Google Core ML driving the roadmap of next gen ML APIs while enabling AI/ML for Waymo, YouTube, Ads and many other teams at Google. She holds a MS in Electrical Engineering from University of California, Irvine and in her free time enjoys hiking and traveling the world with her family.Recent posts\n",
      "CloseHengjie WangAI Performance EngineerHengjie WangAI Performance EngineerHengjie Wang is a software engineer focusing on performance optimizations for AI and scientific applications. He has many years of experience in developing and optimizing large-scale scientific applications on world-ranking supercomputers. He has also developed Deep learning algorithms to advance physical simulations. Before joining Modular, he was a postdoctoral scholar in the Lawerence Berkeley National Lab, where he participated in developing the Exa-scale projects MFIX-Exa and AMReX on national supercomputers. He is a big fan of Go and enjoys hiking and dog training.Recent posts\n",
      "CloseIan TrambleAI Performance EngineerIan TrambleAI Performance EngineerExperienced systems software engineer with a background in performance and accelerated computing. Before joining Modular, Ian spent 5 years at NVIDIA working on MLPerf Inference, TensorRT, and systems software for autonomous vehicles. He is passionate about providing great out-of-the-box performance by abstracting hardware. Ian graduated from the Engineering Science program at the University of Toronto with a major in electrical and computer engineering.Recent posts\n",
      "CloseJakub TucholskiAI Cloud EngineerJakub TucholskiAI Cloud EngineerWorking on web infrastructure since AWS offered only 2 services (S3 & EC2). Past stints include automating global capacity management and improving maps reliability at Uber and helping scale Heath from $0 to $1 million ARR. Likes Robert Caro, death metal, Magic the Gathering, and deterministic builds.Recent posts\n",
      "CloseJames DeckerAI Compiler EngineerJames DeckerAI Compiler EngineerJames is passionate about building tools that boost programmer productivity, focusing on compilers for heterogeneous computing and AI acceleration while at Purdue, Stanford, Google, and SambaNova Systems. James believes deeply that technology, and AI in particular, must be fair to be beneficial, which necessitates that it is easy to use and understand.Recent posts\n",
      "CloseJeff NiuAI Compiler EngineerJeff NiuAI Compiler EngineerCompiler Engineer, MLIR Developer, and former Robotics Hacker. Jeff studied Mechatronics Engineering at the University of Waterloo where he explored his passion for Robotics before falling in love with MLIR and Compilers while at Google, where he worked making TensorFlow faster and better for everyone. Jeff is now developing MLIR-based compilers at Modular to make AI better for the World.Recent posts\n",
      "CloseJoe LoserAI Framework EngineerJoe LoserAI Framework EngineerExpert in C++ and low-latency programming. Before Modular, Joe was at Quantlab writing cutting-edge C++ generic libraries for real-time trading systems that push the boundaries of performance for software and hardware. In his free time, Joe enjoys traveling, hiking, and spending time with his fiancé and dog.Recent posts\n",
      "CloseJuan GalvezAI Framework EngineerJuan GalvezAI Framework EngineerExpert in high-performance computing, parallel computing, concurrency models, runtime systems and accelerating big data analytics. Before Modular, Juan led parallelization and performance development of Bodo.ai's compute and query execution engine. Juan was a core developer of Charm++ at UIUC, a production parallel programming framework used by supercomputing applications that scale to millions of cores, and is the author of Charm4py.Recent posts\n",
      "CloseKate CaldwellAI Framework EngineerKate CaldwellAI Framework EngineerKate is a machine learning engineer passionate about optimizing AI deployment and broadening the impact of developments in the field. Before Modular, Kate worked as as a Machine Learning Research Apprentice while studying for her MS in Computer Science at Northeastern University. In her free time, Kate likes book clubs, cooking, and feeding her dog treats.Recent posts\n",
      "CloseKevin BuchsAI Cloud EngineerKevin BuchsAI Cloud EngineerWorked at the Mayo Clinic’s Special Purpose Processor Development Group performing research developing advanced high speed electronics with novel materials and technologies creating CAD systems, software for advanced testing, analysis and simulation. Helped scale Cloud Engineering & DevOps across large large workloads on AWS, Azure and GCP. Worked with infrastructure as code, mostly using Terraform. Python is my love language. When I'm not helping scale Cloud, I enjoy time with my two grown children and 8 grandchildren.Recent posts\n",
      "CloseLaszlo KindratAI Compiler EngineerLaszlo KindratAI Compiler EngineerLaszlo is a former data scientist turned software engineer. Before Modular, he built XMOS’s first ML compiler and maintained their TFLite Micro runtime, then worked as lead engineer on the MLIR-based software stack at Luminous Computing. He enjoys traveling and all New England seasons.Recent posts\n",
      "CloseLiam StewartAI Cloud EngineerLiam StewartAI Cloud EngineerA software engineer with over 15 years of industry experience, Liam is passionate about building software and systems to address practical problems in robust and forward-looking ways. Liam has built, operated, and scaled cloud systems at a variety of companies including Google, Strava, and most recently PagerDuty. When not at work, he can usually be found outside riding bikes and spending time with his family.Recent posts\n",
      "CloseLiina LindSenior Recruiting ManagerLiina LindSenior Recruiting ManagerLiina is an experienced talent acquisition specialist and leader who most recently built and shaped the global TA process at SiFive. With previous work experience in Japan, the US and Europe, Liina has joined Modular to build a global and world-class team who will reinvent the AI infrastructure for the world.Recent posts\n",
      "CloseLily Orth-SmithAI Compiler EngineerLily Orth-SmithAI Compiler EngineerLily is a machine learning compiler engineer with a passion for programming languages. In her daily work, she likes solving engineering design problems elegantly and practically. Before Modular, Lily worked on Apache TVM (an open source machine learning compiler) at OctoML. In her free time, Lily loves being outdoors— hiking, biking and gardening. She also enjoys woodworking and ceramics.Recent posts\n",
      "CloseMark ShieldsAI Framework EngineerMark ShieldsAI Framework EngineerMark’s engineering career has spanned programming languages and compilers, maps and transport routing, streaming dataflow and, most recently, deep learning compilers. He joins Modular after most recently working on Apache TVM, and before that a distinguished career at Google. Mark is now looking forward to radically reducing the accidental complexity in model compilation, deployment and monitoring.Mark lives with his family in Seattle and is a keen back country hiker, trail runner, climber and renovator.Recent posts\n",
      "CloseMatthew BrookhartAI Compiler EngineerMatthew BrookhartAI Compiler EngineerSoftware Engineering lead with a strong background in mathematics, optimization, and team management. Matthew comes to Modular with over 7 years of experience working on AI models and Compilers at large companies like Intel and small startups working on technologies like TVM. He's a total coding nerd, and loves picking up new programming languages and tracking down bugs.  Matthew enjoys spending his free time hiking in the Wasatch Mountains, and loves to bake delicious breads and pizzas for his family.Recent posts\n",
      "CloseMikhail ZolotukhinAI Compiler EngineerMikhail ZolotukhinAI Compiler EngineerExpert in traditional and ML compilers with over 15 years of experience in the field. Before Modular, Michael contributed to Intel Compiler, GCC, LLVM, and most recently PyTorch. He is passionate about building right things the right way and excited to do that at Modular to help power AI for the world.Recent posts\n",
      "ClosePaige BedwellProgram ManagerPaige BedwellProgram ManagerPaige has spent several years building an impressive set of leadership, logistic, and operational skills in the industries of executive concierge management and outdoor adventure experiences. Paige joined Modular with the vision and aspiration to help AI change the world for the better.Recent posts\n",
      "ClosePatrick BeckSenior IT SpecialistPatrick BeckSenior IT SpecialistPatrick is an IT professional who loves wearing all the different hats after working for more than 7 years at Thumbtack helping to scale out their IT infrastructure, security and systems from its earliest days. After mastering IT Support, Patrick learned device and systems management and is now working to tackle all the IT challenges at Modular. Outside work, Patrick is an avid gardener and aspiring farmer.Recent posts\n",
      "CloseRiver RiddleAI Compiler EngineerRiver RiddleAI Compiler EngineerSoftware Architect, Compiler Engineer, and Programming Language enthusiast. River is a leader within MLIR, and has driven core developments since its inception. Before joining Modular, he developed and evangelized MLIR within Google ML, working with TensorFlow, JAX, Google Tensor, and more. River is passionate about his family, staying fit, and crafting cutting edge developer technology.Recent posts\n",
      "CloseRosane VallimProduct ManagerRosane VallimProduct ManagerProduct manager with a long experience designing and delivering ML experiences and infrastructure at scale. Prior to joining Modular, Rosane led the Windows ML and DirectML product teams at Microsoft. She holds a PhD in Machine Learning and loves traveling, reading and spending time with her family and dog.Recent posts\n",
      "CloseRyan GuoAI Compiler EngineerRyan GuoAI Compiler EngineerRyan is a passionate compiler engineer. Before Modular, he worked on auto-vectorization while studying at UIUC, and Flashlight while interning at FAIR. He cares about building things the right way, and having positive impact on people's lives. When he's not coding, rhino videos and piano keep him sane.Recent posts\n",
      "CloseScott MainAI Technical WriterScott MainAI Technical WriterScott is an experienced lead writer with diverse skills in technology and product development. He’s passionate about designing developer experiences that are simple and intuitive, and documentation that is clear, concise, and complete. Previously, Scott led various documentation projects at Google, including for Android and Coral Edge TPU.Recent posts\n",
      "CloseSean ParadisoAI Framework ManagerSean ParadisoAI Framework ManagerEngineering leader with experience managing teams across the full stack from ML algorithms to high scale production services. Sean served as VP Platform Engineering at Citrine Informatics, building an ML platform for novel materials and chemicals discovery, before joining Twitter to lead the ML Serving team, supporting key high scale infrastructure such as ads serving and timeline ranking. In his free time, Sean enjoys rock climbing, wandering in the woods, and scouting for tractors with his 2 year old son, Leo.Recent posts\n",
      "CloseSrinivasan NarayanamoorthyAI Framework EngineerSrinivasan NarayanamoorthyAI Framework EngineerSrini is an AI framework engineer focussing on performance across the stack from graph optimizations to low level kernel/threading optimizations. Before modular, he was at Intel for almost 10 years performing various roles from CPU hardware development to Tensorflow optimizations. Srini enjoys spending time with his family and playing cricket during summers.Recent posts\n",
      "CloseSteffi StumposAI Compiler EngineerSteffi StumposAI Compiler EngineerSteffi is a software engineer focused on compiler development. Before Modular she was a member of Meta's Probability organization where she contributed to projects in the fields of Differentiable Programming, Probabilistic Programming, and GPGPU optimization. When not at her desk Steffi can be found rock climbing in the hills of Colorado.Recent posts\n",
      "CloseStephen McGroartyAI Compiler EngineerStephen McGroartyAI Compiler EngineerStephen is an experienced software engineer with an interest in machine learning, compilers, computer architecture, and optimization. Before joining Modular he worked at the intersection of these working on compilers for heterogeneous systems at Codeplay and then built out PyTorch integration at Graphcore with work optimizing performance across the stack. In his spare time he enjoys the Californian sunshine and skiing in the winter months.Recent posts\n",
      "CloseTaewook OhAI Framework EngineerTaewook OhAI Framework EngineerSoftware engineer specializing in compilers and runtimes. Before Modular, Taewook tech-led multiple compiler teams at Meta and Samsung, from a LLVM compiler team for server-side applications to a team that builds a compiler for hardware accelerators. He has served the compiler research community as a conference committee member of CGO and LCTES.Recent posts\n",
      "CloseTyler KenneyAI Performance EngineerTyler KenneyAI Performance EngineerTyler is a performance optimization & hardware acceleration specialist. He holds bachelor’s and master’s degrees in computer engineering from Lehigh University. Prior to Modular, Tyler developed compilers, simulators, instruction sets and kernel libraries for AI accelerators first at IBM and then at Lightmatter. He is passionate about forecasting technology and understanding, to the best of his ability, the long-term impacts of artificial intelligence. On weekends Tyler enjoys anything and everything outside, particularly running, camping, playing ultimate frisbee, boating/wakeboarding and skiing.Recent posts\n",
      "CloseYihua LouAI Cloud EngineerYihua LouAI Cloud EngineerExperienced software engineer across a broad range of technologies. Prior to Modular, Lou graduated with a bachelor's in Computer Science from the University of Illinois Urbana-Champaign before working on mobile apps and NLP infrastructure for search and other applications at Google for 9 years. Avid video gamer and orange cat enthusiast.Recent posts\n",
      "CloseLearn more about us\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuNewsletter SignupGet all our latest news, announcements and updates delivered directly to your inbox. You can unsubscribe at anytime.\n",
      "\n",
      "Blog PostsCompanyMay 11, 2023Our launch & what's nextTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerProductMay 2, 2023A unified, extensible platform to superpower your AIChris Lattner,Co-Founder & CEOChris Lattner,Co-Founder & CEOTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerEric Johnson,Product LeadEric Johnson,Product LeadRosane Vallim,Product ManagerRosane Vallim,Product ManagerEngineeringApril 20, 2023The world's fastest unified matrix multiplicationAbdul Dakkak,AI Compiler EngineerAbdul Dakkak,AI Compiler EngineerChad Jarvis,AI Performance EngineerChad Jarvis,AI Performance EngineerEric Johnson,Product LeadEric Johnson,Product LeadHengjie Wang,AI Performance EngineerHengjie Wang,AI Performance EngineerIan Tramble,AI Performance EngineerIan Tramble,AI Performance EngineerEngineeringMarch 23, 2023AI’s compute fragmentation: what matrix multiplication teaches usEric Johnson,Product LeadEric Johnson,Product LeadAbdul Dakkak,AI Compiler EngineerAbdul Dakkak,AI Compiler EngineerChad Jarvis,AI Performance EngineerChad Jarvis,AI Performance EngineerCompanyDecember 15, 2022We want to hear from youRosane Vallim,Product ManagerRosane Vallim,Product ManagerCompanyApril 26, 2022The future of AI depends on ModularityChris Lattner,Co-Founder & CEOChris Lattner,Co-Founder & CEOTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerCompanyJune 30, 2022The Case for a Next-Generation AI Developer PlatformChris Lattner,Co-Founder & CEOChris Lattner,Co-Founder & CEOTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerEric Johnson,Product LeadEric Johnson,Product LeadEngineeringAugust 12, 2022Increasing development velocity of giant AI modelsRiver Riddle,AI Compiler EngineerRiver Riddle,AI Compiler EngineerEric Johnson,Product LeadEric Johnson,Product LeadEngineeringDecember 8, 2022If AI serving tech can’t solve today’s problems, how do we scale into the future?Amit Agarwal,Cloud Infrastructure LeadAmit Agarwal,Cloud Infrastructure LeadEric Johnson,Product LeadEric Johnson,Product LeadCultureMay 21, 2022How we workChris Lattner,Co-Founder & CEOChris Lattner,Co-Founder & CEOTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerCompanyNovember 8, 2022Modular is rebuilding AI in the face of a new economyChris Lattner,Co-Founder & CEOChris Lattner,Co-Founder & CEOTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerEngineeringNovember 10, 2022Part 2: Increasing development velocity of giant AI modelsAbdul Dakkak,AI Compiler EngineerAbdul Dakkak,AI Compiler EngineerEric Johnson,Product LeadEric Johnson,Product LeadRiver Riddle,AI Compiler EngineerRiver Riddle,AI Compiler EngineerDesignAugust 18, 2022Modular's Brand StoryTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerEric Johnson,Product LeadEric Johnson,Product LeadMatt Ellis,MetaLab Brand DirectorMatt Ellis,MetaLab Brand DirectorLearn more about us\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Our Culture\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuA great culture is the key to creating a great company.Build products users loveCustomers firstWe build technology to lift the world by solving our customers' problems. We understand our users' problems and use cases and know there is sometimes a trade-off between \"what is important\" and \"what is interesting\" when building technology. We are clear that our customers always come first, and we always deliver on our promises.Build it rightWe build high-quality production software that displays technical mastery inside and out. We make our infrastructure the right way because we understand how quickly technical debt compounds. We know how faster engineering, product development, and business metrics move with a solid foundation. We build scalable, modular, and reliable systems that meet our customers' needs.Drive resultsWhen our customers and their people succeed, our company succeeds. No matter their role, every employee contributes to our collective success. Individually and together, we are all aligned on what we are working towards and how we can contribute. But we don't just work on auto-pilot. We expect everyone to regularly step back and ask if we're measuring the right input and output. We all win when we drive results that actually matter.Empower peopleOwnershipWe act on behalf of the entire organization and not just for ourselves and our local team. We operate on the assumption that each person is highly motivated and will drive their work with a bias towards action. We drive ownership by tracking progress toward our goals with clear expectations, responsible owners, and solid execution. We expect everyone to act like an owner, and once a decision is made, everyone will fully commit and move forward together.TransparencyWe are transparent by having decisions, calendars, directions, and plans open to everyone in the company. Anyone can constructively ask tough questions and feel safe to have answers provided directly. We expect people to be clear about what they know and open about what they don’t. We want everyone to feel that they can be vulnerable in front of each other and feel safe to take risks because this is how we grow and innovate.Hire the best, never stop learningWe hire great people who seek to constantly grow themselves and others around them. Great people don’t settle; they have a thirst for knowledge and new skills, a desire for self-improvement, and actively seek feedback whenever they can. Great people develop great people; they take coaching others seriously and look to raise the standards of the whole organization.Have fun, live lifeWe believe people do their best work when they are happy. Our goal is to ensure that you will always have the environment to achieve the right mix of family, compensation, growth, and mission to live a balanced and fulfilling life. By having fun and living your life, you also see more of the world, appreciate it, and learn how we can help improve it.Be an incredible teamWin together, fail togetherChanging the world is a team sport, and we need a group of incredibly talented people to be successful. Individual wins, or mistakes, matter less than everyone winning, failing, learning, and growing together. We expect everyone to listen, speak openly, and treat others with respect regardless of the wins or losses along the way. We foster a blameless culture for mistakes, and we expect our team to take risks without feeling insecure or embarrassed. The more we trust each other, the more we can lean on each other, and the more we can learn and grow together.Own inclusion, be diverseWe build for everyone, and we are open to everyone. We believe that the best results come from a team that reflects the world at large. Our customers are diverse, and so are their needs, so we must empower and promote diversity and diverse perspectives at all company levels. We need to build diverse teams and foster diverse thinking to create products that genuinely help the world.Everyone has a voiceWe expect the best concept, design, plan, or direction to succeed regardless of someone’s “rank” in the company. Innovation exists everywhere, and great ideas are inside all of us. You can always reach out to anyone at any level in the company. We foster open communication and constructive debate and expect everyone to accept respectful challenges to their positions. We believe that the job of a leader is to find the right answer with their team, not to magically know everything themselves.Assume positive intentWe expect everyone to assume the best of others. Our experiences have shown that information asymmetry almost always exists between people, and taking the time to understand circumstances via transparent communication is key to building healthy and functioning teams. We're all human and often jump to conclusions; we want people to assume good intentions when we do.Learn more about us\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuLet's talk about Modular's AI Platform. We want to hear from you.Contact usPresspress@modular.comPartnershipshello@modular.comOtherFor any other inquiry, please use our existing pages below.PRODUCTsGetting Started DiscordCareersCareersLEGALTermsPrivacy PolicyAcceptable UseWe are rebuilding and reinventing AI software at its core to scale and enable the world to realize the true power of data, algorithms, and compute. We are building natively multi-framework, multi-cloud, and multi-hardware capable products.Please email us only for Press or Partnerships, otherwise use our other links.Blog PostsCompanyMay 11, 2023Our launch & what's nextTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerProductMay 2, 2023A unified, extensible platform to superpower your AIChris Lattner,Co-Founder & CEOChris Lattner,Co-Founder & CEOTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerEric Johnson,Product LeadEric Johnson,Product LeadRosane Vallim,Product ManagerRosane Vallim,Product ManagerEngineeringApril 20, 2023The world's fastest unified matrix multiplicationAbdul Dakkak,AI Compiler EngineerAbdul Dakkak,AI Compiler EngineerChad Jarvis,AI Performance EngineerChad Jarvis,AI Performance EngineerEric Johnson,Product LeadEric Johnson,Product LeadHengjie Wang,AI Performance EngineerHengjie Wang,AI Performance EngineerIan Tramble,AI Performance EngineerIan Tramble,AI Performance EngineerEngineeringMarch 23, 2023AI’s compute fragmentation: what matrix multiplication teaches usEric Johnson,Product LeadEric Johnson,Product LeadAbdul Dakkak,AI Compiler EngineerAbdul Dakkak,AI Compiler EngineerChad Jarvis,AI Performance EngineerChad Jarvis,AI Performance EngineerCompanyDecember 15, 2022We want to hear from youRosane Vallim,Product ManagerRosane Vallim,Product ManagerCompanyApril 26, 2022The future of AI depends on ModularityChris Lattner,Co-Founder & CEOChris Lattner,Co-Founder & CEOTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerCompanyJune 30, 2022The Case for a Next-Generation AI Developer PlatformChris Lattner,Co-Founder & CEOChris Lattner,Co-Founder & CEOTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerEric Johnson,Product LeadEric Johnson,Product LeadEngineeringAugust 12, 2022Increasing development velocity of giant AI modelsRiver Riddle,AI Compiler EngineerRiver Riddle,AI Compiler EngineerEric Johnson,Product LeadEric Johnson,Product LeadEngineeringDecember 8, 2022If AI serving tech can’t solve today’s problems, how do we scale into the future?Amit Agarwal,Cloud Infrastructure LeadAmit Agarwal,Cloud Infrastructure LeadEric Johnson,Product LeadEric Johnson,Product LeadCultureMay 21, 2022How we workChris Lattner,Co-Founder & CEOChris Lattner,Co-Founder & CEOTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerCompanyNovember 8, 2022Modular is rebuilding AI in the face of a new economyChris Lattner,Co-Founder & CEOChris Lattner,Co-Founder & CEOTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerEngineeringNovember 10, 2022Part 2: Increasing development velocity of giant AI modelsAbdul Dakkak,AI Compiler EngineerAbdul Dakkak,AI Compiler EngineerEric Johnson,Product LeadEric Johnson,Product LeadRiver Riddle,AI Compiler EngineerRiver Riddle,AI Compiler EngineerDesignAugust 18, 2022Modular's Brand StoryTim Davis,Co-Founder & Chief Product OfficerTim Davis,Co-Founder & Chief Product OfficerEric Johnson,Product LeadEric Johnson,Product LeadMatt Ellis,MetaLab Brand DirectorMatt Ellis,MetaLab Brand DirectorLearn more about us\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Get started today\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Get started todayModular is a fully integrated, composable suite of AI infrastructure tools with unmatched industry performance that streamlines AI workflows.Get started today and let us know what products you are interested in. We're rolling out access as fast as we can.Next\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Get started today\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Get started todayModular is a fully integrated, composable suite of AI infrastructure tools with unmatched industry performance that streamlines AI workflows.Get started today and let us know what products you are interested in. We're rolling out access as fast as we can.Next\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Inference Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuThe world's fastest unified AI inference engine. Get  models into production, faster.The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions. Bring your model as-is and deploy it anywhere, across server and edge, with unparalleled usability and performance.Get startedSee our performanceengine P99 Latency: 12.1 ms *P50P90P95P99TensorFlowPyTorchModular Engine* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size101UnificationTrain in any framework, deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude.Cloud & On-PremFrameworksmodular EngineServer & edgeFramework optionalityEasily deploy models trained in any framework, such as TensorFlow or PyTorch, without retraining, conversions or pre-optimization steps, using a unified set of APIs. There are no tricks, no hacks - the Engine just works incredibly fast.Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models. Avoid lock-in and take advantage of price efficiencies and performance improvements without migration costs.02PerformanceMaximize performance, minimize costsReduce latency, increase throughput, and improve resource efficiency across CPUs, GPUs, and accelerators. Productionize larger models and significantly reduce your computing costs.Explore our performance dashboardQueries per Second *125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences *$ 0.12TensorFlow$0.89PyTorch$0.54Modular Engine$0.12* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size1MODULAR ENGINE SPEED-UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family  vs  vs  vs  vs  vs  vsLanguage Model3x3.2x5.3x1.4x2.1x4xRecommender Models6.5x5x7.5x1.1x1.2x4.3xVision Models2.1x2.2x1.7x1.5x1.5x1.3xCompute TypeIntel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)Intel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)ResultsAWS Compute Instances. TensorFlow & PyTorch listed by logo. Full performance & methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again. Run any model, including support for all native framework operators, dynamic shapes, low-precision, and your existing custom operators.DLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseBERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases. Our tools are... well... modular. They integrate with industry-standard infrastructure and open-source tools to minimize migration cost.Request accessseamless integration with popular libraries and tools01.Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular's off-the-shelf NVIDIA Triton and TensorFlow-Serving builds.02.Choose your cloudDeploy the engine on-prem, in your own VPC on any major cloud provider, or get up and running quicker with out hosted solutions.03.METRICS & MONITORINGThe Modular Inference Engine works with industry-standard open-source tooling like Prometheus and Grafana.Ready to try a preview?Contact us to get early-access to the Modular Inference Engine.Request accessAPI References, Tutorials, & MoreRead the Modular Inference Engine docs\n",
      "\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Inference Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuThe world's fastest unified AI inference engine. Get  models into production, faster.The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions. Bring your model as-is and deploy it anywhere, across server and edge, with unparalleled usability and performance.Get startedSee our performanceengine P99 Latency: 12.1 ms *P50P90P95P99TensorFlowPyTorchModular Engine* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size101UnificationTrain in any framework, deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude.Cloud & On-PremFrameworksmodular EngineServer & edgeFramework optionalityEasily deploy models trained in any framework, such as TensorFlow or PyTorch, without retraining, conversions or pre-optimization steps, using a unified set of APIs. There are no tricks, no hacks - the Engine just works incredibly fast.Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models. Avoid lock-in and take advantage of price efficiencies and performance improvements without migration costs.02PerformanceMaximize performance, minimize costsReduce latency, increase throughput, and improve resource efficiency across CPUs, GPUs, and accelerators. Productionize larger models and significantly reduce your computing costs.Explore our performance dashboardQueries per Second *125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences *$ 0.12TensorFlow$0.89PyTorch$0.54Modular Engine$0.12* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size1MODULAR ENGINE SPEED-UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family  vs  vs  vs  vs  vs  vsLanguage Model3x3.2x5.3x1.4x2.1x4xRecommender Models6.5x5x7.5x1.1x1.2x4.3xVision Models2.1x2.2x1.7x1.5x1.5x1.3xCompute TypeIntel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)Intel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)ResultsAWS Compute Instances. TensorFlow & PyTorch listed by logo. Full performance & methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again. Run any model, including support for all native framework operators, dynamic shapes, low-precision, and your existing custom operators.DLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseBERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases. Our tools are... well... modular. They integrate with industry-standard infrastructure and open-source tools to minimize migration cost.Request accessseamless integration with popular libraries and tools01.Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular's off-the-shelf NVIDIA Triton and TensorFlow-Serving builds.02.Choose your cloudDeploy the engine on-prem, in your own VPC on any major cloud provider, or get up and running quicker with out hosted solutions.03.METRICS & MONITORINGThe Modular Inference Engine works with industry-standard open-source tooling like Prometheus and Grafana.Ready to try a preview?Contact us to get early-access to the Modular Inference Engine.Request accessAPI References, Tutorials, & MoreRead the Modular Inference Engine docs\n",
      "\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Inference Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuThe world's fastest unified AI inference engine. Get  models into production, faster.The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions. Bring your model as-is and deploy it anywhere, across server and edge, with unparalleled usability and performance.Get startedSee our performanceengine P99 Latency: 12.1 ms *P50P90P95P99TensorFlowPyTorchModular Engine* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size101UnificationTrain in any framework, deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude.Cloud & On-PremFrameworksmodular EngineServer & edgeFramework optionalityEasily deploy models trained in any framework, such as TensorFlow or PyTorch, without retraining, conversions or pre-optimization steps, using a unified set of APIs. There are no tricks, no hacks - the Engine just works incredibly fast.Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models. Avoid lock-in and take advantage of price efficiencies and performance improvements without migration costs.02PerformanceMaximize performance, minimize costsReduce latency, increase throughput, and improve resource efficiency across CPUs, GPUs, and accelerators. Productionize larger models and significantly reduce your computing costs.Explore our performance dashboardQueries per Second *125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences *$ 0.12TensorFlow$0.89PyTorch$0.54Modular Engine$0.12* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size1MODULAR ENGINE SPEED-UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family  vs  vs  vs  vs  vs  vsLanguage Model3x3.2x5.3x1.4x2.1x4xRecommender Models6.5x5x7.5x1.1x1.2x4.3xVision Models2.1x2.2x1.7x1.5x1.5x1.3xCompute TypeIntel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)Intel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)ResultsAWS Compute Instances. TensorFlow & PyTorch listed by logo. Full performance & methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again. Run any model, including support for all native framework operators, dynamic shapes, low-precision, and your existing custom operators.DLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseBERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases. Our tools are... well... modular. They integrate with industry-standard infrastructure and open-source tools to minimize migration cost.Request accessseamless integration with popular libraries and tools01.Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular's off-the-shelf NVIDIA Triton and TensorFlow-Serving builds.02.Choose your cloudDeploy the engine on-prem, in your own VPC on any major cloud provider, or get up and running quicker with out hosted solutions.03.METRICS & MONITORINGThe Modular Inference Engine works with industry-standard open-source tooling like Prometheus and Grafana.Ready to try a preview?Contact us to get early-access to the Modular Inference Engine.Request accessAPI References, Tutorials, & MoreRead the Modular Inference Engine docs\n",
      "\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Mojo 🔥: Programming language for all of AI\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuMojo 🔥 — a new programming language for all AI developers.Mojo combines the usability of Python with the performance of C, unlocking unparalleled programmability of AI hardware and extensibility of AI models.Get started with MojoRead the docs\n",
      "\n",
      "\n",
      "\n",
      "SOFTMAX.PYMojo 🔥\n",
      "\n",
      "\n",
      "pythondef softmax(lst):\n",
      "  norm = np.exp(lst - np.max(lst))\n",
      "  return norm / norm.sum()def softmax(lst):\n",
      "  norm = np.exp(lst - np.max(lst))\n",
      "  return norm / norm.sum()\n",
      "\n",
      "struct NDArray:\n",
      "  def max(self) -> NDArray:\n",
      "    return self.pmap(SIMD.max)\n",
      "\n",
      "struct SIMD[type: DType, width: Int]:\n",
      "  def max(self, rhs: Self) -> Self:\n",
      "    return (self >= rhs).select(self, rhs)01Usability & ProgrammabilityWrite everything in one languageWrite Python or scale all the way down to the metal. Program the multitude of low-level AI hardware. No C++ or CUDA required.Take a tour of Mojo\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def sort(v: ArraySlice[Int]):\n",
      "  for i in range(len(v)):\n",
      "    for j in range(len(v) - i - 1):\n",
      "      if v[j] > v[j + 1]:\n",
      "        swap(v[j], v[j + 1])FILE_NAME.🔥\n",
      "struct MyPair:\n",
      "  var first: Int\n",
      "  var second: F32\n",
      "  \n",
      "  def __init__(self, first: Int, second: F32):\n",
      "    self.first = first\n",
      "    self.second = secondFILE_NAME.🔥\n",
      "def reorder_and_process(owned x: HugeArray):\n",
      "  sort(x)\t# Update in place\n",
      "  \n",
      "  give_away(x^)\t# Transfer ownership\n",
      "  \n",
      "  print(x[0])\t# Error: ‘x’ moved away!FILE_NAME.🔥\n",
      "def exp[dt: DType, elts: Int]\n",
      "    (x: SIMD[dt, elts]) -> SIMD[dt, elts]:\n",
      "  x = clamp(x, -88.3762626647, 88.37626266)\n",
      "  k = floor(x * INV_LN2 + 0.5)\n",
      "  r = k * NEG_LN2 + x\n",
      "  return ldexp(_exp_taylor(r), k)FILE_NAME.🔥\n",
      "def exp_buffer[dt: DType](data: ArraySlice[dt]):\n",
      "\n",
      "  # Search for the best vector length\n",
      "  alias vector_len = autotune(1, 4, 8, 16, 32)\n",
      "  \n",
      "  # Use it as the vectorization length\n",
      "  vectorize[exp[dt, vector_len]](data)Features include:Progressive TypesLeverage types for better performance and error checking.Zero Cost AbstractionsTake control of storage by inline-allocating values into structures.Ownership + borrow checkerTake advantage of memory safety without the rough edges.Portable parametric algorithmsLeverage compile-time meta-programming to write hardware-agnostic algorithms and reduce boilerplate.LANGUAGE INTEGRATED Auto-tuningAutomatically find the best values for your parameters to take advantage of target hardware.As well as:The full power of MLIRParallel heterogenous runtimeFast compile times\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def sort(v: ArraySlice[Int]):\n",
      "  for i in range(len(v)):\n",
      "    for j in range(len(v) - i - 1):\n",
      "      if v[j] > v[j + 1]:\n",
      "        swap(v[j], v[j + 1])Features include:Progressive TypesLeverage types for better performance and error checking.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "struct MyPair:\n",
      "  var first: Int\n",
      "  var second: F32\n",
      "  \n",
      "  def __init__(self, first: Int, second: F32):\n",
      "    self.first = first\n",
      "    self.second = secondFeatures include:Zero Cost AbstractionsTake control of storage by inline-allocating values into structures.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def reorder_and_process(owned x: HugeArray):\n",
      "  sort(x)\t# Update in place\n",
      "  \n",
      "  give_away(x^)\t# Transfer ownership\n",
      "  \n",
      "  print(x[0])\t# Error: ‘x’ moved away!Features include:Ownership + borrow checkerTake advantage of memory safety without the rough edges.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def exp[dt: DType, elts: Int]\n",
      "    (x: SIMD[dt, elts]) -> SIMD[dt, elts]:\n",
      "  x = clamp(x, -88.3762626647, 88.37626266)\n",
      "  k = floor(x * INV_LN2 + 0.5)\n",
      "  r = k * NEG_LN2 + x\n",
      "  return ldexp(_exp_taylor(r), k)Features include:Portable parametric algorithmsLeverage compile-time meta-programming to write hardware-agnostic algorithms and reduce boilerplate.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def exp_buffer[dt: DType](data: ArraySlice[dt]):\n",
      "\n",
      "  # Search for the best vector length\n",
      "  alias vector_len = autotune(1, 4, 8, 16, 32)\n",
      "  \n",
      "  # Use it as the vectorization length\n",
      "  vectorize[exp[dt, vector_len]](data)Features include:LANGUAGE INTEGRATED Auto-tuningAutomatically find the best values for your parameters to take advantage of target hardware.02PerformanceUnlock Python performanceUtilize the full power of the hardware, including multiple cores, vector units, and exotic accelerator units, with the world's most advanced compiler and heterogenous runtime. Achieve performance on par with C++ and CUDA without the complexity.Play with MojoParallelizationMojo leverages MLIR, which enables Mojo developers to take advantage of vectors, threads, and AI hardware units.PYTHONSingle-threaded executionMojo 🔥Parallel processing across multiple coresLanguagesTime (S) *Speedup vs PythonPython 3.10.91027 s1xPypy46.1 s22xScalar C++0.20 s5000xMojo 🔥0.03 s35000x* AlgorithmMandelbrotInstanceAWS r7iz.metal-16xlIntel Xeon03InteroperabilityAccess the entire Python ecosystemExperience true interoperability with the Python ecosystem. Seamlessly intermix arbitrary libraries like Numpy and Matplotlib and your custom code with Mojo.Read the programming manual\n",
      "\n",
      "\n",
      "\n",
      "MAKE_PLOT.🔥def make_plot(m: Matrix):\n",
      "  plt = Python.import_module(\"matplotlib.pyplot\")\n",
      "  fig = plt.figure(1, [10, 10 * yn // xn], 64)\n",
      "  ax = fig.add_axes([0.0, 0.0, 1.0, 1.0], False, 1)\n",
      "  plt.imshow(image)\n",
      "  plt.show()\n",
      "\n",
      "make_plot(compute_mandelbrot())Mojo 🔥04ExtensibilityUpgrade your models and the Modular stackEasily extend your models with pre and post-processing operations, or replace operations with custom ones. Take advantage of kernel fusion, graph rewrites, shape functions, and more.Model extensibilityMojo can upgrade the existing operations in your model.Input layerHidden layersOutput layer05GET STARTED NOWTry Mojo 🔥 out right now in our PlaygroundMojo is still a work in progress, but it's available to try today in our JupyterHub-based Playground. Run through tutorials and write your own Mojo code.Sign up for accessMojo 🔥01.EASY TO GET STARTEDWe have plenty of easy-to-use Jupyter notebooks to help you get started learning Mojo 🔥.02.Unleash your mojoOur docs will help you quickly discover why Mojo is such a powerful extension to Python, and the future of AI programming.03.JOIN the mojo COMMUNITYCome and chat with us on our Discord, and help shape the future of the language as we continue to develop it.Ready to play with Mojo?Reach out to gain access to the Mojo Playground.Request accessAPI Reference, Tutorials, & MoreRead the Mojo docs\n",
      "\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Get started today\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Get started todayModular is a fully integrated, composable suite of AI infrastructure tools with unmatched industry performance that streamlines AI workflows.Get started today and let us know what products you are interested in. We're rolling out access as fast as we can.Next\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Inference Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuThe world's fastest unified AI inference engine. Get  models into production, faster.The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions. Bring your model as-is and deploy it anywhere, across server and edge, with unparalleled usability and performance.Get startedSee our performanceengine P99 Latency: 12.1 ms *P50P90P95P99TensorFlowPyTorchModular Engine* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size101UnificationTrain in any framework, deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude.Cloud & On-PremFrameworksmodular EngineServer & edgeFramework optionalityEasily deploy models trained in any framework, such as TensorFlow or PyTorch, without retraining, conversions or pre-optimization steps, using a unified set of APIs. There are no tricks, no hacks - the Engine just works incredibly fast.Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models. Avoid lock-in and take advantage of price efficiencies and performance improvements without migration costs.02PerformanceMaximize performance, minimize costsReduce latency, increase throughput, and improve resource efficiency across CPUs, GPUs, and accelerators. Productionize larger models and significantly reduce your computing costs.Explore our performance dashboardQueries per Second *125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences *$ 0.12TensorFlow$0.89PyTorch$0.54Modular Engine$0.12* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size1MODULAR ENGINE SPEED-UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family  vs  vs  vs  vs  vs  vsLanguage Model3x3.2x5.3x1.4x2.1x4xRecommender Models6.5x5x7.5x1.1x1.2x4.3xVision Models2.1x2.2x1.7x1.5x1.5x1.3xCompute TypeIntel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)Intel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)ResultsAWS Compute Instances. TensorFlow & PyTorch listed by logo. Full performance & methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again. Run any model, including support for all native framework operators, dynamic shapes, low-precision, and your existing custom operators.DLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseBERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases. Our tools are... well... modular. They integrate with industry-standard infrastructure and open-source tools to minimize migration cost.Request accessseamless integration with popular libraries and tools01.Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular's off-the-shelf NVIDIA Triton and TensorFlow-Serving builds.02.Choose your cloudDeploy the engine on-prem, in your own VPC on any major cloud provider, or get up and running quicker with out hosted solutions.03.METRICS & MONITORINGThe Modular Inference Engine works with industry-standard open-source tooling like Prometheus and Grafana.Ready to try a preview?Contact us to get early-access to the Modular Inference Engine.Request accessAPI References, Tutorials, & MoreRead the Modular Inference Engine docs\n",
      "\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Get started today\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Get started todayModular is a fully integrated, composable suite of AI infrastructure tools with unmatched industry performance that streamlines AI workflows.Get started today and let us know what products you are interested in. We're rolling out access as fast as we can.Next\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Get started today\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Get started todayModular is a fully integrated, composable suite of AI infrastructure tools with unmatched industry performance that streamlines AI workflows.Get started today and let us know what products you are interested in. We're rolling out access as fast as we can.Next\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Inference Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuThe world's fastest unified AI inference engine. Get  models into production, faster.The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions. Bring your model as-is and deploy it anywhere, across server and edge, with unparalleled usability and performance.Get startedSee our performanceengine P99 Latency: 12.1 ms *P50P90P95P99TensorFlowPyTorchModular Engine* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size101UnificationTrain in any framework, deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude.Cloud & On-PremFrameworksmodular EngineServer & edgeFramework optionalityEasily deploy models trained in any framework, such as TensorFlow or PyTorch, without retraining, conversions or pre-optimization steps, using a unified set of APIs. There are no tricks, no hacks - the Engine just works incredibly fast.Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models. Avoid lock-in and take advantage of price efficiencies and performance improvements without migration costs.02PerformanceMaximize performance, minimize costsReduce latency, increase throughput, and improve resource efficiency across CPUs, GPUs, and accelerators. Productionize larger models and significantly reduce your computing costs.Explore our performance dashboardQueries per Second *125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences *$ 0.12TensorFlow$0.89PyTorch$0.54Modular Engine$0.12* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size1MODULAR ENGINE SPEED-UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family  vs  vs  vs  vs  vs  vsLanguage Model3x3.2x5.3x1.4x2.1x4xRecommender Models6.5x5x7.5x1.1x1.2x4.3xVision Models2.1x2.2x1.7x1.5x1.5x1.3xCompute TypeIntel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)Intel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)ResultsAWS Compute Instances. TensorFlow & PyTorch listed by logo. Full performance & methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again. Run any model, including support for all native framework operators, dynamic shapes, low-precision, and your existing custom operators.DLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseBERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases. Our tools are... well... modular. They integrate with industry-standard infrastructure and open-source tools to minimize migration cost.Request accessseamless integration with popular libraries and tools01.Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular's off-the-shelf NVIDIA Triton and TensorFlow-Serving builds.02.Choose your cloudDeploy the engine on-prem, in your own VPC on any major cloud provider, or get up and running quicker with out hosted solutions.03.METRICS & MONITORINGThe Modular Inference Engine works with industry-standard open-source tooling like Prometheus and Grafana.Ready to try a preview?Contact us to get early-access to the Modular Inference Engine.Request accessAPI References, Tutorials, & MoreRead the Modular Inference Engine docs\n",
      "\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Mojo 🔥: Programming language for all of AI\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuMojo 🔥 — a new programming language for all AI developers.Mojo combines the usability of Python with the performance of C, unlocking unparalleled programmability of AI hardware and extensibility of AI models.Get started with MojoRead the docs\n",
      "\n",
      "\n",
      "\n",
      "SOFTMAX.PYMojo 🔥\n",
      "\n",
      "\n",
      "pythondef softmax(lst):\n",
      "  norm = np.exp(lst - np.max(lst))\n",
      "  return norm / norm.sum()def softmax(lst):\n",
      "  norm = np.exp(lst - np.max(lst))\n",
      "  return norm / norm.sum()\n",
      "\n",
      "struct NDArray:\n",
      "  def max(self) -> NDArray:\n",
      "    return self.pmap(SIMD.max)\n",
      "\n",
      "struct SIMD[type: DType, width: Int]:\n",
      "  def max(self, rhs: Self) -> Self:\n",
      "    return (self >= rhs).select(self, rhs)01Usability & ProgrammabilityWrite everything in one languageWrite Python or scale all the way down to the metal. Program the multitude of low-level AI hardware. No C++ or CUDA required.Take a tour of Mojo\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def sort(v: ArraySlice[Int]):\n",
      "  for i in range(len(v)):\n",
      "    for j in range(len(v) - i - 1):\n",
      "      if v[j] > v[j + 1]:\n",
      "        swap(v[j], v[j + 1])FILE_NAME.🔥\n",
      "struct MyPair:\n",
      "  var first: Int\n",
      "  var second: F32\n",
      "  \n",
      "  def __init__(self, first: Int, second: F32):\n",
      "    self.first = first\n",
      "    self.second = secondFILE_NAME.🔥\n",
      "def reorder_and_process(owned x: HugeArray):\n",
      "  sort(x)\t# Update in place\n",
      "  \n",
      "  give_away(x^)\t# Transfer ownership\n",
      "  \n",
      "  print(x[0])\t# Error: ‘x’ moved away!FILE_NAME.🔥\n",
      "def exp[dt: DType, elts: Int]\n",
      "    (x: SIMD[dt, elts]) -> SIMD[dt, elts]:\n",
      "  x = clamp(x, -88.3762626647, 88.37626266)\n",
      "  k = floor(x * INV_LN2 + 0.5)\n",
      "  r = k * NEG_LN2 + x\n",
      "  return ldexp(_exp_taylor(r), k)FILE_NAME.🔥\n",
      "def exp_buffer[dt: DType](data: ArraySlice[dt]):\n",
      "\n",
      "  # Search for the best vector length\n",
      "  alias vector_len = autotune(1, 4, 8, 16, 32)\n",
      "  \n",
      "  # Use it as the vectorization length\n",
      "  vectorize[exp[dt, vector_len]](data)Features include:Progressive TypesLeverage types for better performance and error checking.Zero Cost AbstractionsTake control of storage by inline-allocating values into structures.Ownership + borrow checkerTake advantage of memory safety without the rough edges.Portable parametric algorithmsLeverage compile-time meta-programming to write hardware-agnostic algorithms and reduce boilerplate.LANGUAGE INTEGRATED Auto-tuningAutomatically find the best values for your parameters to take advantage of target hardware.As well as:The full power of MLIRParallel heterogenous runtimeFast compile times\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def sort(v: ArraySlice[Int]):\n",
      "  for i in range(len(v)):\n",
      "    for j in range(len(v) - i - 1):\n",
      "      if v[j] > v[j + 1]:\n",
      "        swap(v[j], v[j + 1])Features include:Progressive TypesLeverage types for better performance and error checking.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "struct MyPair:\n",
      "  var first: Int\n",
      "  var second: F32\n",
      "  \n",
      "  def __init__(self, first: Int, second: F32):\n",
      "    self.first = first\n",
      "    self.second = secondFeatures include:Zero Cost AbstractionsTake control of storage by inline-allocating values into structures.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def reorder_and_process(owned x: HugeArray):\n",
      "  sort(x)\t# Update in place\n",
      "  \n",
      "  give_away(x^)\t# Transfer ownership\n",
      "  \n",
      "  print(x[0])\t# Error: ‘x’ moved away!Features include:Ownership + borrow checkerTake advantage of memory safety without the rough edges.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def exp[dt: DType, elts: Int]\n",
      "    (x: SIMD[dt, elts]) -> SIMD[dt, elts]:\n",
      "  x = clamp(x, -88.3762626647, 88.37626266)\n",
      "  k = floor(x * INV_LN2 + 0.5)\n",
      "  r = k * NEG_LN2 + x\n",
      "  return ldexp(_exp_taylor(r), k)Features include:Portable parametric algorithmsLeverage compile-time meta-programming to write hardware-agnostic algorithms and reduce boilerplate.\n",
      "\n",
      "\n",
      "\n",
      "FILE_NAME.🔥\n",
      "def exp_buffer[dt: DType](data: ArraySlice[dt]):\n",
      "\n",
      "  # Search for the best vector length\n",
      "  alias vector_len = autotune(1, 4, 8, 16, 32)\n",
      "  \n",
      "  # Use it as the vectorization length\n",
      "  vectorize[exp[dt, vector_len]](data)Features include:LANGUAGE INTEGRATED Auto-tuningAutomatically find the best values for your parameters to take advantage of target hardware.02PerformanceUnlock Python performanceUtilize the full power of the hardware, including multiple cores, vector units, and exotic accelerator units, with the world's most advanced compiler and heterogenous runtime. Achieve performance on par with C++ and CUDA without the complexity.Play with MojoParallelizationMojo leverages MLIR, which enables Mojo developers to take advantage of vectors, threads, and AI hardware units.PYTHONSingle-threaded executionMojo 🔥Parallel processing across multiple coresLanguagesTime (S) *Speedup vs PythonPython 3.10.91027 s1xPypy46.1 s22xScalar C++0.20 s5000xMojo 🔥0.03 s35000x* AlgorithmMandelbrotInstanceAWS r7iz.metal-16xlIntel Xeon03InteroperabilityAccess the entire Python ecosystemExperience true interoperability with the Python ecosystem. Seamlessly intermix arbitrary libraries like Numpy and Matplotlib and your custom code with Mojo.Read the programming manual\n",
      "\n",
      "\n",
      "\n",
      "MAKE_PLOT.🔥def make_plot(m: Matrix):\n",
      "  plt = Python.import_module(\"matplotlib.pyplot\")\n",
      "  fig = plt.figure(1, [10, 10 * yn // xn], 64)\n",
      "  ax = fig.add_axes([0.0, 0.0, 1.0, 1.0], False, 1)\n",
      "  plt.imshow(image)\n",
      "  plt.show()\n",
      "\n",
      "make_plot(compute_mandelbrot())Mojo 🔥04ExtensibilityUpgrade your models and the Modular stackEasily extend your models with pre and post-processing operations, or replace operations with custom ones. Take advantage of kernel fusion, graph rewrites, shape functions, and more.Model extensibilityMojo can upgrade the existing operations in your model.Input layerHidden layersOutput layer05GET STARTED NOWTry Mojo 🔥 out right now in our PlaygroundMojo is still a work in progress, but it's available to try today in our JupyterHub-based Playground. Run through tutorials and write your own Mojo code.Sign up for accessMojo 🔥01.EASY TO GET STARTEDWe have plenty of easy-to-use Jupyter notebooks to help you get started learning Mojo 🔥.02.Unleash your mojoOur docs will help you quickly discover why Mojo is such a powerful extension to Python, and the future of AI programming.03.JOIN the mojo COMMUNITYCome and chat with us on our Discord, and help shape the future of the language as we continue to develop it.Ready to play with Mojo?Reach out to gain access to the Mojo Playground.Request accessAPI Reference, Tutorials, & MoreRead the Mojo docs\n",
      "\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Hardware Developers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuUnlock your hardware design with software that provides generality and usability for AI developers.Modular's software stack will take care of all upstream integrations with AI frameworks, graph optimizations, and more, so you can focus on the differentiating features of your hardware. Own your code generation, performance and feature set. It's still early, but we're excited about the future.Contact us nowLearn how it works01BenefitsIntegrating with the Modular stack gets you:01.Access to all AI frameworksEffortlessly extend your customer reach to all popular AI frameworks.02.Better performanceAutofusion and graph optimizations boost your hardware performance.03.Full compatibilityWe support the ever-changing AI ecosystem, including the long-tail of operators and models.04.Market DifferentiationYou own your performance and can utilize the full capabilities of your hardware.05.Faster time to marketYour hardware “just works” often with only a few weeks of development.02How it worksIntegration is simple\n",
      "\n",
      "\n",
      "FrameworksModular handles integration & packagingend-user tools\n",
      "\n",
      "\n",
      "Modular engineModular handles offload, kernel fusion, compilation,, caching, & developer tools\n",
      "\n",
      "\n",
      "Your Compiler + KernelsYou provide LLVM or MLIR code generation, and extend the stack with Mojo 🔥 kernelsyour HardwareYou design the hardware and have in-house expertise03Modern AI EngineModular handles framework support and end-user toolingModular handles the ever-changing world of AI frameworks, models, and operators, providing you with a single cross-framework integration point for your hardware stack.Full framework, model, and op supportIntegration with TensorFlow, PyTorch, plus variants like ONNX and TorchScriptFull generality of models, including dynamic shapes, sparsity, custom ops, etc.Thousands of long-tail operators needed for compatibilityCompiler transformations and developer toolingKernel fusion and other performance optimizationsAutomatic graph partitioning for distributed inferenceStandardized and hackable tools04IntegrationPlug your hardware in at the graph or code generation levelBring your own code gen backend for CPU, GPU, or DSPs, and everything just works. For CGRA, FPGA, or other exotic hardware, start with our standardized operator set and extend the system to your needs.Focus your effort on ML operators you care aboutModular provides a library of customizable kernels and microkernels written in Mojo 🔥Focus on the subset of the problem for your hardwareEverything else just works — we provide fallback legacy long-tail kernels for compatibilityExtend the systemas neededAdd new Mojo 🔥 kernels if you don’t find what you’re looking for, and enable your customers to the sameUse Mojo 🔥 to directly inject MLIR, C/C++ or assembly code as neededLeverage standardized operators and tools to write high-level graph transformationsInterested in partnering with us?Contact us to discuss how we can work together.Contact UsAPI Reference, Guides, & MoreLearn more about our platform\n",
      "\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Inference Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuThe world's fastest unified AI inference engine. Get  models into production, faster.The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions. Bring your model as-is and deploy it anywhere, across server and edge, with unparalleled usability and performance.Get startedSee our performanceengine P99 Latency: 12.1 ms *P50P90P95P99TensorFlowPyTorchModular Engine* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size101UnificationTrain in any framework, deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude.Cloud & On-PremFrameworksmodular EngineServer & edgeFramework optionalityEasily deploy models trained in any framework, such as TensorFlow or PyTorch, without retraining, conversions or pre-optimization steps, using a unified set of APIs. There are no tricks, no hacks - the Engine just works incredibly fast.Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models. Avoid lock-in and take advantage of price efficiencies and performance improvements without migration costs.02PerformanceMaximize performance, minimize costsReduce latency, increase throughput, and improve resource efficiency across CPUs, GPUs, and accelerators. Productionize larger models and significantly reduce your computing costs.Explore our performance dashboardQueries per Second *125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences *$ 0.12TensorFlow$0.89PyTorch$0.54Modular Engine$0.12* ModelDLRM RMC1InstanceAWS c6g.4xlarge (Graviton2)Batch Size1MODULAR ENGINE SPEED-UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family  vs  vs  vs  vs  vs  vsLanguage Model3x3.2x5.3x1.4x2.1x4xRecommender Models6.5x5x7.5x1.1x1.2x4.3xVision Models2.1x2.2x1.7x1.5x1.5x1.3xCompute TypeIntel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)Intel (c5.4xlarge)AMD (c5a.4xlarge)ARM (c6g.4xlarge)ResultsAWS Compute Instances. TensorFlow & PyTorch listed by logo. Full performance & methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again. Run any model, including support for all native framework operators, dynamic shapes, low-precision, and your existing custom operators.DLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseDLRM RMC1 (multi-hot support)RoBERTa-baseGPT-2BERT-large-uncasedDLRM RMC2 (multi-hot support)RoBERTa-baseBERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch14BERT-base-uncasedDLRM RMC1 (multi-hot support)GPT-2BERT-large-uncasedDLRM RMC2CLIP-ViT-large-patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases. Our tools are... well... modular. They integrate with industry-standard infrastructure and open-source tools to minimize migration cost.Request accessseamless integration with popular libraries and tools01.Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular's off-the-shelf NVIDIA Triton and TensorFlow-Serving builds.02.Choose your cloudDeploy the engine on-prem, in your own VPC on any major cloud provider, or get up and running quicker with out hosted solutions.03.METRICS & MONITORINGThe Modular Inference Engine works with industry-standard open-source tooling like Prometheus and Grafana.Ready to try a preview?Contact us to get early-access to the Modular Inference Engine.Request accessAPI References, Tutorials, & MoreRead the Modular Inference Engine docs\n",
      "\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Get started today\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Get started todayModular is a fully integrated, composable suite of AI infrastructure tools with unmatched industry performance that streamlines AI workflows.Get started today and let us know what products you are interested in. We're rolling out access as fast as we can.Next\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Blog\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuCompanyOur launch & what's nextMay 11, 2023Tim DavisCo-Founder & Chief Product OfficerTim DavisCo-Founder & Chief Product OfficerRead postFeatured postsProductA unified, extensible platform to superpower your AIMay 2, 2023\n",
      "Read postEngineeringThe world's fastest unified matrix multiplicationApril 20, 2023\n",
      "Read postBrowse all postsCompanyOur launch & what's nextMay 11, 2023|\n",
      "ProductA unified, extensible platform to superpower your AIMay 2, 2023|\n",
      "EngineeringThe world's fastest unified matrix multiplicationApril 20, 2023|\n",
      "EngineeringAI’s compute fragmentation: what matrix multiplication teaches usMarch 23, 2023|\n",
      "CompanyWe want to hear from youDecember 15, 2022|\n",
      "EngineeringIf AI serving tech can’t solve today’s problems, how do we scale into the future?December 8, 2022|\n",
      "EngineeringPart 2: Increasing development velocity of giant AI modelsNovember 10, 2022|\n",
      "CompanyModular is rebuilding AI in the face of a new economyNovember 8, 2022|\n",
      "DesignModular's Brand StoryAugust 18, 2022|\n",
      "EngineeringIncreasing development velocity of giant AI modelsAugust 12, 2022|\n",
      "CompanyThe Case for a Next-Generation AI Developer PlatformJune 30, 2022|\n",
      "CultureHow we workMay 21, 2022|\n",
      "CompanyThe future of AI depends on ModularityApril 26, 2022|\n",
      "\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Careers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuPlayJoin us in building the future of AISee open rolesRead about our cultureWe want to enable AI to be used by anyone, anywhere. Our ambitions are enormous, but working here will feel very familiar. You can change the world without giving up your lifeWhy Modular?Grow with the bestBuild with some of the industry's best AI leaders.Maximize how you workWe will always push the limits to create the best possible environment for our people and teams. Read how we work.Build AI for the worldBuild a next-generation developer platform, with production quality infrastructure, for the world.Have fun, live lifeRegular team onsites, local meetups & fun, strong team collaboration and more.Work & life, balanced1Leading medical, dental and vision packages2Strong compensation & equity packages3Generous maternity & paternity leave4401K Plan5Work wherever you want6Unlimited Vacation & PTO7Corporate perks & epic team fun8Great set upWorking at ModularWe believe in a thoughtful framework to family, compensation, growth, and mission - each of these elements is critical to anyone living a balanced and fulfilling life. We want to ensure that you have a place to achieve the right mix.We’re trusting & empoweringWe trust that you will hold our values and standards. This means we don't micromanage you.We write things downThis is key to being asynchronous. It allows real-time discussions to be more thoughtful and contextually driven.We have levelsWe acknowledge levels of experience upfront and have a transparent and well-defined leveling system.Learn about usI am truly impressed with the collective experience of the Modular team in building some of the industry’s most widely used AI systems and tools. And humbled and excited to be part of this team in our journey to build the next generation AI platform and infrastructure for the world.Amit AgarwalCloud Infrastructure LeadI picked modular because of the people and what they believe in and what they want to do. I want to be a part of something that makes a difference for the better.Paige BedwellProgram ManagerI joined because there is literally no better team on the planet to rebuild AI. It's a once in a lifetime opportunity.\n",
      "I'm building for the world, and working with the best.River RiddleAI Compiler EngineerWe are a set of world class engineers and leaders who really deeply understand this problem, and have solved it to varying degrees of success before. Now we are committed to solving it the right way.Aman LaChapelleAI Compiler EngineerThe team is incredible. They're very smart. They're experts in their field, and we're solving the hardest computational problems in the world.Abdul DakkakAI Compiler EngineerThe best part of working here is a strong commitment to culture. I work on the most challenging problems, have the freedom to do it anywhere, and have a huge impact on AI.Eric JohnsonProduct LeadJoin our teamCome and be part of a world-class team that is rebuilding AI for everyone. We welcome applications from all backgrounds and communities.\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Terms of Service\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuTerms of UseLast Updated: May 2nd, 2023These Terms of Use (this “Agreement”), effective as of the date on which you check a box, click a button, or otherwise acknowledge your acceptance of this Agreement, is by and between Modular Inc. with offices located at 228 Hamilton Ave, Palo Alto, CA 94301, USA (“Modular”, “we”, or “us”) and you. This Agreement constitutes a binding contract between you and Modular, and your use of the Platform (as defined below) is at all times subject to the terms and conditions outlined in this Agreement. This Agreement incorporates by reference all other terms and policies governing your use of the Platform, including our Privacy Policy (https://www.modular.com/privacy), Acceptable Use Policy (https://www.modular.com/legal/use), as well as any other policies we may adopt from time to time. 1. Definitions\"Account\" means the account you set up to access the Platform, and represents your legal and services relationship with Modular. “Code” means any software code that you write, develop, or otherwise import for use on the Platform.  “Derivative Data” means data and information related to or derived from Users of the Platform that has been aggregated and/or anonymized by Modular, including any metrics, feedback, and ratings relating to any Code.“Developer” means a User who wrote or otherwise contributed to Code. “Harmful Code” means any software, hardware, or other technology, device, or means, including any virus, worm, malware, or other malicious computer code, the purpose or effect of which is to permit unauthorized access to, or to destroy, disrupt, disable, distort, or otherwise harm or impede in any manner any (i) computer, software, firmware, hardware, system, or network; or (ii) any application or function of any of the foregoing or the security, integrity, confidentiality, or use of any data processed thereby.“Modular IP” means the Platform are and any and all intellectual property provided to you or any other User in connection with the foregoing. For the avoidance of doubt, Modular IP includes Derivative Data and any information, data, or other content derived from Modular’s provision of the Platform but does not include User Generated Content.  “Platform” means Modular’s proprietary, hosted software platform, and other website functionality as made available to Users from time to time at www.modular.com (or a successor, or sub-site). “Third-Party Products” means any third-party products provided with, integrated with, or incorporated into the Platform.“User,” “you,” and “your” refer to the individual person, company, or organization that has visited or is using the Platform; that accesses or uses any part of an Account; or that directs the use of the Account in the performance of its functions. A User must be at least 18 years of age.“User Generated Content” means information, data, and other content, in any form or medium, that is submitted, posted, or otherwise transmitted by a User through the Platform, including any Code; provided that, for purposes of clarity, User Generated Content as defined herein does not include Derivative Data.2. Account Registration and RequirementsRegistration. You must provide a valid email address in order to complete the Account signup process. Account registration and provisioning is at Modular’s sole discretion, and signing up for our waitlist does not guarantee that you will be eligible for account registration. RequirementsYou must be a human to create an Account. Accounts registered by \"bots\" or other automated methods are not permitted. You must be age 18 or older. The Children’s Online Privacy Protection Act (“COPPA”) requires that online service providers obtain parental consent before they knowingly collect personally identifiable information online from children who are under thirteen (13). We do not knowingly collect or solicit personally identifiable information from children under thirteen (18). Users under the age of 18 are not permitted to use Modular. Modular does not target its Platform to children under 18, and we do not permit any Users under 18 on our Platform. If we learn of any User under the age of 18, we will terminate that User’s Account immediately.Your login may only be used by one person. You may not share your Account with others, and you may not use anyone else’s Account.Account Security. You are responsible for keeping your Account secure while you use the Platform. We offer tools to help you maintain your Account's security, but the content of your Account and its security are your responsibility. You are responsible for all content posted and activity that occurs under your Account (even when content is posted by others who have Accounts under your Account). You are responsible for maintaining the security of your Account and password. Modular cannot and will not be liable for any loss or damage from your failure to comply with this security obligation. You will promptly notify Modular if you become aware of any unauthorized use of, or access to, our Platform through your Account, including any unauthorized use of your password or Account.3. Platform Access and UseSubject to and conditioned on your compliance with the terms and conditions of this Agreement, Modular hereby grants you a right to access and use the Platform on a non-exclusive, non-transferable, and non-sublicensable basis. Your use is limited to personal, non-commercial, internal business purposes.Use Restrictions. You shall not use the Platform for any purposes beyond the scope of the access granted in this Agreement. You shall at all times comply with Modular’s Acceptable Use Policy (https://www.modular.com/privacy).Reservation of Rights. Modular reserves all rights not expressly granted to you in this Agreement. Except for the limited rights and licenses expressly granted under this Agreement, nothing in this Agreement grants, by implication, waiver, estoppel, or otherwise, to you or any third party any intellectual property rights or other right, title, or interest in or to the Modular IP.Suspension. Notwithstanding anything to the contrary in this Agreement, Modular may temporarily suspend your Account and/or access to the Platform if: (i) Modular reasonably determines that (a) there is a threat or attack on any of the Modular IP; (b) your or another User’s use of the Modular IP disrupts or poses a security risk to the Modular IP or to any other User, customer, or vendor of Modular; (c) you are using the Modular IP for fraudulent or illegal activities or in violation of the Acceptable Use Policy; (e) Modular’s provision of the Platform to you is prohibited by applicable law; or (f) any User Generated Content (including any Code) submitted, posted, or otherwise transmitted by you through the Platform may infringe or otherwise violate any third party’s intellectual property or other rights; (ii) any vendor of Modular has suspended or terminated Modular’s access to or use of any Third-Party Products required to enable you to access the Platform; or (iii) in accordance with a violation of any other term of this Agreement (each of (i), (ii), or (iii), a “Service Suspension”). Modular shall use commercially reasonable efforts to provide written notice of any Service Suspension to you and to provide updates regarding resumption of access to the Platform following any Service Suspension. Modular shall use commercially reasonable efforts to resume providing access to the Platform as soon as reasonably possible after the event giving rise to the Service Suspension is cured. Modular will have no liability for any damage, liabilities, losses (including any loss of data or profits), or any other consequences that you or any other User may incur as a result of a Service Suspension. Derivative Data. Notwithstanding anything to the contrary in this Agreement, Modular may monitor your use of the Platform and collect and compile Derivative Data. As between you and Modular, all right, title, and interest in Derivative Data, and all intellectual property rights therein, belong to and are retained solely by Modular. You acknowledges that Modular may compile Derivative Data based on User Generated Content input into and transmitted via the Platform. Notwithstanding anything to the contrary in this Agreement, you further acknowledges that Modular may use and disclose Derivative Data for any lawful purpose.4. User ResponsibilitiesGeneral. You are at all times responsible and liable for all uses of the Platform resulting from access from your Account, directly or indirectly, whether such access or use is permitted by or in violation of this Agreement. User Generated Content. You shall not upload to the Platform any User Generated Content that you do not have sufficient rights to upload. You hereby represent and warrant that you have sufficient rights to use any Code you upload to or otherwise use or incorporate as part of the Platform. You shall at all times abide by and comply with the Modular Acceptable Use Policy (https://www.modular.com/terms). You hereby grant to Modular a non-exclusive, royalty-free, worldwide license to reproduce, distribute, and otherwise use and display your User Generated Content and perform all acts with respect to your User Generated Content as may be necessary for Modular to provide the Platform, and a non-exclusive, perpetual, irrevocable, royalty-free, worldwide license to reproduce, distribute, modify, and otherwise use and display your User Generated Content incorporated within the Derivative Data, and as otherwise necessary to provide you with Platform functionality.Third-Party Products. Modular may from time to time make Third-Party Products available to you or may allow for certain Third-Party Products to be integrated with the Platform to allow for the transmission of Code or other User Generated Content from such Third-Party Products into the Platform (including, for example and without limitation, Github, AWS Code Commit, BitBucket, etc.). For purposes of this Agreement, such Third-Party Products are subject to their own terms and conditions. Modular is not responsible for the operation of any Third-Party Products and makes no representations or warranties of any kind with respect to Third-Party Products or their respective providers. If you do not agree to abide by the applicable terms for any such Third-Party Products, then you should not install or use such Third-Party Products. By authorizing Modular to transmit your User Generated Content from Third-Party Products into the Platform, you represent and warrant to Modular that you have all right, power, and authority to provide such authorization.User Controls and Responsibility. You have and will retain sole responsibility for: (i) all your own User Generated Content; (ii) your technology infrastructure and network and internet connection(s) from which you access the Platform; (iii) the security and use of your Account and associated credentials; and (iv) all access to and use of the Platform, including all results obtained from, and all conclusions, decisions, and actions based on, such access or use.5. Account FeesYou may access the Platform for free, or we may charge a fee for using the Platform (the “Paid Services”).Paid Platform Access. Certain aspects of features of the Platform may be subject to payments now or in the future (“Account Fees”). Payment Processor. We use a third-party payment processor (the “Payment Processor”) to bill you through a payment account linked to your Account on the Platform (your “Billing Account”) for any owed Account Fees. The processing of payments will be subject to the terms, conditions and privacy policies of the Payment Processor in addition to this Agreement.Payment Method. The terms of your payment will be based on your Payment Method and may be determined by agreements between you and the financial institution, credit card issuer or other provider of your chosen Payment Method. If we, through the Payment Processor, do not receive payment from you, you agree to pay all amounts due on your Billing Account upon demand.Recurring Billing. Some of the Paid Services may consist of an initial period, for which there is a one-time charge, followed by recurring period charges as agreed to by you. By choosing a recurring payment plan, you acknowledge that such Paid Services have an initial and recurring payment feature and you accept responsibility for all recurring charges prior to cancellation. WE MAY SUBMIT PERIODIC CHARGES (E.G., MONTHLY) WITHOUT FURTHER AUTHORIZATION FROM YOU, UNTIL YOU PROVIDE PRIOR NOTICE (RECEIPT OF WHICH IS CONFIRMED BY US) THAT YOU HAVE TERMINATED THIS AUTHORIZATION OR WISH TO CHANGE YOUR PAYMENT METHOD. SUCH NOTICE WILL NOT AFFECT CHARGES SUBMITTED BEFORE WE REASONABLY COULD ACT. TO TERMINATE YOUR AUTHORIZATION OR CHANGE YOUR PAYMENT METHOD, CONTACT US.Current Information Required. YOU MUST PROVIDE CURRENT, COMPLETE AND ACCURATE INFORMATION FOR YOUR BILLING ACCOUNT. YOU MUST PROMPTLY UPDATE ALL INFORMATION TO KEEP YOUR BILLING ACCOUNT CURRENT, COMPLETE AND ACCURATE (SUCH AS A CHANGE IN BILLING ADDRESS, CREDIT CARD NUMBER, OR CREDIT CARD EXPIRATION DATE), AND YOU MUST PROMPTLY NOTIFY US OR OUR PAYMENT PROCESSOR IF YOUR PAYMENT METHOD IS CANCELED (E.G., FOR LOSS OR THEFT) OR IF YOU BECOME AWARE OF A POTENTIAL BREACH OF SECURITY, SUCH AS THE UNAUTHORIZED DISCLOSURE OR USE OF YOUR USER NAME OR PASSWORD. CHANGES TO SUCH INFORMATION CAN BE MADE AT ACCOUNT SETTINGS BY CONTACTING US. IF YOU FAIL TO PROVIDE ANY OF THE FOREGOING INFORMATION, YOU AGREE THAT WE MAY CONTINUE CHARGING YOU FOR ANY USE OF PAID SERVICES UNDER YOUR BILLING ACCOUNT UNLESS YOU HAVE TERMINATED YOUR PAID SERVICES AS SET FORTH ABOVE.Change in Amount Authorized. If the amount to be charged to your Billing Account varies from the amount you preauthorized (other than due to the imposition or change in the amount of state sales taxes), you have the right to receive, and we shall provide, notice of the amount to be charged and the date of the charge before the scheduled date of the transaction. Any agreement you have with your payment provider will govern your use of your Payment Method. You agree that we may accumulate charges incurred and submit them as one or more aggregate charges during or at the end of each billing cycle.Reaffirmation of Authorization. Your non-termination or continued use of a Paid Service reaffirms that we are authorized to charge your Payment Method for that Paid Service. We may submit those charges for payment and you will be responsible for such charges. This does not waive our right to seek payment directly from you. Your charges may be payable in advance, in arrears, per usage, or as otherwise described when you initially selected to use the Paid Service. Free Trials and Other Promotions. Any free trial or other promotion that provides access to a Paid Service must be used within the specified time of the trial. You must stop using a Paid Service before the end of the trial period in order to avoid being charged for that Paid Service. If you cancel prior to the end of the trial period and are inadvertently charged for a Paid Service, please contact us at hello@modular.com.6. ConfidentialityYour Confidentiality Obligations. You agree that any non-public information we give you, such as information about a private beta offering or any information or materials made available on non-public portions of the Platform, is Modular’s confidential information, regardless of whether it is marked or identified as such (collectively, “Confidential Information”). You agree to only use such Confidential Information for the express purpose of testing and evaluating such beta products and not for any other purpose. You should use the same degree of care as you would with your own confidential information, but no less than reasonable precautions to prevent any unauthorized use, disclosure, publication, or dissemination of our Confidential Information. You promise not to disclose, publish, or disseminate any Confidential Information to any third party, unless we don’t otherwise prohibit or restrict such disclosure (for example, you might be part of a Modular-organized group discussion about a private beta feature).Exceptions. Confidential Information will not include information that is: (a) or becomes publicly available without breach of this Agreement through no act or inaction on your part (such as when a private beta feature becomes part of our publicly offered Platform); (b) known to you before we disclose it to you; (c) independently developed by you without breach of any confidentiality obligation to us or any third party; or (d) disclosed with permission from Modular. You will not violate the terms of this Agreement if you are required to disclose Confidential Information pursuant to operation of law, provided Modular has been given reasonable advance written notice to object, unless prohibited by law.7. Data Security and Processing of personal InformationSecurity Measures. Modular will implement and maintain commercially reasonable administrative, physical, and technical safeguards designed to protect applicable User Generated Content from unauthorized access, use, alteration or disclosure. Processing of Personal Information; No Sensitive Data. Modular’s rights and obligations with respect to Personal Information that it collects directly from you are set forth in Modular’s Privacy Policy (https://www.modular.com/privacy). 8. Intellectual Property Ownership; Feedback.Modular IP. You acknowledge that, as between you and Modular, Modular owns all right, title, and interest, including all intellectual property rights, in and to the Modular IP and, with respect to Third-Party Products, the applicable third-party providers own all right, title, and interest, including all intellectual property rights, in and to the Third-Party Products. Your User Generated Content. Modular acknowledges that, as between you and Modular, you and your licensors (if any) retain all right, title, and interest, including all intellectual property rights, in and to User Generated Content.Feedback. If you sends us any communications or materials by mail, email, telephone, or otherwise, suggesting or recommending changes to the Modular IP, including without limitation, new features or functionality relating thereto, or any comments, questions, suggestions, or the like (“Feedback”), Modular is free to use such Feedback.9. Warranty DisclaimerMODULAR AND ITS LICENSORS, SUPPLIERS, PARTNERS, PARENT, SUBSIDIARIES OR AFFILIATED ENTITIES, AND EACH OF THEIR RESPECTIVE OFFICERS, DIRECTORS, MEMBERS, EMPLOYEES, CONSULTANTS, CONTRACT EMPLOYEES, REPRESENTATIVES AND AGENTS, AND EACH OF THEIR RESPECTIVE SUCCESSORS AND ASSIGNS (MODULAR AND ALL SUCH PARTIES TOGETHER, THE “MODULAR PARTIES”) MAKE NO REPRESENTATIONS OR WARRANTIES CONCERNING THE MODULAR IP, AND THE MODULAR PARTIES WILL NOT BE RESPONSIBLE OR LIABLE FOR THE ACCURACY, AVAILABILITY, OCCURRENCE OF ERRORS, COPYRIGHT COMPLIANCE, LEGALITY, OR DECENCY OF MATERIAL CONTAINED IN OR ACCESSED THROUGH THE PLATFORM OR ANY CLAIMS, ACTIONS, SUITS PROCEDURES, COSTS, EXPENSES, DAMAGES OR LIABILITIES ARISING OUT OF USE OF, OR IN ANY WAY RELATED TO YOUR ACCESS OF THE PLATFORM OR USE OF ANY MODULAR IP. THE MODULAR PARTIES MAKE NO REPRESENTATIONS OR WARRANTIES REGARDING SUGGESTIONS OR RECOMMENDATIONS OFFERED THROUGH OR IN CONNECTION WITH YOUR USE OF THE PLATFORM. THE MODULAR IP IS PROVIDED BY MODULAR (AND ITS LICENSORS AND SUPPLIERS) ON AN “AS-IS” BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING, WITHOUT LIMITATION, IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, OR THAT USE OF THE MODULAR IP WILL BE UNINTERRUPTED OR ERROR-FREE. SOME STATES DO NOT ALLOW LIMITATIONS ON HOW LONG AN IMPLIED WARRANTY LASTS, SO THE ABOVE LIMITATIONS MAY NOT APPLY TO YOU.10. IndemnificationYou agree to indemnify and hold the Modular Parties harmless from and against any and all claims, liabilities, damages (actual and consequential), losses and expenses (including attorneys’ fees) arising from or in any way related to any claims relating to (a) your use of the Modular IP (including any actions taken by a third party using your Account), and (b) your violation or breach of any of the terms of this Agreement. In the event of such a claim, suit, or action (“Claim”), we will attempt to provide notice of the Claim to the contact information we have for your Account (provided that failure to deliver such notice shall not eliminate or reduce your indemnification obligations hereunder).11. Limitation of LiabilityTO THE FULLEST EXTENT ALLOWED BY APPLICABLE LAW, UNDER NO CIRCUMSTANCES AND UNDER NO LEGAL THEORY (INCLUDING, WITHOUT LIMITATION, TORT, CONTRACT, STRICT LIABILITY, OR OTHERWISE) SHALL ANY OF THE MODULAR PARTIES BE LIABLE TO YOU OR TO ANY OTHER PERSON FOR (A) ANY INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE OR CONSEQUENTIAL DAMAGES OF ANY KIND, INCLUDING DAMAGES FOR LOST PROFITS, BUSINESS INTERRUPTION, LOSS OF DATA, LOSS OF GOODWILL, WORK STOPPAGE, ACCURACY OF RESULTS, OR COMPUTER FAILURE OR MALFUNCTION, (B) ANY SUBSTITUTE GOODS, SERVICES OR TECHNOLOGY, (C) ANY AMOUNT, IN THE AGGREGATE, IN EXCESS OF THE GREATER OF (I) ONE-HUNDRED ($100) DOLLARS OR (II) THE AMOUNTS PAID AND/OR PAYABLE BY YOU TO MODULAR IN CONNECTION WITH THE ACCOUNT FEES FOR THE PLATFORM IN THE TWELVE (12) MONTH PERIOD PRECEDING THIS APPLICABLE CLAIM OR (D) ANY MATTER BEYOND OUR REASONABLE CONTROL. SOME STATES DO NOT ALLOW THE EXCLUSION OR LIMITATION OF INCIDENTAL OR CONSEQUENTIAL OR CERTAIN OTHER DAMAGES, SO THE ABOVE LIMITATION AND EXCLUSIONS MAY NOT APPLY TO YOU.12. GeneralAssignment. You may not assign, delegate or transfer this Agreement or your rights or obligations hereunder, or your Account, in any way (by operation of law or otherwise) without Modular’s prior written consent. We may transfer, assign, or delegate this Agreement and our rights and obligations without consent.Choice of Law. This Agreement are governed by and will be construed under the Federal Arbitration Act, applicable federal law, and the laws of the State of California, without regard to the conflicts of laws provisions thereof.Miscellaneous. The failure of Modular to exercise, in any way, any right herein shall not be deemed a waiver of any further rights hereunder. If any provision of this Agreement is found to be unenforceable or invalid, that provision will be limited or eliminated, to the minimum extent necessary, so that this Agreement shall otherwise remain in full force and effect and enforceable. You and Modular agree that this Agreement is the complete and exclusive statement of the mutual understanding between you and Modular, and that the terms contained herein supersede and cancel all previous written and oral agreements, communications and other understandings relating to the subject matter of this Agreement. Except for changes by us as described here, no other amendment or modification of these Terms will be effective unless in writing and signed by both you and Modular. You hereby acknowledge and agree that you are not an employee, agent, partner, or joint venturer of Modular, and you do not have any authority of any kind to bind Modular in any respect whatsoever. Arbitration Agreement. Please read the following ARBITRATION AGREEMENT carefully because it requires you to arbitrate certain disputes and claims with Modular and limits the manner in which you can seek relief from Modular. Both you and Modular acknowledge and agree that for the purposes of any dispute arising out of or relating to the subject matter of this Agreement, Modular's officers, directors, employees and independent contractors (“Representatives”) are third-party beneficiaries of this Agreement, and that upon your acceptance of this Agreement, Representatives will have the right (and will be deemed to have accepted the right) to enforce this Agreement against you as the third-party beneficiary hereof.Arbitration Rules; Applicability of Arbitration Agreement. You and Modular shall use best efforts to settle any dispute, claim, question, or disagreement arising out of or relating to the subject matter of this Agreement directly through good-faith negotiations, which shall be a precondition to either party initiating arbitration. If such negotiations do not resolve the dispute, it shall be finally settled by binding arbitration in San Mateo County, California. The arbitration will proceed in the English language, in accordance with the JAMS Streamlined Arbitration Rules and Procedures (the “Rules”) then in effect, by one commercial arbitrator with substantial experience in resolving intellectual property and commercial contract disputes. The arbitrator shall be selected from the appropriate list of JAMS arbitrators in accordance with such Rules. Judgment upon the award rendered by such arbitrator may be entered in any court of competent jurisdiction. Costs of Arbitration. The Rules will govern payment of all arbitration fees. Modular will pay all arbitration fees for claims less than seventy-five thousand ($75,000) dollars. Modular will not seek its attorneys’ fees and costs in arbitration unless the arbitrator determines that your claim is frivolous. Waiver of Jury Trial. YOU AND MODULAR WAIVE ANY CONSTITUTIONAL AND STATUTORY RIGHTS TO GO TO COURT AND HAVE A TRIAL IN FRONT OF A JUDGE OR JURY. You and Modular are instead choosing to have claims and disputes resolved by arbitration. Arbitration procedures are typically more limited, more efficient, and less costly than rules applicable in court and are subject to very limited review by a court. In any litigation between you and Modular over whether to vacate or enforce an arbitration award, YOU AND MODULAR WAIVE ALL RIGHTS TO A JURY TRIAL, and elect instead to have the dispute be resolved by a judge.Waiver of Class or Consolidated Actions. ALL CLAIMS AND DISPUTES WITHIN THE SCOPE OF THIS ARBITRATION AGREEMENT MUST BE ARBITRATED OR LITIGATED ON AN INDIVIDUAL BASIS AND NOT ON A CLASS BASIS. CLAIMS OF MORE THAN ONE USER CANNOT BE ARBITRATED OR LITIGATED JOINTLY OR CONSOLIDATED WITH THOSE OF ANY OTHER USER. If however, this waiver of class or consolidated actions is deemed invalid or unenforceable, neither you nor Modular is entitled to arbitration; instead all claims and disputes will be resolved in a court. Opt-out. You have the right to opt out of the provisions of this Section by sending written notice of your decision to opt out to the following address: Modular, Inc., 228 Hamilton Ave. 3rd Floor Palo Alto, CA 94301 postmarked within thirty (30) days of first accepting this Agreement. You must include (i) your name and residence address, (ii) the email address and/or telephone number associated with your Account, and (iii) a clear statement that you want to opt out of this Agreement’s arbitration agreement.Exclusive Venue. If you send the opt-out notice in (e), and/or in any circumstances where the foregoing arbitration agreement permits either you or Modular to litigate any dispute arising out of or relating to the subject matter of this Agreement in court, then the foregoing arbitration agreement will not apply to either party, and both you and Modular agree that any judicial proceeding (other than small claims actions) will be brought in the state or federal courts located in, respectively, San Mateo County, California, or the federal district in which that county falls. Severability. If the prohibition against class actions and other claims brought on behalf of third parties contained above is found to be unenforceable, then all of the preceding language in this Arbitration Agreement section will be null and void. This arbitration agreement will survive the termination of your relationship with Modular.\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Privacy Policy\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuPrivacy PolicyLast Updated: May 2nd, 2023At Modular, we take your privacy seriously. Please read this Privacy Policy to learn how we treat your personal data. By using or accessing our Platform (as defined in the Terms) or our website, (collectively the “Services”) in any manner, you acknowledge that you accept the practices and policies outlined below, and you hereby consent that we will collect, use and share your information as described in this Privacy Policy. Remember that your use of Modular's Services is at all times subject to our Terms of Use (https://www.modular.com/terms)(collectively the “Terms”). The Terms incorporate this Privacy Policy by reference. Any terms we use in this Privacy Policy without defining them have the definitions given to them in the Terms. We’re constantly trying to improve our Services, so we may need to change this Privacy Policy from time to time, but we will alert you to any such changes by placing a notice on the Modular website, by sending you an email and/or by some other means. Please note that if you’ve opted not to receive legal notice emails from us (or you haven’t provided us with your email address), those legal notices will still govern your use of the Services, and you are still responsible for reading and understanding them. If you use the Services after any changes to the Privacy Policy have been posted, that means you agree to all of the changes. Use of information we collect is subject to the Privacy Policy in effect at the time such information is collected.You may print a copy of this Privacy Policy by clicking print.DefinitionsWhat this Privacy Policy CoversPersonal DataHow We Share Your Personal DataTracking Tools and Opt-OutData Security and RetentionPersonal Data of ChildrenState Law Privacy RightsEuropean Union and United Kingdom Data Subject RightsChanges to this Policy & Contact InformationWhat this Privacy Policy CoversThis Privacy Policy covers how we treat Personal Data that we gather when you access or use our Services. “Personal Data” means any information that identifies or relates to a particular individual and also includes information referred to as “personally identifiable information” or “personal information” under applicable data privacy laws, rules or regulations. This Privacy Policy does not cover the practices of companies we don’t own or control or people we don’t manage. If you are a User of the Platform, note that the “Professional and Employment Related Data” categories of Personal Data collected and shared pursuant to this Privacy Policy are applicable only to users of the website who apply for open job positions with us.  Personal DataCategories of Personal Data We Collect‍This chart details the categories of Personal Data that we collect and have collected over the past 12 months:Category of Personal DataExamples of Personal Data We CollectCategories of Third Parties with whom we share this dataProfile or Contact DataFirst and last name, Email, Unique identifiers such as passwordsService Providers, Advertising Partners, Analytics PartnersPayment DataPayment card type, Last 4 digits of payment card, Billing address, phone number, emailService ProvidersDevice/IP DataIP address, Domain server, Type of device/OS/browser used to access ServicesService Providers, Advertising Partners, Analytics PartnersWeb AnalyticsWeb page interactions, Referring webpage/source, Non-identifiable request IDsService Providers, Advertising Partners, Analytics PartnersSocial Network DataEmail, Phone number, User name, IP address, Device IDService Providers, Advertising Partners, Analytics Partners, Parties you authorizeProfessional or Employment-Related DataJob title, Resume, Job HistoryGeolocation DataIP address based location information, Specific location dataCategories of Sources of Personal DataWe collect Personal Data about you from the following categories of sources:YouWhen you provide such information directly to us - When you create an account or use our interactive tools and Services. When you voluntarily provide information in free-form text boxes through the Services or through responses to surveys or questionnaires. When you send us an email or otherwise contact us.  When you use the Services and such information is collected automatically - Through Cookies (defined in the “Tracking Tools and Opt-Out” section below). If you use a location-enabled browser, we may receive information about your location. If you download and install certain applications and software we make available, we may receive and collect information transmitted from your computing device for the purpose of providing you the relevant Services, such as information regarding when you are logged on and available to receive updates or alert notices.Third PartiesVendors - We may use analytics providers to analyze how you interact and engage with the Services, or third parties may help us provide you with customer support. We may use vendors to obtain information to generate leads and create user profiles.Social Networks - If you provide your social network account credentials to us or otherwise sign in to the Services through a third-party site or service, some content and/or information in those accounts may be transmitted into your account with us.Our Commercial or Business Purposes for Collecting or Disclosing Personal DataProviding, Customizing and Improving the Services - Creating and managing your account or other user profiles. Processing orders or other transactions; billing. Providing you with the products, services or information you request. Meeting or fulfilling the reason you provided the information to us. Providing support and assistance for the Services. Improving the Services, including testing, research, internal analytics and product development. Personalizing the Services, website content and communications based on your preferences. Doing fraud protection, security and debugging. Carrying out other business purposes stated when collecting your Personal Data or as otherwise set forth in applicable data privacy laws, such as the California Consumer Privacy Act, as amended by the California Privacy Rights Act of 2020 (the “CPRA”).Marketing the Services - Marketing and selling the Services.Corresponding with You - Responding to correspondence that we receive from you, contacting you when necessary or requested, and sending you information about Modular or the Services. Sending emails and other communications according to your preferences or that display content that we think will interest you.Meeting Legal Requirements and Enforcing Legal Terms - Fulfilling our legal obligations under applicable law, regulation, court order or other legal process, such as preventing, detecting and investigating security incidents and potentially illegal or prohibited activities. Protecting the rights, property or safety of you, Modular or another party. Enforcing any agreements with you. Responding to claims that any posting or other content violates third-party rights. Resolving disputes.We will not collect additional categories of Personal Data or use the Personal Data we collected for materially different, unrelated or incompatible purposes without providing you notice.How We Share or Disclose Your Personal DataWe disclose your Personal Data to the categories of service providers and other parties listed in this section. Depending on state laws that may be applicable to you, some of these disclosures may constitute a “sale” of your Personal Data. For more information, please refer to the state-specific sections below.Service Providers. These parties help us provide the Services or perform business functions on our behalf. They include: Hosting, technology and communication providers. Security and fraud prevention consultants. Payment processors.Analytics Partners. These parties provide analytics on web traffic or usage of the Services. They include companies that track how users found or were referred to the Services. Companies that track how users interact with the Services.Advertising Partners.Parties You Authorize, Access or Authenticate. Third parties you access through the services. Social media services. Other users.Legal ObligationsWe may share any Personal Data that we collect with third parties in conjunction with any of the activities set forth under “Meeting Legal Requirements and Enforcing Legal Terms” in the “Our Commercial or Business Purposes for Collecting Personal Data” section above. Business Transfers‍All of your Personal Data that we collect may be transferred to a third party if we undergo a merger, acquisition, bankruptcy or other transaction in which that third party assumes control of our business (in whole or in part). Should one of these events occur, we will make reasonable efforts to notify you before your information becomes subject to different privacy and security policies and practices.Data that is Not Personal Data‍We may create aggregated, de-identified or anonymized data from the Personal Data we collect, including by removing information that makes the data personally identifiable to a particular user. We may use such aggregated, de-identified or anonymized data and share it with third parties for our lawful business purposes, including to analyze, build and improve the Services and promote our business, provided that we will not share such data in a manner that could identify you.  Tracking Tools and Opt-OutThe Services use cookies and similar technologies such as pixel tags, web beacons, clear GIFs and JavaScript (collectively, “Cookies”) to enable our servers to recognize your web browser, tell us how and when you visit and use our Services, analyze trends, learn about our user base and operate and improve our Services. Cookies are small pieces of data– usually text files – placed on your computer, tablet, phone or similar device when you use that device to access our Services. We may also supplement the information we collect from you with information received from third parties, including third parties that have placed their own Cookies on your device(s). Please note that because of our use of Cookies, the Services do not support “Do Not Track” requests sent from a browser at this time.We use the following types of Cookies:Essential Cookies. Essential Cookies are required for providing you with features or services that you have requested. For example, certain Cookies enable you to log into secure areas of our Services. Disabling these Cookies may make certain features and services unavailable.Functional Cookies. Functional Cookies are used to record your choices and settings regarding our Services, maintain your preferences over time and recognize you when you return to our Services. These Cookies help us to personalize our content for you, greet you by name and remember your preferences (for example, your choice of language or region).Performance/Analytical Cookies. Performance/Analytical Cookies allow us to understand how visitors use our Services. They do this by collecting information about the number of visitors to the Services, what pages visitors view on our Services and how long visitors are viewing pages on the Services. Performance/Analytical Cookies also help us measure the performance of our advertising campaigns in order to help us improve our campaigns and the Services’ content for those who engage with our advertising. For example, Google LLC (“Google”) uses cookies in connection with its Google Analytics services. Google’s ability to use and share information collected by Google Analytics about your visits to the Services is subject to the Google Analytics Terms of Service and the Google Privacy Policy. You have the option to opt-out of Google’s use of Cookies by visiting the Google advertising opt-out page at www.google.com/privacy_ads.html or the Google Analytics Opt-out Browser Add-on at https://tools.google.com/dlpage/gaoptout/.Retargeting/Advertising Cookies. Retargeting/Advertising Cookies collect data about your online activity and identify your interests so that we can provide advertising that we believe is relevant to you. You can decide whether or not to accept Cookies through your internet browser’s settings. Most browsers have an option for turning off the Cookie feature, which will prevent your browser from accepting new Cookies, as well as (depending on the sophistication of your browser software) allow you to decide on acceptance of each new Cookie in a variety of ways. You can also delete all Cookies that are already on your device. If you do this, however, you may have to manually adjust some preferences every time you visit our website and some of the Services and functionalities may not work. To explore what Cookie settings are available to you or to modify your Cookies preferences, look in the “preferences” or “options” section of your browser’s menu. To find out more information about Cookies, including information about how to manage and delete Cookies, please visit http://www.allaboutcookies.org/ or https://ico.org.uk/for-the-public/online/cookies/ if you are located in the European Union.Data SecurityWe seek to protect your Personal Data from unauthorized access, use and disclosure using appropriate physical, technical, organizational and administrative security measures based on the type of Personal Data and how we are processing that data. You should also help protect your data by appropriately selecting and protecting your password and/or other sign-on mechanism; limiting access to your computer or device and browser; and signing off after you have finished accessing your account. Although we work to protect the security of your account and other data that we hold in our records, please be aware that no method of transmitting data over the internet or storing data is completely secure.Data RetentionWe retain Personal Data about you for as long as you have an open account with us or as otherwise necessary to provide you with our Services or to perform our business or commercial purposes for collecting your Personal Data. When establishing a retention period for specific categories of data, we consider who we collected the data from, our need for the Personal Data, why we collected the Personal Data, and the sensitivity of the Personal Data. In some cases we retain Personal Data for longer, if doing so is necessary to comply with our legal obligations, resolve disputes or collect fees owed, or is otherwise permitted or required by applicable law, rule or regulation. We may further retain information in an anonymous or aggregated form where that information would not identify you personally.Personal Data of ChildrenAs noted in the Terms of Use, we do not knowingly collect or solicit Personal Data about children under 18 years of age; if you are a child under the age of 18, please do not attempt to register for or otherwise use the Services or send us any Personal Data. If we learn we have collected Personal Data from a child under 18 years of age, we will delete that information as quickly as possible. If you believe that a child under 18 years of age may have provided Personal Data to us, please contact us at hello@modular.com.State Law Privacy RightsCaliforniaIf you are a California resident, you have the rights set forth in this section. Please see the “Exercising Your Rights” section below for instructions regarding how to exercise these rights. Please note that we may process Personal Data of our customers’ end users or employees in connection with our provision of certain services to our customers. If we are processing your Personal Data as a service provider, you should contact the entity that collected your Personal Data in the first instance to address your rights with respect to such data.If there are any conflicts between this section and any other provision of this Privacy Policy and you are a California resident, the portion that is more protective of Personal Data shall control to the extent of such conflict. If you have any questions about this section or whether any of the following rights apply to you, please contact us at hello@modular.com.AccessYou have the right to request certain information about our collection and use of your Personal Data over the past 12 months. In response, we will provide you with the following information:The categories of Personal Data that we have collected about you.The categories of sources from which that Personal Data was collected.The business or commercial purpose for collecting or selling your Personal Data.The categories of third parties with whom we have shared your Personal Data.The specific pieces of Personal Data that we have collected about you.If we have disclosed your Personal Data to any third parties for a business purpose over the past 12 months, we will identify the categories of Personal Data shared with each category of third party recipient. If we have sold your Personal Data over the past 12 months, we will identify the categories of Personal Data sold to each category of third party recipient.DeletionYou have the right to request that we delete the Personal Data that we have collected about you. Under the CPRA, this right is subject to certain exceptions: for example, we may need to retain your Personal Data to provide you with the Services or complete a transaction or other action you have requested, or deletion may require disproportional effort. If your deletion request is subject to one of these exceptions, we may deny your deletion request. CorrectionYou have the right to request that we correct any inaccurate Personal Data we have collected about you. Under the CPRA, this right is subject to certain exceptions: for example, if we decide, based on the totality of circumstances related to your Personal Data, that such data is correct. If your correction request is subject to one of these exceptions, we may deny your request. Exercising Your RightsTo exercise the rights described above, you or your Authorized Agent (defined below) must send us a request that (1) provides sufficient information to allow us to verify that you are the person about whom we have collected Personal Data, and (2) describes your request in sufficient detail to allow us to understand, evaluate and respond to it. Each request that meets both of these criteria will be considered a “Valid Request.” We may not respond to requests that do not meet these criteria. We will only use Personal Data provided in a Valid Request to verify your identity and complete your request. You do not need an account to submit a Valid Request.We will work to respond to your Valid Request within 45 days of receipt. We will not charge you a fee for making a Valid Request unless your Valid Request(s) is excessive, repetitive or manifestly unfounded. If we determine that your Valid Request warrants a fee, we will notify you of the fee and explain that decision before completing your request.You may submit a Valid Request using the following methods:Email us at: hello@modular.comSubmit a form at this address: https://www.modular.com/contactYou may also authorize an agent (an “Authorized Agent”) to exercise your rights on your behalf. To do this, you must provide your Authorized Agent with written permission to exercise your rights on your behalf, and we may request a copy of this written permission from your Authorized Agent when they make a request on your behalf.‍Personal Data Sales Opt-Out and Opt-InWe will not sell your Personal Data, and have not done so over the last 12 months. To our knowledge, we do not sell the Personal Data of minors under 18 years of age.‍We Will Not Discriminate Against You for Exercising Your Rights Under the CPRAWe will not discriminate against you for exercising your rights under the CPRA. We will not deny you our services, charge you different prices or rates, or provide you a lower quality of goods and services if you exercise your rights under the CPRA. However, we may offer different tiers of our Services as allowed by applicable data privacy laws (including the CPRA) with varying prices, rates or levels of quality of the goods or services you receive related to the value of Personal Data that we receive from you. ‍Under California Civil Code Sections 1798.83-1798.84, California residents are entitled to contact us to prevent disclosure of Personal Data to third parties for such third parties’ direct marketing purposes; in order to submit such a request, please contact us at hello@modular.com. However, we do not sell your Personal Data or have plans to do so. ‍Nevada Resident RightsIf you are a resident of Nevada, you have the right to opt-out of the sale of certain Personal Data to third parties who intend to license or sell that Personal Data. You can exercise this right by contacting us at hello@modular.com with the subject line “Nevada Do Not Sell Request” and providing us with your name and the email address associated with your account. However, we do not sell your Personal Data nor have plans to do so. Virginia Resident RightsIf you are a Virginia resident, you have the rights set forth under the Virginia Consumer Data Protection Act (“VCDPA”). Please see the “Exercising Your Rights” section below for instructions regarding how to exercise these rights. Please note that we may process Personal Data of our customers’ end users or employees in connection with our provision of certain services to our customers. If we are processing your Personal Data as a service provider, you should contact the entity that collected your Personal Data in the first instance to address your rights with respect to such data. Additionally, please note that these rights are subject to certain conditions and exceptions under applicable law, which may permit or require us to deny your request.If there are any conflicts between this section and any other provision of this Privacy Policy and you are a Virginia resident, the portion that is more protective of Personal Data shall control to the extent of such conflict. If you have any questions about this section or whether any of the following rights apply to you, please contact us at hello@modular.com. ‍Access‍You have the right to request confirmation of whether or not we are processing your Personal Data and to access your Personal Data. ‍Correction‍You have the right to correct inaccuracies in your Personal Data, to the extent such correction is appropriate in consideration of the nature of such data and our purposes of processing your Personal Data. ‍Portability‍You have the right to request a copy of your Personal Data in a machine-readable format, to the extent technically feasible.European Union and United Kingdom Data Subject RightsEU and UK Residents‍If you are a resident of the European Union (“EU”), United Kingdom (“UK”), Lichtenstein, Norway or Iceland, you may have additional rights under the EU or UK General Data Protection Regulation (the “GDPR”) with respect to your Personal Data, as outlined below. For this section, we use the terms “Personal Data” and “processing” as they are defined in the GDPR, but “Personal Data” generally means information that can be used to individually identify a person, and “processing” generally covers actions that can be performed in connection with data such as collection, use, storage and disclosure. Modular will be the controller of your Personal Data processed in connection with the Services.If there are any conflicts between this this section and any other provision of this Privacy Policy, the policy or portion that is more protective of Personal Data shall control to the extent of such conflict. If you have any questions about this section or whether any of the following applies to you, please contact us at hello@modular.com.‍Personal Data We Collect‍The “Categories of Personal Data We Collect” section above details the Personal Data that we collect from you.‍Personal Data Use and Processing Grounds‍The “Our Commercial or Business Purposes for Collecting Personal Data” section above explains how we use your Personal Data.We will only process your Personal Data if we have a lawful basis for doing so. Lawful bases for processing include consent, contractual necessity and our “legitimate interests” or the legitimate interest of others, as further described below.Contractual Necessity. We process the following categories of Personal Data as a matter of “contractual necessity”, meaning that we need to process the data to perform under our Terms of Use with you, which enables us to provide you with the Services. When we process data due to contractual necessity, failure to provide such Personal Data will result in your inability to use some or all portions of the Services that require such data. Profile or contact data, Payment DataLegitimate Interest:. We process the following categories of Personal Data when we believe it furthers the legitimate interest of us or third parties Device data, Web analytics data, Geolocation Data, Professional Data, We may also de-identify or anonymize Personal Data to further our legitimate interests. Providing, customizing and improving the Services.Marketing the Services.Corresponding with you.Meeting legal requirements and enforcing legal terms.Completing corporate transactions. Consent. In some cases, we process Personal Data based on the consent you expressly grant to us at the time we collect such data. When we process Personal Data based on your consent, it will be expressly indicated to you at the point and time of collection. Other Processing Grounds. From time to time we may also need to process Personal Data to comply with a legal obligation, if it is necessary to protect the vital interests of you or other data subjects, or if it is necessary for a task carried out in the public interest.Sharing Personal Data‍The “How We Share Your Personal Data” section above details how we share your Personal Data with third parties. ‍EU Data Subject Rights‍You have certain rights with respect to your Personal Data, including those set forth below. For more information about these rights, or to submit a request, please email us at hello@modular.com. Please note that in some circumstances, we may not be able to fully comply with your request, such as if it is frivolous or extremely impractical, if it jeopardizes the rights of others, or if it is not required by law, but in those circumstances, we will still respond to notify you of such a decision. In some cases, we may also need you to provide us with additional information, which may include Personal Data, if necessary to verify your identity and the nature of your request.  Access. You can request more information about the Personal Data we hold about you and request a copy of such Personal Data.Rectification. If you believe that any Personal Data we are holding about you is incorrect or incomplete, you can request that we correct or supplement such data.Erasure. You can request that we erase some or all of your Personal Data from our systems.  Withdrawal of Consent. If we are processing your Personal Data based on your consent (as indicated at the time of collection of such data), you have the right to withdraw your consent at any time. Please note, however, that if you exercise this right, you may have to then provide express consent on a case-by-case basis for the use or disclosure of certain of your Personal Data, if such use or disclosure is necessary to enable you to utilize some or all of our Services. Portability. You can ask for a copy of your Personal Data in a machine-readable format. You can also request that we transmit the data to another controller where technically feasible. Objection. You can contact us to let us know that you object to the further use or disclosure of your Personal Data for certain purposes, such as for direct marketing purposes. Restriction of Processing. You can ask us to restrict further processing of your Personal Data.Right to File Complaint. You have the right to lodge a complaint about Modular's practices with respect to your Personal Data with the supervisory authority of your country or EU Member State. A list of Supervisory Authorities is available here: https://edpb.europa.eu/about-edpb/board/members_en.Transfers of Personal DataThe Services are hosted and operated in the United States (“U.S.”) through Modular and its service providers, and if you do not reside in the U.S., laws in the U.S. may differ from the laws where you reside. By using the Services, you acknowledge that any Personal Data about you, regardless of whether provided by you or obtained from a third party, is being provided to Modular in the U.S. and will be hosted on U.S. servers, and you authorize Modular to transfer, store and process your information to and in the U.S., and possibly other countries. You hereby consent to the transfer of your data to the U.S. pursuant to EU-U.S. Privacy Shield Frameworks, respectively, the details of which are further set forth below. While the Privacy Shield is no longer a valid basis on which Modular may rely to transfer Personal Data from the EU to the U.S. pursuant to the GDPR, Modular continues to comply with the EU-U.S. Privacy Shield Framework as set forth by the U.S. Department of Commerce regarding the collection, use and retention of Personal Data from EU member countries transferred to the U.S. pursuant to Privacy Shield. Modular has certified that it adheres to the Privacy Shield Principles with respect to such data. If there is any conflict between the policies in this Privacy Policy and data subject rights under the Privacy Shield Principles, the Privacy Shield Principles shall govern. To learn more about the Privacy Shield program, and to view our certification page, please visit https://www.privacyshield.gov/. Modular will transfer Personal Data from the EU to the U.S. pursuant to GDPR adhering to the model clauses. In certain situations, we may be required to disclose Personal Data in response to lawful requests by public authorities, including to meet national security or law enforcement requirements.Changes to this Privacy PolicyContact Information‍If you have any questions or comments about this Privacy Policy, the ways in which we collect and use your Personal Data or your choices and rights regarding such collection and use, please do not hesitate to contact us at:www.modular.comhello@modular.comwww.modular.com/contact\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modular: Acceptable Use Policy\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "PERFORMANCE DASH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOCSMojo🔥\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DocsHardwareBlogCareersCompany\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "Vision\n",
      "\n",
      "\n",
      "Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsletter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Culture\n",
      "\n",
      "\n",
      "\n",
      "contactSign inGet Started\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MenuAcceptable Use PolicyLast Updated: May 2nd, 2023This Acceptable Use Policy forms part of both Modular’s Terms of Use (https://www.modular.com/terms), and governs User use of the Platform. This Acceptable Use Policy outlines certain restricted activities in which Users may not engage while using the Platform. Modular reserves the right to suspend and/or terminate User accounts for any violations of or failure to comply with the guidelines set forth in this Acceptable Use Policy. Compliance with Laws and RegulationsUsers shall use the Platform in compliance with all applicable laws, regulations, and all of the guidelines set forth herein. User SafetyWe do not allow conduct, content or activity on Modular that:is unlawful or promotes unlawful activities;is sexually obscene or relates to sexual exploitation or abuse, including of minors;is libelous, defamatory, or fraudulent;is discriminatory or abusive toward any individual or group;is false, inaccurate, or intentionally deceptive information and likely to adversely affect the public interest (including health, safety, election integrity, and civic participation);harasses or abuses another individual or group, including our employees, officers, and agents, or other Users;threatens or incites violence toward any individual or group, especially on the basis of who they are;gratuitously depicts or glorifies violence, including violent images; oris off-topic, or interacts with Platform features in a way that significantly or repeatedly disrupts the experience of other Users.Intellectual Property, Authenticity, and Private InformationWe do not allow content or activity on Modular that:attempts to reverse engineer, scrape, or otherwise utilize the Platform for any competitive purposes, including but not limited to discovering Modular IP that constitutes Confidential Information for use in a competitive product; infringes any intellectual property, privacy, or proprietary right of any party, including patent, trademark, trade secret, copyright, right of publicity, personal information or other rights;unlawfully shares unauthorized product licensing keys, software for generating unauthorized product licensing keys, or software for bypassing checks for product licensing keys, including extension of a free license beyond its trial period; orimpersonates any person or entity, including any of our employees or representatives, including through false association with Modular, or by fraudulently misrepresenting one’s identity or the Platform’s purpose.Spam and Inauthentic Activity We do not allow content or activity on Modular that is:automated excessive bulk activity and coordinated inauthentic activity, such as spamming or cryptocurrencybulk distribution of promotions and advertising;inauthentic interactions, such as fake accounts and automated inauthentic activity;creation of or participation in secondary markets for the purpose of the proliferation of inauthentic activity;using Modular for propagating abuse on other platforms;phishing or attempted phishing; orusing Modular servers for any form of excessive automated bulk activity, to place undue burden on our servers through automated means, or to relay any form of unsolicited advertising or solicitation through our servers, such as get-rich-quick schemes.Site Access and SafetyWe do not allow content or activity on Modular that:directly supports unlawful active attack or malware campaigns that are causing technical harms, such as using the Platform to deliver malicious executables or as attack infrastructure, for example by organizing denial of Platform attacks or managing command and control servers, with no implicit or explicit dual-use purpose prior to the abuse occurring; oruses our servers to disrupt or to attempt to disrupt, or to gain or to attempt to gain unauthorized access to, any platform, device, data, account or network. Platforms Usage LimitsUsers will not reproduce, duplicate, copy, sell, resell, scrape, re-use or exploit any portion of the Platform, use of the Platform, or access to the Platform without Modular’s express written permission.PrivacyMisuse of Personal Information is prohibited. Any person or entity collecting data from the Platform must comply with the Modular Privacy Policy (https://www.modular.com/privacy). If a User collects any Personal Information from the Platform, that User agrees it will only use that Personal Information for the purpose for which the respective User to whom the Personal Information pertains has authorized its use. User agrees that it will reasonably secure any Personal Information it has gathered from the Platform, and User will respond promptly to complaints, removal requests, and \"do not contact\" requests from us or other Users (to the extent applicable).AdvertisingWhile we understand that Users may want to promote their respective User Generated Content by posting supporters' names or logos in its account, the primary focus of the User Generated Content posted to the Platform should not be advertising or promotional marketing. Users may include static images, links, and promotional text in the README documents or project description sections associated with its Account(s), but they must be related to the AI Algorithms Users and Developers are sharing on the Platform. Users may not advertise by posting monetized or excessive bulk content.Users may not promote or distribute content or activity that is illegal or otherwise prohibited by the applicable Terms of Use by which they are bound or this Acceptable Use Policy, including excessive automated bulk activity (for example, spamming), get-rich-quick schemes, and misrepresentation or deception related to its promotion.If a User decide to post any promotional materials in its account, User is solely responsible for complying with all applicable laws and regulations, including without limitation the U.S. Federal Trade Commission's Guidelines on Endorsements and Testimonials. Modular reserves the right to remove any promotional materials or advertisements that, in our sole discretion, violate any Modular terms or policies.User ProtectionUser must not engage in activity that significantly harms other Users. Modular will interpret policies and resolve disputes in favor of protecting Users as a whole.\n",
      "\n",
      "EngineMojo 🔥HardwarePerformanceGet StartedBlogCareersCopyright © 2023,Modular Inc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms,Privacy&Acceptable Use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links = get_links(\"https://www.modular.com/\")\n",
    "ctext = transform_links_to_corpus(links)\n",
    "ctext= \"\".join(ctext)\n",
    "print(ctext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff4c580",
   "metadata": {},
   "source": [
    "## step 3: perform all cleaning to transform a text corpus into NLP tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813a9411",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "633a9add",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T21:56:40.695316Z",
     "start_time": "2023-05-04T21:56:39.563531Z"
    }
   },
   "source": [
    " python3 -m spacy download en_core_web_lg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e70f58dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T17:19:27.292115Z",
     "start_time": "2023-05-13T17:19:25.186646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Modular AI development starts here Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuWATCH OUR 2023 PRODUCT KEYNOTEThe future of AI development starts hereJoin our DiscordWatch Keynote SummaryPlatformENGINEMOJO The next generation AI developer platform The fastest unified AI inference engine in the world A new programming language for all AI developers Get startedLearn more Ai Frameworks Clouds SOFTMAX py pythonMojo def softmax lst norm np exp lst np max lst return norm norm sum def softmax lst norm np exp lst np max lst return norm norm sum struct NDArray def max self NDArray return self pmap SIMD max struct SIMD type DType width Int def max self rhs Self Self return self rhs select self rhs Modular engine performance across hardware typesintelMore than2xFaster on FLOAT32AMDMore than3xFaster on FLOAT32GravitonMore than4xFaster on FLOAT32Engine devicesModular engine performance across hardware typesintelMore than2xFaster on FLOAT32AMDMore than3xFaster on FLOAT32GravitonMore than4xFaster on FLOAT32 file_name py pythonMojo def softmax lst norm np exp lst np max lst return norm norm sum def softmax lst norm np exp lst np max lst return norm norm sum struct NDArray def max self NDArray return self pmap SIMD max struct SIMD type DType width Int def max self rhs Self Self return self rhs select self rhs Discover how our revolutionary infrastructure makes AI more usable scalable high performant and cost effective The Modular Engine unifies AI frameworks and hardware and delivers unparalleled performance and cost savings Mojo combines the usability of Python with the performance of C unlocking unparalleled programmability of hardware Our unified extensible platform superpowers your AIModular is an integrated composable suite of tools that simplifies your AI infrastructure so your team can develop deploy and innovate faster Clouds Ai Frameworks Engine Devices01Model deploymentThe world s fastest unified inference engineModular s inference engine unifies AI industry frameworks and hardware enabling you to deploy to any cloud or on prem environment with minimal code changes unlocking unmatched usability performance and portability Learn moreRead the docsCOMpute portabilityRun your modelsanywhere reduce costsSeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models Avoid lock in and take advantage of cloud price efficiencies and performance improvements without migration costs Learn more02Programmability ExtensibilityMojo a new programming language for all AI developersMojo is a programming language that combines the usability of Python with the performance of C unlocking unparalleled programmability of AI hardware and extensibility of AI models Learn moreRead the docs SOftmax def softmax lst norm np exp lst np max lst return norm norm sum struct NDArray def max self NDArray return self pmap SIMD max struct SIMD type DType width Int def max self rhs Self Self return self rhs select self rhs model ScalabilityDeploy the largest models in the world on our stackThe Modular Compute Platform dynamically partitions models with billions of parameters and distributes their execution across multiple machines enabling unparalleled efficiency scale and reliability for the largest workloads Contact usLLaMA Gopher T5 Jurassic WORLD CLASS ENTERPRISE COMMUNITY SUPPORTGet help from the people who know Modular bestAs a community member you can chat with the Modular team directly on Discord and as an enterprise customer you get direct support from industry experts to keep you running and enable you to scale to your next challenges Chat with us now General ModularToday at 4 17PMHow can we help you Deploy on the fastest unified infrastructure on the planetModular unlocks state of the art latency efficiency and throughput helping you productionize larger models and realize massive cost savings on your cloud bill Queries per Second 125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qps ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size1Don t believe us Put us to the test Explore our performanceLanguageRun Test Computer VisionRun Test RecommendationRun Test LAUNCHING IN 2023Modular s cloud compute platformJoin the waiting list01 TRAINING AT SCALENotebooks for training on the largest compute clusters using Python Mojo for highly optimized workloads 02 MANAGED BYOCUtilize our managed environment or Bring your own cloud BYOC for seamless workload management 03 PERFORMANCE METRICSDetailed machine performance and metrics data to provide end to end insight into your AI workloads 04 DEVELOPER FIRST UI CLILeverage our easy to use web UI or CLI tooling to seamlessly manage your training and deployment workflows 05 SECURITY ENCRYPTIONEnterprise security encryption for your data to be secured at rest and in transit on your data stores Why Modular Built by the world s AI experts Our team has built most of the world s existing AI infrastructure including TensorFlow PyTorch TPUs and MLIR and launched software like Swift and LLVM Now we re focused on rebuilding AI infrastructure for the world Reinvented from the ground upTo unlock the next wave of AI innovation we need a first principles approach to the lowest layers of the AI stack We can t pile on more and more layers of complexity on top of already over complicated existing solutions Built with generality in mindNatively multi model multi framework multi hardware and multi cloud our infrastructure scales from the largest clusters down to the smallest edge devices and in between Infrastructure that just works We build technology that meets you where you are at You shouldn t have to rewrite your models or application code grapple with confusing converters or be a hardware expert to take advantage of state of the art technology Built for youMove beyond Big Tech s trickle down infrastructure Get direct access to industry experts that will help solve any issue you have with our infrastructure and make sure we re meeting your SLA SLOs Ready to get started Sign up to gain early access to Modular s infrastructure Request accessAPI References Tutorials MoreRead the docs EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Inference Engine Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuThe world s fastest unified AI inference engine Get models into production faster The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions Bring your model as is and deploy it anywhere across server and edge with unparalleled usability and performance Get startedSee our performanceengine P99 Latency 12 1 ms P50P90P95P99TensorFlowPyTorchModular Engine ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size101UnificationTrain in any framework deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude Cloud On PremFrameworksmodular EngineServer edgeFramework optionalityEasily deploy models trained in any framework such as TensorFlow or PyTorch without retraining conversions or pre optimization steps using a unified set of APIs There are no tricks no hacks the Engine just works incredibly fast Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models Avoid lock in and take advantage of price efficiencies and performance improvements without migration costs 02PerformanceMaximize performance minimize costsReduce latency increase throughput and improve resource efficiency across CPUs GPUs and accelerators Productionize larger models and significantly reduce your computing costs Explore our performance dashboardQueries per Second 125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences 0 12TensorFlow 0 89PyTorch 0 54Modular Engine 0 12 ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size1MODULAR ENGINE SPEED UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family vs vs vs vs vs vsLanguage Model3x3 2x5 3x1 4x2 1x4xRecommender Models6 5x5x7 5x1 1x1 2x4 3xVision Models2 1x2 2x1 7x1 5x1 5x1 3xCompute TypeIntel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge Intel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge ResultsAWS Compute Instances TensorFlow PyTorch listed by logo Full performance methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again Run any model including support for all native framework operators dynamic shapes low precision and your existing custom operators DLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseBERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases Our tools are well modular They integrate with industry standard infrastructure and open source tools to minimize migration cost Request accessseamless integration with popular libraries and tools01 Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular s off the shelf NVIDIA Triton and TensorFlow Serving builds 02 Choose your cloudDeploy the engine on prem in your own VPC on any major cloud provider or get up and running quicker with out hosted solutions 03 METRICS MONITORINGThe Modular Inference Engine works with industry standard open source tooling like Prometheus and Grafana Ready to try a preview Contact us to get early access to the Modular Inference Engine Request accessAPI References Tutorials MoreRead the Modular Inference Engine docs EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Inference Engine Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuThe world s fastest unified AI inference engine Get models into production faster The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions Bring your model as is and deploy it anywhere across server and edge with unparalleled usability and performance Get startedSee our performanceengine P99 Latency 12 1 ms P50P90P95P99TensorFlowPyTorchModular Engine ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size101UnificationTrain in any framework deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude Cloud On PremFrameworksmodular EngineServer edgeFramework optionalityEasily deploy models trained in any framework such as TensorFlow or PyTorch without retraining conversions or pre optimization steps using a unified set of APIs There are no tricks no hacks the Engine just works incredibly fast Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models Avoid lock in and take advantage of price efficiencies and performance improvements without migration costs 02PerformanceMaximize performance minimize costsReduce latency increase throughput and improve resource efficiency across CPUs GPUs and accelerators Productionize larger models and significantly reduce your computing costs Explore our performance dashboardQueries per Second 125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences 0 12TensorFlow 0 89PyTorch 0 54Modular Engine 0 12 ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size1MODULAR ENGINE SPEED UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family vs vs vs vs vs vsLanguage Model3x3 2x5 3x1 4x2 1x4xRecommender Models6 5x5x7 5x1 1x1 2x4 3xVision Models2 1x2 2x1 7x1 5x1 5x1 3xCompute TypeIntel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge Intel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge ResultsAWS Compute Instances TensorFlow PyTorch listed by logo Full performance methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again Run any model including support for all native framework operators dynamic shapes low precision and your existing custom operators DLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseBERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases Our tools are well modular They integrate with industry standard infrastructure and open source tools to minimize migration cost Request accessseamless integration with popular libraries and tools01 Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular s off the shelf NVIDIA Triton and TensorFlow Serving builds 02 Choose your cloudDeploy the engine on prem in your own VPC on any major cloud provider or get up and running quicker with out hosted solutions 03 METRICS MONITORINGThe Modular Inference Engine works with industry standard open source tooling like Prometheus and Grafana Ready to try a preview Contact us to get early access to the Modular Inference Engine Request accessAPI References Tutorials MoreRead the Modular Inference Engine docs EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Mojo Programming language for all of AI Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuMojo a new programming language for all AI developers Mojo combines the usability of Python with the performance of C unlocking unparalleled programmability of AI hardware and extensibility of AI models Get started with MojoRead the docs SOFTMAX PYMojo pythondef softmax lst norm np exp lst np max lst return norm norm sum def softmax lst norm np exp lst np max lst return norm norm sum struct NDArray def max self NDArray return self pmap SIMD max struct SIMD type DType width Int def max self rhs Self Self return self rhs select self rhs 01Usability ProgrammabilityWrite everything in one languageWrite Python or scale all the way down to the metal Program the multitude of low level AI hardware No C or CUDA required Take a tour of Mojo FILE_NAME def sort v ArraySlice Int for i in range len v for j in range len v i 1 if v j v j 1 swap v j v j 1 FILE_NAME struct MyPair var first Int var second F32 def __init__ self first Int second F32 self first first self second secondFILE_NAME def reorder_and_process owned x HugeArray sort x Update in place give_away x Transfer ownership print x 0 Error x moved away FILE_NAME def exp dt DType elts Int x SIMD dt elts SIMD dt elts x clamp x 88 3762626647 88 37626266 k floor x INV_LN2 0 5 r k NEG_LN2 x return ldexp _exp_taylor r k FILE_NAME def exp_buffer dt DType data ArraySlice dt Search for the best vector length alias vector_len autotune 1 4 8 16 32 Use it as the vectorization length vectorize exp dt vector_len data Features include Progressive TypesLeverage types for better performance and error checking Zero Cost AbstractionsTake control of storage by inline allocating values into structures Ownership borrow checkerTake advantage of memory safety without the rough edges Portable parametric algorithmsLeverage compile time meta programming to write hardware agnostic algorithms and reduce boilerplate LANGUAGE INTEGRATED Auto tuningAutomatically find the best values for your parameters to take advantage of target hardware As well as The full power of MLIRParallel heterogenous runtimeFast compile times FILE_NAME def sort v ArraySlice Int for i in range len v for j in range len v i 1 if v j v j 1 swap v j v j 1 Features include Progressive TypesLeverage types for better performance and error checking FILE_NAME struct MyPair var first Int var second F32 def __init__ self first Int second F32 self first first self second secondFeatures include Zero Cost AbstractionsTake control of storage by inline allocating values into structures FILE_NAME def reorder_and_process owned x HugeArray sort x Update in place give_away x Transfer ownership print x 0 Error x moved away Features include Ownership borrow checkerTake advantage of memory safety without the rough edges FILE_NAME def exp dt DType elts Int x SIMD dt elts SIMD dt elts x clamp x 88 3762626647 88 37626266 k floor x INV_LN2 0 5 r k NEG_LN2 x return ldexp _exp_taylor r k Features include Portable parametric algorithmsLeverage compile time meta programming to write hardware agnostic algorithms and reduce boilerplate FILE_NAME def exp_buffer dt DType data ArraySlice dt Search for the best vector length alias vector_len autotune 1 4 8 16 32 Use it as the vectorization length vectorize exp dt vector_len data Features include LANGUAGE INTEGRATED Auto tuningAutomatically find the best values for your parameters to take advantage of target hardware 02PerformanceUnlock Python performanceUtilize the full power of the hardware including multiple cores vector units and exotic accelerator units with the world s most advanced compiler and heterogenous runtime Achieve performance on par with C and CUDA without the complexity Play with MojoParallelizationMojo leverages MLIR which enables Mojo developers to take advantage of vectors threads and AI hardware units PYTHONSingle threaded executionMojo Parallel processing across multiple coresLanguagesTime S Speedup vs PythonPython 3 10 91027 s1xPypy46 1 s22xScalar C 0 20 s5000xMojo 0 03 s35000x AlgorithmMandelbrotInstanceAWS r7iz metal 16xlIntel Xeon03InteroperabilityAccess the entire Python ecosystemExperience true interoperability with the Python ecosystem Seamlessly intermix arbitrary libraries like Numpy and Matplotlib and your custom code with Mojo Read the programming manual MAKE_PLOT def make_plot m Matrix plt Python import_module matplotlib pyplot fig plt figure 1 10 10 yn xn 64 ax fig add_axes 0 0 0 0 1 0 1 0 False 1 plt imshow image plt show make_plot compute_mandelbrot Mojo 04ExtensibilityUpgrade your models and the Modular stackEasily extend your models with pre and post processing operations or replace operations with custom ones Take advantage of kernel fusion graph rewrites shape functions and more Model extensibilityMojo can upgrade the existing operations in your model Input layerHidden layersOutput layer05GET STARTED NOWTry Mojo out right now in our PlaygroundMojo is still a work in progress but it s available to try today in our JupyterHub based Playground Run through tutorials and write your own Mojo code Sign up for accessMojo 01 EASY TO GET STARTEDWe have plenty of easy to use Jupyter notebooks to help you get started learning Mojo 02 Unleash your mojoOur docs will help you quickly discover why Mojo is such a powerful extension to Python and the future of AI programming 03 JOIN the mojo COMMUNITYCome and chat with us on our Discord and help shape the future of the language as we continue to develop it Ready to play with Mojo Reach out to gain access to the Mojo Playground Request accessAPI Reference Tutorials MoreRead the Mojo docs EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Mojo Programming language for all of AI Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuMojo a new programming language for all AI developers Mojo combines the usability of Python with the performance of C unlocking unparalleled programmability of AI hardware and extensibility of AI models Get started with MojoRead the docs SOFTMAX PYMojo pythondef softmax lst norm np exp lst np max lst return norm norm sum def softmax lst norm np exp lst np max lst return norm norm sum struct NDArray def max self NDArray return self pmap SIMD max struct SIMD type DType width Int def max self rhs Self Self return self rhs select self rhs 01Usability ProgrammabilityWrite everything in one languageWrite Python or scale all the way down to the metal Program the multitude of low level AI hardware No C or CUDA required Take a tour of Mojo FILE_NAME def sort v ArraySlice Int for i in range len v for j in range len v i 1 if v j v j 1 swap v j v j 1 FILE_NAME struct MyPair var first Int var second F32 def __init__ self first Int second F32 self first first self second secondFILE_NAME def reorder_and_process owned x HugeArray sort x Update in place give_away x Transfer ownership print x 0 Error x moved away FILE_NAME def exp dt DType elts Int x SIMD dt elts SIMD dt elts x clamp x 88 3762626647 88 37626266 k floor x INV_LN2 0 5 r k NEG_LN2 x return ldexp _exp_taylor r k FILE_NAME def exp_buffer dt DType data ArraySlice dt Search for the best vector length alias vector_len autotune 1 4 8 16 32 Use it as the vectorization length vectorize exp dt vector_len data Features include Progressive TypesLeverage types for better performance and error checking Zero Cost AbstractionsTake control of storage by inline allocating values into structures Ownership borrow checkerTake advantage of memory safety without the rough edges Portable parametric algorithmsLeverage compile time meta programming to write hardware agnostic algorithms and reduce boilerplate LANGUAGE INTEGRATED Auto tuningAutomatically find the best values for your parameters to take advantage of target hardware As well as The full power of MLIRParallel heterogenous runtimeFast compile times FILE_NAME def sort v ArraySlice Int for i in range len v for j in range len v i 1 if v j v j 1 swap v j v j 1 Features include Progressive TypesLeverage types for better performance and error checking FILE_NAME struct MyPair var first Int var second F32 def __init__ self first Int second F32 self first first self second secondFeatures include Zero Cost AbstractionsTake control of storage by inline allocating values into structures FILE_NAME def reorder_and_process owned x HugeArray sort x Update in place give_away x Transfer ownership print x 0 Error x moved away Features include Ownership borrow checkerTake advantage of memory safety without the rough edges FILE_NAME def exp dt DType elts Int x SIMD dt elts SIMD dt elts x clamp x 88 3762626647 88 37626266 k floor x INV_LN2 0 5 r k NEG_LN2 x return ldexp _exp_taylor r k Features include Portable parametric algorithmsLeverage compile time meta programming to write hardware agnostic algorithms and reduce boilerplate FILE_NAME def exp_buffer dt DType data ArraySlice dt Search for the best vector length alias vector_len autotune 1 4 8 16 32 Use it as the vectorization length vectorize exp dt vector_len data Features include LANGUAGE INTEGRATED Auto tuningAutomatically find the best values for your parameters to take advantage of target hardware 02PerformanceUnlock Python performanceUtilize the full power of the hardware including multiple cores vector units and exotic accelerator units with the world s most advanced compiler and heterogenous runtime Achieve performance on par with C and CUDA without the complexity Play with MojoParallelizationMojo leverages MLIR which enables Mojo developers to take advantage of vectors threads and AI hardware units PYTHONSingle threaded executionMojo Parallel processing across multiple coresLanguagesTime S Speedup vs PythonPython 3 10 91027 s1xPypy46 1 s22xScalar C 0 20 s5000xMojo 0 03 s35000x AlgorithmMandelbrotInstanceAWS r7iz metal 16xlIntel Xeon03InteroperabilityAccess the entire Python ecosystemExperience true interoperability with the Python ecosystem Seamlessly intermix arbitrary libraries like Numpy and Matplotlib and your custom code with Mojo Read the programming manual MAKE_PLOT def make_plot m Matrix plt Python import_module matplotlib pyplot fig plt figure 1 10 10 yn xn 64 ax fig add_axes 0 0 0 0 1 0 1 0 False 1 plt imshow image plt show make_plot compute_mandelbrot Mojo 04ExtensibilityUpgrade your models and the Modular stackEasily extend your models with pre and post processing operations or replace operations with custom ones Take advantage of kernel fusion graph rewrites shape functions and more Model extensibilityMojo can upgrade the existing operations in your model Input layerHidden layersOutput layer05GET STARTED NOWTry Mojo out right now in our PlaygroundMojo is still a work in progress but it s available to try today in our JupyterHub based Playground Run through tutorials and write your own Mojo code Sign up for accessMojo 01 EASY TO GET STARTEDWe have plenty of easy to use Jupyter notebooks to help you get started learning Mojo 02 Unleash your mojoOur docs will help you quickly discover why Mojo is such a powerful extension to Python and the future of AI programming 03 JOIN the mojo COMMUNITYCome and chat with us on our Discord and help shape the future of the language as we continue to develop it Ready to play with Mojo Reach out to gain access to the Mojo Playground Request accessAPI Reference Tutorials MoreRead the Mojo docs EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Hardware Developers Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuUnlock your hardware design with software that provides generality and usability for AI developers Modular s software stack will take care of all upstream integrations with AI frameworks graph optimizations and more so you can focus on the differentiating features of your hardware Own your code generation performance and feature set It s still early but we re excited about the future Contact us nowLearn how it works01BenefitsIntegrating with the Modular stack gets you 01 Access to all AI frameworksEffortlessly extend your customer reach to all popular AI frameworks 02 Better performanceAutofusion and graph optimizations boost your hardware performance 03 Full compatibilityWe support the ever changing AI ecosystem including the long tail of operators and models 04 Market DifferentiationYou own your performance and can utilize the full capabilities of your hardware 05 Faster time to marketYour hardware just works often with only a few weeks of development 02How it worksIntegration is simple FrameworksModular handles integration packagingend user tools Modular engineModular handles offload kernel fusion compilation caching developer tools Your Compiler KernelsYou provide LLVM or MLIR code generation and extend the stack with Mojo kernelsyour HardwareYou design the hardware and have in house expertise03Modern AI EngineModular handles framework support and end user toolingModular handles the ever changing world of AI frameworks models and operators providing you with a single cross framework integration point for your hardware stack Full framework model and op supportIntegration with TensorFlow PyTorch plus variants like ONNX and TorchScriptFull generality of models including dynamic shapes sparsity custom ops etc Thousands of long tail operators needed for compatibilityCompiler transformations and developer toolingKernel fusion and other performance optimizationsAutomatic graph partitioning for distributed inferenceStandardized and hackable tools04IntegrationPlug your hardware in at the graph or code generation levelBring your own code gen backend for CPU GPU or DSPs and everything just works For CGRA FPGA or other exotic hardware start with our standardized operator set and extend the system to your needs Focus your effort on ML operators you care aboutModular provides a library of customizable kernels and microkernels written in Mojo Focus on the subset of the problem for your hardwareEverything else just works we provide fallback legacy long tail kernels for compatibilityExtend the systemas neededAdd new Mojo kernels if you don t find what you re looking for and enable your customers to the sameUse Mojo to directly inject MLIR C C or assembly code as neededLeverage standardized operators and tools to write high level graph transformationsInterested in partnering with us Contact us to discuss how we can work together Contact UsAPI Reference Guides MoreLearn more about our platform EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Blog Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuCompanyOur launch what s nextMay 11 2023Tim DavisCo Founder Chief Product OfficerTim DavisCo Founder Chief Product OfficerRead postFeatured postsProductA unified extensible platform to superpower your AIMay 2 2023 Read postEngineeringThe world s fastest unified matrix multiplicationApril 20 2023 Read postBrowse all postsCompanyOur launch what s nextMay 11 2023 ProductA unified extensible platform to superpower your AIMay 2 2023 EngineeringThe world s fastest unified matrix multiplicationApril 20 2023 EngineeringAI s compute fragmentation what matrix multiplication teaches usMarch 23 2023 CompanyWe want to hear from youDecember 15 2022 EngineeringIf AI serving tech can t solve today s problems how do we scale into the future December 8 2022 EngineeringPart 2 Increasing development velocity of giant AI modelsNovember 10 2022 CompanyModular is rebuilding AI in the face of a new economyNovember 8 2022 DesignModular s Brand StoryAugust 18 2022 EngineeringIncreasing development velocity of giant AI modelsAugust 12 2022 CompanyThe Case for a Next Generation AI Developer PlatformJune 30 2022 CultureHow we workMay 21 2022 CompanyThe future of AI depends on ModularityApril 26 2022 EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Careers Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuPlayJoin us in building the future of AISee open rolesRead about our cultureWe want to enable AI to be used by anyone anywhere Our ambitions are enormous but working here will feel very familiar You can change the world without giving up your lifeWhy Modular Grow with the bestBuild with some of the industry s best AI leaders Maximize how you workWe will always push the limits to create the best possible environment for our people and teams Read how we work Build AI for the worldBuild a next generation developer platform with production quality infrastructure for the world Have fun live lifeRegular team onsites local meetups fun strong team collaboration and more Work life balanced1Leading medical dental and vision packages2Strong compensation equity packages3Generous maternity paternity leave4401K Plan5Work wherever you want6Unlimited Vacation PTO7Corporate perks epic team fun8Great set upWorking at ModularWe believe in a thoughtful framework to family compensation growth and mission each of these elements is critical to anyone living a balanced and fulfilling life We want to ensure that you have a place to achieve the right mix We re trusting empoweringWe trust that you will hold our values and standards This means we don t micromanage you We write things downThis is key to being asynchronous It allows real time discussions to be more thoughtful and contextually driven We have levelsWe acknowledge levels of experience upfront and have a transparent and well defined leveling system Learn about usI am truly impressed with the collective experience of the Modular team in building some of the industry s most widely used AI systems and tools And humbled and excited to be part of this team in our journey to build the next generation AI platform and infrastructure for the world Amit AgarwalCloud Infrastructure LeadI picked modular because of the people and what they believe in and what they want to do I want to be a part of something that makes a difference for the better Paige BedwellProgram ManagerI joined because there is literally no better team on the planet to rebuild AI It s a once in a lifetime opportunity I m building for the world and working with the best River RiddleAI Compiler EngineerWe are a set of world class engineers and leaders who really deeply understand this problem and have solved it to varying degrees of success before Now we are committed to solving it the right way Aman LaChapelleAI Compiler EngineerThe team is incredible They re very smart They re experts in their field and we re solving the hardest computational problems in the world Abdul DakkakAI Compiler EngineerThe best part of working here is a strong commitment to culture I work on the most challenging problems have the freedom to do it anywhere and have a huge impact on AI Eric JohnsonProduct LeadJoin our teamCome and be part of a world class team that is rebuilding AI for everyone We welcome applications from all backgrounds and communities EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use About Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuWe are world leaders in AI infrastructure We contributed to so much of it now we are reinventing it We believe that AI is a net positive force in the world and will help transform it for the better Our vision and mission are to reinvent AI infrastructure to advance humanity and our surroundingsRead our visionHow it startedChris Lattner and Tim Davis met at Google and felt AI was being held back by overly complex and fragmented infrastructure Motivated by a desire to accelerate the impact of AI on the world by lifting the industry towards production quality AI software they founded Modular Together with a team of the world s best AI infrastructure leaders a mix of engineers product managers designers and operational and infrastructure talent from the leading AI companies we are reinventing and rebuilding AI for everyone Our leadership teamChris LattnerCo Founder CEOTim DavisCo Founder Chief Product OfficerAmit AgarwalCloud Infrastructure LeadEric JohnsonProduct LeadMike EdwardsOperations LeadNick KreegerFramework Engineering LeadTatiana ShpeismanCompiler Engineering LeadMeet more of the teamBacked by the best investors in AIOur culture and values1Build it rightCustomers firstWe build technology to lift the world by solving our customers problems We are clear that our customers always come first and we always deliver on our promises Build it rightWe build high quality production software that displays technical mastery inside and out We make our infrastructure the right way as we understand compounding technical debt Drive resultsWhen our customers and their people succeed our company succeeds No matter their role every employee contributes to our collective success We all win when we drive results that actually matter 2Empower peopleOwnershipWe act on behalf of the entire organization and not just for ourselves and our local team We operate on the assumption that each person is highly motivated and will drive their work with a bias towards action TransparencyWe are transparent by having decisions calendars directions and plans open to everyone in the company Anyone can constructively ask tough questions and feel safe to have answers provided directly Hire the best never stop learningWe hire great people who seek to constantly grow themselves and others around them Great people develop great people they take coaching others seriously and look to raise the standards Have fun live lifeWe believe people do their best work when they are happy 3Be an incredible teamWin together fail togetherChanging the world is a team sport Individual wins or mistakes matter less than everyone winning failing learning and growing together Own inclusion be diverseWe build for everyone and we are open to everyone We believe that the best results come from a team that reflects the world at large Everyone has a voiceWe expect the best concept design plan or direction to succeed regardless of someone s rank in the company Assume positive intentWe expect everyone to assume the best of others We re all human and often jump to conclusions we want people to assume good intentions when we do 1Build products users love2Empower people3Be an incredible teamRead about our cultureCome reinvent AI with us EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use About Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuWe are world leaders in AI infrastructure We contributed to so much of it now we are reinventing it We believe that AI is a net positive force in the world and will help transform it for the better Our vision and mission are to reinvent AI infrastructure to advance humanity and our surroundingsRead our visionHow it startedChris Lattner and Tim Davis met at Google and felt AI was being held back by overly complex and fragmented infrastructure Motivated by a desire to accelerate the impact of AI on the world by lifting the industry towards production quality AI software they founded Modular Together with a team of the world s best AI infrastructure leaders a mix of engineers product managers designers and operational and infrastructure talent from the leading AI companies we are reinventing and rebuilding AI for everyone Our leadership teamChris LattnerCo Founder CEOTim DavisCo Founder Chief Product OfficerAmit AgarwalCloud Infrastructure LeadEric JohnsonProduct LeadMike EdwardsOperations LeadNick KreegerFramework Engineering LeadTatiana ShpeismanCompiler Engineering LeadMeet more of the teamBacked by the best investors in AIOur culture and values1Build it rightCustomers firstWe build technology to lift the world by solving our customers problems We are clear that our customers always come first and we always deliver on our promises Build it rightWe build high quality production software that displays technical mastery inside and out We make our infrastructure the right way as we understand compounding technical debt Drive resultsWhen our customers and their people succeed our company succeeds No matter their role every employee contributes to our collective success We all win when we drive results that actually matter 2Empower peopleOwnershipWe act on behalf of the entire organization and not just for ourselves and our local team We operate on the assumption that each person is highly motivated and will drive their work with a bias towards action TransparencyWe are transparent by having decisions calendars directions and plans open to everyone in the company Anyone can constructively ask tough questions and feel safe to have answers provided directly Hire the best never stop learningWe hire great people who seek to constantly grow themselves and others around them Great people develop great people they take coaching others seriously and look to raise the standards Have fun live lifeWe believe people do their best work when they are happy 3Be an incredible teamWin together fail togetherChanging the world is a team sport Individual wins or mistakes matter less than everyone winning failing learning and growing together Own inclusion be diverseWe build for everyone and we are open to everyone We believe that the best results come from a team that reflects the world at large Everyone has a voiceWe expect the best concept design plan or direction to succeed regardless of someone s rank in the company Assume positive intentWe expect everyone to assume the best of others We re all human and often jump to conclusions we want people to assume good intentions when we do 1Build products users love2Empower people3Be an incredible teamRead about our cultureCome reinvent AI with us EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Vision Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuEnable AI to be used by anyone anywhereOur mission is to have real positive impact in the world by reinventing the way AI technology is developed and deployed into production with a next generation developer platformAI can change the world but not until the core infrastructure upon which it is built is fixed and industry fragmentation healed The opportunity cost is not measured in dollars alone AI can truly save lives It can improve dialogue within societies It can better humanity the environment and our futures We have no time to wait Why we created ModularAfter working for years at the world s largest technology companies scaling the world s largest AI work loads building the hardware that powers them and deploying AI to billions of mobile phones and edge devices we saw that fragmentation and technical complexity held back the impact to a privileged few The rest of the world isn t benefiting as it should be from this transformational technology We aim to push the whole world of AI forward not just a select few companies and products To do that we need to rethink the current AI systems and infrastructure from first principles to make it easy for anyone to leverage AI to solve the world s most critical problems with software that just works Modular and composable infrastructure that simplifies AI development and deployment is what the world needs Learn About usOur goal is as enormous as it is profound The only way to succeed is to build a different kind of company to achieve this We have assembled the best AI software and hardware leaders and are systematically rebuilding the AI software stack from the ground up The software that powers AI was created by researchers for research But that time is now over AI is no longer a research projectThe next generation ML system needs to be production quality and meet developers where they are AI shouldn t be something you need to shape your application around This is the only way to reduce fragmentation and unlock the next generation of hardware data and algorithmic innovations It is time to incorporate the lessons learned into a single modular and composable system that integrates the best known technologies from across the industry It must be natively multi framework multi cloud and multi hardware It needs to combine the best performance with the best usability Blog PostsCompanyMay 11 2023Our launch what s nextTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerProductMay 2 2023A unified extensible platform to superpower your AIChris Lattner Co Founder CEOChris Lattner Co Founder CEOTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerEric Johnson Product LeadEric Johnson Product LeadRosane Vallim Product ManagerRosane Vallim Product ManagerEngineeringApril 20 2023The world s fastest unified matrix multiplicationAbdul Dakkak AI Compiler EngineerAbdul Dakkak AI Compiler EngineerChad Jarvis AI Performance EngineerChad Jarvis AI Performance EngineerEric Johnson Product LeadEric Johnson Product LeadHengjie Wang AI Performance EngineerHengjie Wang AI Performance EngineerIan Tramble AI Performance EngineerIan Tramble AI Performance EngineerEngineeringMarch 23 2023AI s compute fragmentation what matrix multiplication teaches usEric Johnson Product LeadEric Johnson Product LeadAbdul Dakkak AI Compiler EngineerAbdul Dakkak AI Compiler EngineerChad Jarvis AI Performance EngineerChad Jarvis AI Performance EngineerCompanyDecember 15 2022We want to hear from youRosane Vallim Product ManagerRosane Vallim Product ManagerCompanyApril 26 2022The future of AI depends on ModularityChris Lattner Co Founder CEOChris Lattner Co Founder CEOTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerCompanyJune 30 2022The Case for a Next Generation AI Developer PlatformChris Lattner Co Founder CEOChris Lattner Co Founder CEOTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerEric Johnson Product LeadEric Johnson Product LeadEngineeringAugust 12 2022Increasing development velocity of giant AI modelsRiver Riddle AI Compiler EngineerRiver Riddle AI Compiler EngineerEric Johnson Product LeadEric Johnson Product LeadEngineeringDecember 8 2022If AI serving tech can t solve today s problems how do we scale into the future Amit Agarwal Cloud Infrastructure LeadAmit Agarwal Cloud Infrastructure LeadEric Johnson Product LeadEric Johnson Product LeadCultureMay 21 2022How we workChris Lattner Co Founder CEOChris Lattner Co Founder CEOTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerCompanyNovember 8 2022Modular is rebuilding AI in the face of a new economyChris Lattner Co Founder CEOChris Lattner Co Founder CEOTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerEngineeringNovember 10 2022Part 2 Increasing development velocity of giant AI modelsAbdul Dakkak AI Compiler EngineerAbdul Dakkak AI Compiler EngineerEric Johnson Product LeadEric Johnson Product LeadRiver Riddle AI Compiler EngineerRiver Riddle AI Compiler EngineerDesignAugust 18 2022Modular s Brand StoryTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerEric Johnson Product LeadEric Johnson Product LeadMatt Ellis MetaLab Brand DirectorMatt Ellis MetaLab Brand DirectorLearn more about us EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Team Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuMeet the team building thefuture of AI for the worldOur team brings experience from the largest and most sophisticated technology companies in the worldWe have built and contributed to foundational AI technologies like TensorFlow PyTorch TF Lite XLA TPUs ONNXRuntime Android Apple Neural Engine MLIR LLVM Clang Swift and more We are world leading experts in compilers runtimes distributed computation and hardware and have deployed production workloads to billions of users and devices Team membersChris LattnerCo Founder CEOChris LattnerCo Founder CEODistinguished Leader who founded and scaled critical infrastructure including LLVM Clang MLIR Cloud TPUs and the Swift programming language Chris built AI and core systems at multiple world leading technology companies including Apple Google SiFive and Tesla clattner modular comRecent posts CloseTim DavisCo Founder Chief Product OfficerTim DavisCo Founder Chief Product OfficerRepeat Entrepreneur and Product Leader Tim helped build found and scale large parts of Google s AI infrastructure at Google Brain and Core Systems from APIs TensorFlow Compilers XLA MLIR and runtimes for server CPU GPU TPU and TF Lite Mobile Micro Web Android ML NNAPI large model infrastructure OSS for billions of users and devices Loves running building products to help people and the world tim modular comRecent posts CloseAmit AgarwalCloud Infrastructure LeadAmit AgarwalCloud Infrastructure LeadEngineering leader with 15 years of experience building shipping and operating AI ML HPC distributed computing frameworks and cloud platforms at the scale of millions of users and thousands of enterprises Grew teams and scaled the design and implementation of deep learning frameworks personalized speech recognition and conversational AI services at Microsoft Amit also scaled and optimized speech and computer vision runtimes including GPU acceleration and ASICs Amit enjoys hiking playing billiards and exploring the world with his family in his free time Recent posts CloseEric JohnsonProduct LeadEric JohnsonProduct LeadProduct leader who has built and scaled AI applications and infrastructure Eric led the TensorFlow API Compiler and Runtime teams at Google Brain and Core Systems including the founding of TFRT and the productionization of JAX He holds an MBA from Wharton and Computer Science MS from Penn and loves soccer fitness and the great outdoors eric modular comRecent posts CloseMike EdwardsOperations LeadMike EdwardsOperations LeadMike has spent over 25 years working in the fields of IT corporate operations and software development most recently at Apple Mike volunteers his time serving as a Board member with the LLVM Foundation focusing on finance and operations Mike truly believes in the power of AI to help address some of the world s greatest needs Recent posts CloseNick KreegerFramework Engineering LeadNick KreegerFramework Engineering LeadSoftware Engineering lead with over 15 years of experience working at Google Microsoft and a handful of startups Nick has contributed to many technologies in Machine Learning such as TensorFlow js TensorFlow Lite Micro and ONNX ONNXRuntime Nick enjoys spending his free time with family and enjoying the Minnesotan outdoors Recent posts CloseTatiana ShpeismanCompiler Engineering LeadTatiana ShpeismanCompiler Engineering LeadLeader in compilers programming models and AI systems Before joining Modular Tatiana led CPU and GPU compiler infrastructure for Google ML co founded MLIR and was a Principal Engineer and Director of Programming Systems Research at Intel Labs Tatiana has published 40 research papers holds 50 US and international patents and has served on numerous research conference programming committees including being Co Chair of CGO 2022 Recent posts CloseAbdul DakkakAI Compiler EngineerAbdul DakkakAI Compiler EngineerExpert in machine learning compilers programming languages and accelerated computing Before Modular Abdul led the development of AI compilers for GPUs at Microsoft Research and the Mathematica Compiler at Wolfram Research Abdul has developed open source tools for accelerating real world applications to optimize their performance across the hardware and software stack Recent posts CloseAditya BhagwatAI Framework EngineerAditya BhagwatAI Framework EngineerAditya is a software engineer who is passionate about machine learning systems and enjoys crafting elegant software solutions to complex problems At Modular he s working on building the next generation of frameworks enabled by the latest innovations in our stack Before joining Modular he was busy getting his master s degree in AI from Carnegie Mellon University In his free time he enjoys listening to classical music cooking and reading Recent posts CloseAlex KirchhoffAI Performance EngineerAlex KirchhoffAI Performance EngineerAlex is a software engineer specializing in low level systems performance Alex previously worked on AI inference in firmware at Apple and designed substantial portions of Xnor ai s inference stack Alex also has a background in computer security and vulnerability research with a focus in reverse engineering and binary exploitation Alex cares about program correctness understandability and efficiency and enjoys learning how things work as well as their failure modes Alex holds a Bachelor of Science in Computer Science from the University of Washington with a minor in Mathematics Recent posts CloseAlexandr NikitinAI Cloud EngineerAlexandr NikitinAI Cloud EngineerAlex is a software engineer with over 15 years of experience who is passionate about building efficient fault tolerant and high performance systems Prior to joining Modular he led the Einstein Platform ML Serving solution at Salesforce which scaled to support hundreds of thousands of ML models and prior to that build extremely high performance ads systems In his free time Alex enjoys mountaineering climbing and trail running Recent posts CloseAman LaChapelleAI Compiler EngineerAman LaChapelleAI Compiler EngineerAman specializes in building and deploying complex technologies on a variety of platforms He has and continues to design and build cutting edge compiler and runtime stacks for novel accelerators heterogeneous SoCs and traditional server deployments at companies like Apple and SambaNova Systems Aman cares deeply about democratizing state of the art technology Recent posts CloseAndrew DingTechnical Program ManagerAndrew DingTechnical Program ManagerAndrew is an experienced technical program manager passionate about solving real world problems that improve the lives of people through technology Before Modular he taught machine learning as a graduate student instructor at the University of California Berkeley before working at LinkedIn and Plaid to scale and improve their reliability and ML infrastructure In his spare time he enjoys playing Poker Recent posts CloseArjun SurendranAI Framework EngineerArjun SurendranAI Framework EngineerArjun specializes in the intersection of Machine Learning and Software Engineering Prior to joining Modular he was a Machine Learning Engineer on Adobe s On Device Machine Learning team Arjun is passionate about making things simpler and accessible to a wider audience and enjoys tinkering with system level software and learning about programming languages internals Recent posts CloseBlake HuangProgram Co ordinatorBlake HuangProgram Co ordinatorA recruiter and scheduling master who has had multiple roles at AT T Meta and SiFive Loves startup life and co ordinating everything Recent posts CloseBrendan DukeAI Framework EngineerBrendan DukeAI Framework EngineerBrendan is adept at building systems spanning the software and machine learning stack Brendan started his career by writing firmware for the AMD Secure Processor He then went on to complete his master s in machine learning at the University of Guelph He has since focused on state of the art deep learning tech for the past 5 years Most recently Brendan designed a deep learning tech stack optimized to deploy AR experiences to the web on mobile devices while at Modiface When away from the keyboard Brendan enjoys spending time with his fiancée and family and exploring Hamilton with his goldendoodle Hank Recent posts CloseBrian GesiakAI Compiler EngineerBrian GesiakAI Compiler EngineerExperienced compiler engineer with an interest in modern programming language design Before joining Modular Brian spent nearly a decade at Meta working on a variety of compiler projects including LLVM Clang and the Move programming language Brian believes that Modular has the opportunity to push forward the state of the art of programming languages and their user experience and is thrilled to help build that future Recent posts CloseChad JarvisAI Performance EngineerChad JarvisAI Performance EngineerChad has a strong background in low level code optimization parallel programming and high performance computing He has worked for more than 17 years in research and engineering in Europe and North America He holds a PhD in particle physics and is one of the authors of the Higgs Boson discovery Chad has a passion and focus for understanding things at a fundamental level Prior to joining Modular he worked at Graphcore working closely with the hardware engineers to implement and optimize custom features of the GC hardware and before that Simula Research Laboratory among many other distinguished research facilities He enjoys spending his spare time with his family travelling collecting rare coins and eating excellent food Recent posts CloseChristopher NiesAI Cloud EngineerChristopher NiesAI Cloud EngineerSouthern California tech nerd turned Bay Area Cloud Engineer now enjoying a healthy mix of both Spent 5 years building Hearth s infrastructure stack from the ground up from the first Ruby on Rails model to Director of Backend Engineering Likes Dungeons and Dragons puzzles and being near the ocean Recent posts CloseDan MoldovanAI Framework EngineerDan MoldovanAI Framework EngineerDan has over 15 years of software engineering experience in a wide variety of fields and roles Before Modular Dan worked in teams such as Google Brain and TensorFlow where he co authored AutoGraph led improvements to system architecture graph representations and APIs developed ML and TensorFlow training material and collaborated with ML researchers Dan is passionate about developing next generation programming languages for machine learning Dan enjoys hiking stargazing and traveling around the world Recent posts CloseDeep DhillonAI Cloud EngineerDeep DhillonAI Cloud EngineerDeep is a passionate Cloud Infrastructure Engineer who enjoys building automating and deploying highly scalable applications He is a recent graduate from the University of Waterloo and before Modular he worked at Google developing Kubernetes based database infrastructure for Google Distributed Cloud Hosted In his free time Deep enjoys travelling to new places taking photos and playing sports Deep is now building cloud AI ML infrastructure at Modular Recent posts CloseFabian TschoppAI Framework EngineerFabian TschoppAI Framework EngineerFabian is adept at engineering AI infrastructure that enables AI for everyone since the early days of machine learning frameworks Fabian designed the official OpenCL version of Caffe while studying computer science and neural systems at ETH Zürich working together with AMD and Intel He joins Modular after most recently working on PyTorch ONNX and PopART for Graphcore s IPU AI accelerator hardware Originally from Switzerland Fabian now resides in Norway where he enjoys spending time with his fiancée and daughter When away from the keyboard Fabian can be found rowing during summer and cross country skiing during winter Recent posts CloseGoldie GaddeTechnical Program ManagerGoldie GaddeTechnical Program ManagerLead Technical Program Manager with 18 years of industry experience working at Google Brain and Cisco in a variety of roles and technologies from enabling Google s revolutionary data centers to enabling ML for the world Goldie has a consistent track record in solving problems that involve technical and organizational complexities Prior to joining Modular Goldie was the lead TPM for TensorFlow Keras APIs at Google Core ML driving the roadmap of next gen ML APIs while enabling AI ML for Waymo YouTube Ads and many other teams at Google She holds a MS in Electrical Engineering from University of California Irvine and in her free time enjoys hiking and traveling the world with her family Recent posts CloseHengjie WangAI Performance EngineerHengjie WangAI Performance EngineerHengjie Wang is a software engineer focusing on performance optimizations for AI and scientific applications He has many years of experience in developing and optimizing large scale scientific applications on world ranking supercomputers He has also developed Deep learning algorithms to advance physical simulations Before joining Modular he was a postdoctoral scholar in the Lawerence Berkeley National Lab where he participated in developing the Exa scale projects MFIX Exa and AMReX on national supercomputers He is a big fan of Go and enjoys hiking and dog training Recent posts CloseIan TrambleAI Performance EngineerIan TrambleAI Performance EngineerExperienced systems software engineer with a background in performance and accelerated computing Before joining Modular Ian spent 5 years at NVIDIA working on MLPerf Inference TensorRT and systems software for autonomous vehicles He is passionate about providing great out of the box performance by abstracting hardware Ian graduated from the Engineering Science program at the University of Toronto with a major in electrical and computer engineering Recent posts CloseJakub TucholskiAI Cloud EngineerJakub TucholskiAI Cloud EngineerWorking on web infrastructure since AWS offered only 2 services S3 EC2 Past stints include automating global capacity management and improving maps reliability at Uber and helping scale Heath from 0 to 1 million ARR Likes Robert Caro death metal Magic the Gathering and deterministic builds Recent posts CloseJames DeckerAI Compiler EngineerJames DeckerAI Compiler EngineerJames is passionate about building tools that boost programmer productivity focusing on compilers for heterogeneous computing and AI acceleration while at Purdue Stanford Google and SambaNova Systems James believes deeply that technology and AI in particular must be fair to be beneficial which necessitates that it is easy to use and understand Recent posts CloseJeff NiuAI Compiler EngineerJeff NiuAI Compiler EngineerCompiler Engineer MLIR Developer and former Robotics Hacker Jeff studied Mechatronics Engineering at the University of Waterloo where he explored his passion for Robotics before falling in love with MLIR and Compilers while at Google where he worked making TensorFlow faster and better for everyone Jeff is now developing MLIR based compilers at Modular to make AI better for the World Recent posts CloseJoe LoserAI Framework EngineerJoe LoserAI Framework EngineerExpert in C and low latency programming Before Modular Joe was at Quantlab writing cutting edge C generic libraries for real time trading systems that push the boundaries of performance for software and hardware In his free time Joe enjoys traveling hiking and spending time with his fiancé and dog Recent posts CloseJuan GalvezAI Framework EngineerJuan GalvezAI Framework EngineerExpert in high performance computing parallel computing concurrency models runtime systems and accelerating big data analytics Before Modular Juan led parallelization and performance development of Bodo ai s compute and query execution engine Juan was a core developer of Charm at UIUC a production parallel programming framework used by supercomputing applications that scale to millions of cores and is the author of Charm4py Recent posts CloseKate CaldwellAI Framework EngineerKate CaldwellAI Framework EngineerKate is a machine learning engineer passionate about optimizing AI deployment and broadening the impact of developments in the field Before Modular Kate worked as as a Machine Learning Research Apprentice while studying for her MS in Computer Science at Northeastern University In her free time Kate likes book clubs cooking and feeding her dog treats Recent posts CloseKevin BuchsAI Cloud EngineerKevin BuchsAI Cloud EngineerWorked at the Mayo Clinic s Special Purpose Processor Development Group performing research developing advanced high speed electronics with novel materials and technologies creating CAD systems software for advanced testing analysis and simulation Helped scale Cloud Engineering DevOps across large large workloads on AWS Azure and GCP Worked with infrastructure as code mostly using Terraform Python is my love language When I m not helping scale Cloud I enjoy time with my two grown children and 8 grandchildren Recent posts CloseLaszlo KindratAI Compiler EngineerLaszlo KindratAI Compiler EngineerLaszlo is a former data scientist turned software engineer Before Modular he built XMOS s first ML compiler and maintained their TFLite Micro runtime then worked as lead engineer on the MLIR based software stack at Luminous Computing He enjoys traveling and all New England seasons Recent posts CloseLiam StewartAI Cloud EngineerLiam StewartAI Cloud EngineerA software engineer with over 15 years of industry experience Liam is passionate about building software and systems to address practical problems in robust and forward looking ways Liam has built operated and scaled cloud systems at a variety of companies including Google Strava and most recently PagerDuty When not at work he can usually be found outside riding bikes and spending time with his family Recent posts CloseLiina LindSenior Recruiting ManagerLiina LindSenior Recruiting ManagerLiina is an experienced talent acquisition specialist and leader who most recently built and shaped the global TA process at SiFive With previous work experience in Japan the US and Europe Liina has joined Modular to build a global and world class team who will reinvent the AI infrastructure for the world Recent posts CloseLily Orth SmithAI Compiler EngineerLily Orth SmithAI Compiler EngineerLily is a machine learning compiler engineer with a passion for programming languages In her daily work she likes solving engineering design problems elegantly and practically Before Modular Lily worked on Apache TVM an open source machine learning compiler at OctoML In her free time Lily loves being outdoors hiking biking and gardening She also enjoys woodworking and ceramics Recent posts CloseMark ShieldsAI Framework EngineerMark ShieldsAI Framework EngineerMark s engineering career has spanned programming languages and compilers maps and transport routing streaming dataflow and most recently deep learning compilers He joins Modular after most recently working on Apache TVM and before that a distinguished career at Google Mark is now looking forward to radically reducing the accidental complexity in model compilation deployment and monitoring Mark lives with his family in Seattle and is a keen back country hiker trail runner climber and renovator Recent posts CloseMatthew BrookhartAI Compiler EngineerMatthew BrookhartAI Compiler EngineerSoftware Engineering lead with a strong background in mathematics optimization and team management Matthew comes to Modular with over 7 years of experience working on AI models and Compilers at large companies like Intel and small startups working on technologies like TVM He s a total coding nerd and loves picking up new programming languages and tracking down bugs Matthew enjoys spending his free time hiking in the Wasatch Mountains and loves to bake delicious breads and pizzas for his family Recent posts CloseMikhail ZolotukhinAI Compiler EngineerMikhail ZolotukhinAI Compiler EngineerExpert in traditional and ML compilers with over 15 years of experience in the field Before Modular Michael contributed to Intel Compiler GCC LLVM and most recently PyTorch He is passionate about building right things the right way and excited to do that at Modular to help power AI for the world Recent posts ClosePaige BedwellProgram ManagerPaige BedwellProgram ManagerPaige has spent several years building an impressive set of leadership logistic and operational skills in the industries of executive concierge management and outdoor adventure experiences Paige joined Modular with the vision and aspiration to help AI change the world for the better Recent posts ClosePatrick BeckSenior IT SpecialistPatrick BeckSenior IT SpecialistPatrick is an IT professional who loves wearing all the different hats after working for more than 7 years at Thumbtack helping to scale out their IT infrastructure security and systems from its earliest days After mastering IT Support Patrick learned device and systems management and is now working to tackle all the IT challenges at Modular Outside work Patrick is an avid gardener and aspiring farmer Recent posts CloseRiver RiddleAI Compiler EngineerRiver RiddleAI Compiler EngineerSoftware Architect Compiler Engineer and Programming Language enthusiast River is a leader within MLIR and has driven core developments since its inception Before joining Modular he developed and evangelized MLIR within Google ML working with TensorFlow JAX Google Tensor and more River is passionate about his family staying fit and crafting cutting edge developer technology Recent posts CloseRosane VallimProduct ManagerRosane VallimProduct ManagerProduct manager with a long experience designing and delivering ML experiences and infrastructure at scale Prior to joining Modular Rosane led the Windows ML and DirectML product teams at Microsoft She holds a PhD in Machine Learning and loves traveling reading and spending time with her family and dog Recent posts CloseRyan GuoAI Compiler EngineerRyan GuoAI Compiler EngineerRyan is a passionate compiler engineer Before Modular he worked on auto vectorization while studying at UIUC and Flashlight while interning at FAIR He cares about building things the right way and having positive impact on people s lives When he s not coding rhino videos and piano keep him sane Recent posts CloseScott MainAI Technical WriterScott MainAI Technical WriterScott is an experienced lead writer with diverse skills in technology and product development He s passionate about designing developer experiences that are simple and intuitive and documentation that is clear concise and complete Previously Scott led various documentation projects at Google including for Android and Coral Edge TPU Recent posts CloseSean ParadisoAI Framework ManagerSean ParadisoAI Framework ManagerEngineering leader with experience managing teams across the full stack from ML algorithms to high scale production services Sean served as VP Platform Engineering at Citrine Informatics building an ML platform for novel materials and chemicals discovery before joining Twitter to lead the ML Serving team supporting key high scale infrastructure such as ads serving and timeline ranking In his free time Sean enjoys rock climbing wandering in the woods and scouting for tractors with his 2 year old son Leo Recent posts CloseSrinivasan NarayanamoorthyAI Framework EngineerSrinivasan NarayanamoorthyAI Framework EngineerSrini is an AI framework engineer focussing on performance across the stack from graph optimizations to low level kernel threading optimizations Before modular he was at Intel for almost 10 years performing various roles from CPU hardware development to Tensorflow optimizations Srini enjoys spending time with his family and playing cricket during summers Recent posts CloseSteffi StumposAI Compiler EngineerSteffi StumposAI Compiler EngineerSteffi is a software engineer focused on compiler development Before Modular she was a member of Meta s Probability organization where she contributed to projects in the fields of Differentiable Programming Probabilistic Programming and GPGPU optimization When not at her desk Steffi can be found rock climbing in the hills of Colorado Recent posts CloseStephen McGroartyAI Compiler EngineerStephen McGroartyAI Compiler EngineerStephen is an experienced software engineer with an interest in machine learning compilers computer architecture and optimization Before joining Modular he worked at the intersection of these working on compilers for heterogeneous systems at Codeplay and then built out PyTorch integration at Graphcore with work optimizing performance across the stack In his spare time he enjoys the Californian sunshine and skiing in the winter months Recent posts CloseTaewook OhAI Framework EngineerTaewook OhAI Framework EngineerSoftware engineer specializing in compilers and runtimes Before Modular Taewook tech led multiple compiler teams at Meta and Samsung from a LLVM compiler team for server side applications to a team that builds a compiler for hardware accelerators He has served the compiler research community as a conference committee member of CGO and LCTES Recent posts CloseTyler KenneyAI Performance EngineerTyler KenneyAI Performance EngineerTyler is a performance optimization hardware acceleration specialist He holds bachelor s and master s degrees in computer engineering from Lehigh University Prior to Modular Tyler developed compilers simulators instruction sets and kernel libraries for AI accelerators first at IBM and then at Lightmatter He is passionate about forecasting technology and understanding to the best of his ability the long term impacts of artificial intelligence On weekends Tyler enjoys anything and everything outside particularly running camping playing ultimate frisbee boating wakeboarding and skiing Recent posts CloseYihua LouAI Cloud EngineerYihua LouAI Cloud EngineerExperienced software engineer across a broad range of technologies Prior to Modular Lou graduated with a bachelor s in Computer Science from the University of Illinois Urbana Champaign before working on mobile apps and NLP infrastructure for search and other applications at Google for 9 years Avid video gamer and orange cat enthusiast Recent posts CloseLearn more about us EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Newsletter Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuNewsletter SignupGet all our latest news announcements and updates delivered directly to your inbox You can unsubscribe at anytime Blog PostsCompanyMay 11 2023Our launch what s nextTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerProductMay 2 2023A unified extensible platform to superpower your AIChris Lattner Co Founder CEOChris Lattner Co Founder CEOTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerEric Johnson Product LeadEric Johnson Product LeadRosane Vallim Product ManagerRosane Vallim Product ManagerEngineeringApril 20 2023The world s fastest unified matrix multiplicationAbdul Dakkak AI Compiler EngineerAbdul Dakkak AI Compiler EngineerChad Jarvis AI Performance EngineerChad Jarvis AI Performance EngineerEric Johnson Product LeadEric Johnson Product LeadHengjie Wang AI Performance EngineerHengjie Wang AI Performance EngineerIan Tramble AI Performance EngineerIan Tramble AI Performance EngineerEngineeringMarch 23 2023AI s compute fragmentation what matrix multiplication teaches usEric Johnson Product LeadEric Johnson Product LeadAbdul Dakkak AI Compiler EngineerAbdul Dakkak AI Compiler EngineerChad Jarvis AI Performance EngineerChad Jarvis AI Performance EngineerCompanyDecember 15 2022We want to hear from youRosane Vallim Product ManagerRosane Vallim Product ManagerCompanyApril 26 2022The future of AI depends on ModularityChris Lattner Co Founder CEOChris Lattner Co Founder CEOTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerCompanyJune 30 2022The Case for a Next Generation AI Developer PlatformChris Lattner Co Founder CEOChris Lattner Co Founder CEOTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerEric Johnson Product LeadEric Johnson Product LeadEngineeringAugust 12 2022Increasing development velocity of giant AI modelsRiver Riddle AI Compiler EngineerRiver Riddle AI Compiler EngineerEric Johnson Product LeadEric Johnson Product LeadEngineeringDecember 8 2022If AI serving tech can t solve today s problems how do we scale into the future Amit Agarwal Cloud Infrastructure LeadAmit Agarwal Cloud Infrastructure LeadEric Johnson Product LeadEric Johnson Product LeadCultureMay 21 2022How we workChris Lattner Co Founder CEOChris Lattner Co Founder CEOTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerCompanyNovember 8 2022Modular is rebuilding AI in the face of a new economyChris Lattner Co Founder CEOChris Lattner Co Founder CEOTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerEngineeringNovember 10 2022Part 2 Increasing development velocity of giant AI modelsAbdul Dakkak AI Compiler EngineerAbdul Dakkak AI Compiler EngineerEric Johnson Product LeadEric Johnson Product LeadRiver Riddle AI Compiler EngineerRiver Riddle AI Compiler EngineerDesignAugust 18 2022Modular s Brand StoryTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerEric Johnson Product LeadEric Johnson Product LeadMatt Ellis MetaLab Brand DirectorMatt Ellis MetaLab Brand DirectorLearn more about us EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Our Culture Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuA great culture is the key to creating a great company Build products users loveCustomers firstWe build technology to lift the world by solving our customers problems We understand our users problems and use cases and know there is sometimes a trade off between what is important and what is interesting when building technology We are clear that our customers always come first and we always deliver on our promises Build it rightWe build high quality production software that displays technical mastery inside and out We make our infrastructure the right way because we understand how quickly technical debt compounds We know how faster engineering product development and business metrics move with a solid foundation We build scalable modular and reliable systems that meet our customers needs Drive resultsWhen our customers and their people succeed our company succeeds No matter their role every employee contributes to our collective success Individually and together we are all aligned on what we are working towards and how we can contribute But we don t just work on auto pilot We expect everyone to regularly step back and ask if we re measuring the right input and output We all win when we drive results that actually matter Empower peopleOwnershipWe act on behalf of the entire organization and not just for ourselves and our local team We operate on the assumption that each person is highly motivated and will drive their work with a bias towards action We drive ownership by tracking progress toward our goals with clear expectations responsible owners and solid execution We expect everyone to act like an owner and once a decision is made everyone will fully commit and move forward together TransparencyWe are transparent by having decisions calendars directions and plans open to everyone in the company Anyone can constructively ask tough questions and feel safe to have answers provided directly We expect people to be clear about what they know and open about what they don t We want everyone to feel that they can be vulnerable in front of each other and feel safe to take risks because this is how we grow and innovate Hire the best never stop learningWe hire great people who seek to constantly grow themselves and others around them Great people don t settle they have a thirst for knowledge and new skills a desire for self improvement and actively seek feedback whenever they can Great people develop great people they take coaching others seriously and look to raise the standards of the whole organization Have fun live lifeWe believe people do their best work when they are happy Our goal is to ensure that you will always have the environment to achieve the right mix of family compensation growth and mission to live a balanced and fulfilling life By having fun and living your life you also see more of the world appreciate it and learn how we can help improve it Be an incredible teamWin together fail togetherChanging the world is a team sport and we need a group of incredibly talented people to be successful Individual wins or mistakes matter less than everyone winning failing learning and growing together We expect everyone to listen speak openly and treat others with respect regardless of the wins or losses along the way We foster a blameless culture for mistakes and we expect our team to take risks without feeling insecure or embarrassed The more we trust each other the more we can lean on each other and the more we can learn and grow together Own inclusion be diverseWe build for everyone and we are open to everyone We believe that the best results come from a team that reflects the world at large Our customers are diverse and so are their needs so we must empower and promote diversity and diverse perspectives at all company levels We need to build diverse teams and foster diverse thinking to create products that genuinely help the world Everyone has a voiceWe expect the best concept design plan or direction to succeed regardless of someone s rank in the company Innovation exists everywhere and great ideas are inside all of us You can always reach out to anyone at any level in the company We foster open communication and constructive debate and expect everyone to accept respectful challenges to their positions We believe that the job of a leader is to find the right answer with their team not to magically know everything themselves Assume positive intentWe expect everyone to assume the best of others Our experiences have shown that information asymmetry almost always exists between people and taking the time to understand circumstances via transparent communication is key to building healthy and functioning teams We re all human and often jump to conclusions we want people to assume good intentions when we do Learn more about us EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Contact Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuLet s talk about Modular s AI Platform We want to hear from you Contact usPresspress modular comPartnershipshello modular comOtherFor any other inquiry please use our existing pages below PRODUCTsGetting Started DiscordCareersCareersLEGALTermsPrivacy PolicyAcceptable UseWe are rebuilding and reinventing AI software at its core to scale and enable the world to realize the true power of data algorithms and compute We are building natively multi framework multi cloud and multi hardware capable products Please email us only for Press or Partnerships otherwise use our other links Blog PostsCompanyMay 11 2023Our launch what s nextTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerProductMay 2 2023A unified extensible platform to superpower your AIChris Lattner Co Founder CEOChris Lattner Co Founder CEOTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerEric Johnson Product LeadEric Johnson Product LeadRosane Vallim Product ManagerRosane Vallim Product ManagerEngineeringApril 20 2023The world s fastest unified matrix multiplicationAbdul Dakkak AI Compiler EngineerAbdul Dakkak AI Compiler EngineerChad Jarvis AI Performance EngineerChad Jarvis AI Performance EngineerEric Johnson Product LeadEric Johnson Product LeadHengjie Wang AI Performance EngineerHengjie Wang AI Performance EngineerIan Tramble AI Performance EngineerIan Tramble AI Performance EngineerEngineeringMarch 23 2023AI s compute fragmentation what matrix multiplication teaches usEric Johnson Product LeadEric Johnson Product LeadAbdul Dakkak AI Compiler EngineerAbdul Dakkak AI Compiler EngineerChad Jarvis AI Performance EngineerChad Jarvis AI Performance EngineerCompanyDecember 15 2022We want to hear from youRosane Vallim Product ManagerRosane Vallim Product ManagerCompanyApril 26 2022The future of AI depends on ModularityChris Lattner Co Founder CEOChris Lattner Co Founder CEOTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerCompanyJune 30 2022The Case for a Next Generation AI Developer PlatformChris Lattner Co Founder CEOChris Lattner Co Founder CEOTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerEric Johnson Product LeadEric Johnson Product LeadEngineeringAugust 12 2022Increasing development velocity of giant AI modelsRiver Riddle AI Compiler EngineerRiver Riddle AI Compiler EngineerEric Johnson Product LeadEric Johnson Product LeadEngineeringDecember 8 2022If AI serving tech can t solve today s problems how do we scale into the future Amit Agarwal Cloud Infrastructure LeadAmit Agarwal Cloud Infrastructure LeadEric Johnson Product LeadEric Johnson Product LeadCultureMay 21 2022How we workChris Lattner Co Founder CEOChris Lattner Co Founder CEOTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerCompanyNovember 8 2022Modular is rebuilding AI in the face of a new economyChris Lattner Co Founder CEOChris Lattner Co Founder CEOTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerEngineeringNovember 10 2022Part 2 Increasing development velocity of giant AI modelsAbdul Dakkak AI Compiler EngineerAbdul Dakkak AI Compiler EngineerEric Johnson Product LeadEric Johnson Product LeadRiver Riddle AI Compiler EngineerRiver Riddle AI Compiler EngineerDesignAugust 18 2022Modular s Brand StoryTim Davis Co Founder Chief Product OfficerTim Davis Co Founder Chief Product OfficerEric Johnson Product LeadEric Johnson Product LeadMatt Ellis MetaLab Brand DirectorMatt Ellis MetaLab Brand DirectorLearn more about us EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Get started today Get started todayModular is a fully integrated composable suite of AI infrastructure tools with unmatched industry performance that streamlines AI workflows Get started today and let us know what products you are interested in We re rolling out access as fast as we can Next Modular Get started today Get started todayModular is a fully integrated composable suite of AI infrastructure tools with unmatched industry performance that streamlines AI workflows Get started today and let us know what products you are interested in We re rolling out access as fast as we can Next Modular Inference Engine Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuThe world s fastest unified AI inference engine Get models into production faster The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions Bring your model as is and deploy it anywhere across server and edge with unparalleled usability and performance Get startedSee our performanceengine P99 Latency 12 1 ms P50P90P95P99TensorFlowPyTorchModular Engine ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size101UnificationTrain in any framework deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude Cloud On PremFrameworksmodular EngineServer edgeFramework optionalityEasily deploy models trained in any framework such as TensorFlow or PyTorch without retraining conversions or pre optimization steps using a unified set of APIs There are no tricks no hacks the Engine just works incredibly fast Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models Avoid lock in and take advantage of price efficiencies and performance improvements without migration costs 02PerformanceMaximize performance minimize costsReduce latency increase throughput and improve resource efficiency across CPUs GPUs and accelerators Productionize larger models and significantly reduce your computing costs Explore our performance dashboardQueries per Second 125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences 0 12TensorFlow 0 89PyTorch 0 54Modular Engine 0 12 ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size1MODULAR ENGINE SPEED UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family vs vs vs vs vs vsLanguage Model3x3 2x5 3x1 4x2 1x4xRecommender Models6 5x5x7 5x1 1x1 2x4 3xVision Models2 1x2 2x1 7x1 5x1 5x1 3xCompute TypeIntel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge Intel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge ResultsAWS Compute Instances TensorFlow PyTorch listed by logo Full performance methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again Run any model including support for all native framework operators dynamic shapes low precision and your existing custom operators DLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseBERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases Our tools are well modular They integrate with industry standard infrastructure and open source tools to minimize migration cost Request accessseamless integration with popular libraries and tools01 Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular s off the shelf NVIDIA Triton and TensorFlow Serving builds 02 Choose your cloudDeploy the engine on prem in your own VPC on any major cloud provider or get up and running quicker with out hosted solutions 03 METRICS MONITORINGThe Modular Inference Engine works with industry standard open source tooling like Prometheus and Grafana Ready to try a preview Contact us to get early access to the Modular Inference Engine Request accessAPI References Tutorials MoreRead the Modular Inference Engine docs EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Inference Engine Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuThe world s fastest unified AI inference engine Get models into production faster The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions Bring your model as is and deploy it anywhere across server and edge with unparalleled usability and performance Get startedSee our performanceengine P99 Latency 12 1 ms P50P90P95P99TensorFlowPyTorchModular Engine ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size101UnificationTrain in any framework deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude Cloud On PremFrameworksmodular EngineServer edgeFramework optionalityEasily deploy models trained in any framework such as TensorFlow or PyTorch without retraining conversions or pre optimization steps using a unified set of APIs There are no tricks no hacks the Engine just works incredibly fast Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models Avoid lock in and take advantage of price efficiencies and performance improvements without migration costs 02PerformanceMaximize performance minimize costsReduce latency increase throughput and improve resource efficiency across CPUs GPUs and accelerators Productionize larger models and significantly reduce your computing costs Explore our performance dashboardQueries per Second 125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences 0 12TensorFlow 0 89PyTorch 0 54Modular Engine 0 12 ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size1MODULAR ENGINE SPEED UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family vs vs vs vs vs vsLanguage Model3x3 2x5 3x1 4x2 1x4xRecommender Models6 5x5x7 5x1 1x1 2x4 3xVision Models2 1x2 2x1 7x1 5x1 5x1 3xCompute TypeIntel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge Intel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge ResultsAWS Compute Instances TensorFlow PyTorch listed by logo Full performance methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again Run any model including support for all native framework operators dynamic shapes low precision and your existing custom operators DLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseBERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases Our tools are well modular They integrate with industry standard infrastructure and open source tools to minimize migration cost Request accessseamless integration with popular libraries and tools01 Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular s off the shelf NVIDIA Triton and TensorFlow Serving builds 02 Choose your cloudDeploy the engine on prem in your own VPC on any major cloud provider or get up and running quicker with out hosted solutions 03 METRICS MONITORINGThe Modular Inference Engine works with industry standard open source tooling like Prometheus and Grafana Ready to try a preview Contact us to get early access to the Modular Inference Engine Request accessAPI References Tutorials MoreRead the Modular Inference Engine docs EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Inference Engine Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuThe world s fastest unified AI inference engine Get models into production faster The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions Bring your model as is and deploy it anywhere across server and edge with unparalleled usability and performance Get startedSee our performanceengine P99 Latency 12 1 ms P50P90P95P99TensorFlowPyTorchModular Engine ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size101UnificationTrain in any framework deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude Cloud On PremFrameworksmodular EngineServer edgeFramework optionalityEasily deploy models trained in any framework such as TensorFlow or PyTorch without retraining conversions or pre optimization steps using a unified set of APIs There are no tricks no hacks the Engine just works incredibly fast Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models Avoid lock in and take advantage of price efficiencies and performance improvements without migration costs 02PerformanceMaximize performance minimize costsReduce latency increase throughput and improve resource efficiency across CPUs GPUs and accelerators Productionize larger models and significantly reduce your computing costs Explore our performance dashboardQueries per Second 125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences 0 12TensorFlow 0 89PyTorch 0 54Modular Engine 0 12 ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size1MODULAR ENGINE SPEED UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family vs vs vs vs vs vsLanguage Model3x3 2x5 3x1 4x2 1x4xRecommender Models6 5x5x7 5x1 1x1 2x4 3xVision Models2 1x2 2x1 7x1 5x1 5x1 3xCompute TypeIntel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge Intel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge ResultsAWS Compute Instances TensorFlow PyTorch listed by logo Full performance methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again Run any model including support for all native framework operators dynamic shapes low precision and your existing custom operators DLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseBERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases Our tools are well modular They integrate with industry standard infrastructure and open source tools to minimize migration cost Request accessseamless integration with popular libraries and tools01 Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular s off the shelf NVIDIA Triton and TensorFlow Serving builds 02 Choose your cloudDeploy the engine on prem in your own VPC on any major cloud provider or get up and running quicker with out hosted solutions 03 METRICS MONITORINGThe Modular Inference Engine works with industry standard open source tooling like Prometheus and Grafana Ready to try a preview Contact us to get early access to the Modular Inference Engine Request accessAPI References Tutorials MoreRead the Modular Inference Engine docs EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Mojo Programming language for all of AI Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuMojo a new programming language for all AI developers Mojo combines the usability of Python with the performance of C unlocking unparalleled programmability of AI hardware and extensibility of AI models Get started with MojoRead the docs SOFTMAX PYMojo pythondef softmax lst norm np exp lst np max lst return norm norm sum def softmax lst norm np exp lst np max lst return norm norm sum struct NDArray def max self NDArray return self pmap SIMD max struct SIMD type DType width Int def max self rhs Self Self return self rhs select self rhs 01Usability ProgrammabilityWrite everything in one languageWrite Python or scale all the way down to the metal Program the multitude of low level AI hardware No C or CUDA required Take a tour of Mojo FILE_NAME def sort v ArraySlice Int for i in range len v for j in range len v i 1 if v j v j 1 swap v j v j 1 FILE_NAME struct MyPair var first Int var second F32 def __init__ self first Int second F32 self first first self second secondFILE_NAME def reorder_and_process owned x HugeArray sort x Update in place give_away x Transfer ownership print x 0 Error x moved away FILE_NAME def exp dt DType elts Int x SIMD dt elts SIMD dt elts x clamp x 88 3762626647 88 37626266 k floor x INV_LN2 0 5 r k NEG_LN2 x return ldexp _exp_taylor r k FILE_NAME def exp_buffer dt DType data ArraySlice dt Search for the best vector length alias vector_len autotune 1 4 8 16 32 Use it as the vectorization length vectorize exp dt vector_len data Features include Progressive TypesLeverage types for better performance and error checking Zero Cost AbstractionsTake control of storage by inline allocating values into structures Ownership borrow checkerTake advantage of memory safety without the rough edges Portable parametric algorithmsLeverage compile time meta programming to write hardware agnostic algorithms and reduce boilerplate LANGUAGE INTEGRATED Auto tuningAutomatically find the best values for your parameters to take advantage of target hardware As well as The full power of MLIRParallel heterogenous runtimeFast compile times FILE_NAME def sort v ArraySlice Int for i in range len v for j in range len v i 1 if v j v j 1 swap v j v j 1 Features include Progressive TypesLeverage types for better performance and error checking FILE_NAME struct MyPair var first Int var second F32 def __init__ self first Int second F32 self first first self second secondFeatures include Zero Cost AbstractionsTake control of storage by inline allocating values into structures FILE_NAME def reorder_and_process owned x HugeArray sort x Update in place give_away x Transfer ownership print x 0 Error x moved away Features include Ownership borrow checkerTake advantage of memory safety without the rough edges FILE_NAME def exp dt DType elts Int x SIMD dt elts SIMD dt elts x clamp x 88 3762626647 88 37626266 k floor x INV_LN2 0 5 r k NEG_LN2 x return ldexp _exp_taylor r k Features include Portable parametric algorithmsLeverage compile time meta programming to write hardware agnostic algorithms and reduce boilerplate FILE_NAME def exp_buffer dt DType data ArraySlice dt Search for the best vector length alias vector_len autotune 1 4 8 16 32 Use it as the vectorization length vectorize exp dt vector_len data Features include LANGUAGE INTEGRATED Auto tuningAutomatically find the best values for your parameters to take advantage of target hardware 02PerformanceUnlock Python performanceUtilize the full power of the hardware including multiple cores vector units and exotic accelerator units with the world s most advanced compiler and heterogenous runtime Achieve performance on par with C and CUDA without the complexity Play with MojoParallelizationMojo leverages MLIR which enables Mojo developers to take advantage of vectors threads and AI hardware units PYTHONSingle threaded executionMojo Parallel processing across multiple coresLanguagesTime S Speedup vs PythonPython 3 10 91027 s1xPypy46 1 s22xScalar C 0 20 s5000xMojo 0 03 s35000x AlgorithmMandelbrotInstanceAWS r7iz metal 16xlIntel Xeon03InteroperabilityAccess the entire Python ecosystemExperience true interoperability with the Python ecosystem Seamlessly intermix arbitrary libraries like Numpy and Matplotlib and your custom code with Mojo Read the programming manual MAKE_PLOT def make_plot m Matrix plt Python import_module matplotlib pyplot fig plt figure 1 10 10 yn xn 64 ax fig add_axes 0 0 0 0 1 0 1 0 False 1 plt imshow image plt show make_plot compute_mandelbrot Mojo 04ExtensibilityUpgrade your models and the Modular stackEasily extend your models with pre and post processing operations or replace operations with custom ones Take advantage of kernel fusion graph rewrites shape functions and more Model extensibilityMojo can upgrade the existing operations in your model Input layerHidden layersOutput layer05GET STARTED NOWTry Mojo out right now in our PlaygroundMojo is still a work in progress but it s available to try today in our JupyterHub based Playground Run through tutorials and write your own Mojo code Sign up for accessMojo 01 EASY TO GET STARTEDWe have plenty of easy to use Jupyter notebooks to help you get started learning Mojo 02 Unleash your mojoOur docs will help you quickly discover why Mojo is such a powerful extension to Python and the future of AI programming 03 JOIN the mojo COMMUNITYCome and chat with us on our Discord and help shape the future of the language as we continue to develop it Ready to play with Mojo Reach out to gain access to the Mojo Playground Request accessAPI Reference Tutorials MoreRead the Mojo docs EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Get started today Get started todayModular is a fully integrated composable suite of AI infrastructure tools with unmatched industry performance that streamlines AI workflows Get started today and let us know what products you are interested in We re rolling out access as fast as we can Next Modular Inference Engine Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuThe world s fastest unified AI inference engine Get models into production faster The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions Bring your model as is and deploy it anywhere across server and edge with unparalleled usability and performance Get startedSee our performanceengine P99 Latency 12 1 ms P50P90P95P99TensorFlowPyTorchModular Engine ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size101UnificationTrain in any framework deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude Cloud On PremFrameworksmodular EngineServer edgeFramework optionalityEasily deploy models trained in any framework such as TensorFlow or PyTorch without retraining conversions or pre optimization steps using a unified set of APIs There are no tricks no hacks the Engine just works incredibly fast Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models Avoid lock in and take advantage of price efficiencies and performance improvements without migration costs 02PerformanceMaximize performance minimize costsReduce latency increase throughput and improve resource efficiency across CPUs GPUs and accelerators Productionize larger models and significantly reduce your computing costs Explore our performance dashboardQueries per Second 125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences 0 12TensorFlow 0 89PyTorch 0 54Modular Engine 0 12 ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size1MODULAR ENGINE SPEED UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family vs vs vs vs vs vsLanguage Model3x3 2x5 3x1 4x2 1x4xRecommender Models6 5x5x7 5x1 1x1 2x4 3xVision Models2 1x2 2x1 7x1 5x1 5x1 3xCompute TypeIntel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge Intel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge ResultsAWS Compute Instances TensorFlow PyTorch listed by logo Full performance methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again Run any model including support for all native framework operators dynamic shapes low precision and your existing custom operators DLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseBERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases Our tools are well modular They integrate with industry standard infrastructure and open source tools to minimize migration cost Request accessseamless integration with popular libraries and tools01 Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular s off the shelf NVIDIA Triton and TensorFlow Serving builds 02 Choose your cloudDeploy the engine on prem in your own VPC on any major cloud provider or get up and running quicker with out hosted solutions 03 METRICS MONITORINGThe Modular Inference Engine works with industry standard open source tooling like Prometheus and Grafana Ready to try a preview Contact us to get early access to the Modular Inference Engine Request accessAPI References Tutorials MoreRead the Modular Inference Engine docs EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Get started today Get started todayModular is a fully integrated composable suite of AI infrastructure tools with unmatched industry performance that streamlines AI workflows Get started today and let us know what products you are interested in We re rolling out access as fast as we can Next Modular Get started today Get started todayModular is a fully integrated composable suite of AI infrastructure tools with unmatched industry performance that streamlines AI workflows Get started today and let us know what products you are interested in We re rolling out access as fast as we can Next Modular Inference Engine Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuThe world s fastest unified AI inference engine Get models into production faster The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions Bring your model as is and deploy it anywhere across server and edge with unparalleled usability and performance Get startedSee our performanceengine P99 Latency 12 1 ms P50P90P95P99TensorFlowPyTorchModular Engine ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size101UnificationTrain in any framework deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude Cloud On PremFrameworksmodular EngineServer edgeFramework optionalityEasily deploy models trained in any framework such as TensorFlow or PyTorch without retraining conversions or pre optimization steps using a unified set of APIs There are no tricks no hacks the Engine just works incredibly fast Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models Avoid lock in and take advantage of price efficiencies and performance improvements without migration costs 02PerformanceMaximize performance minimize costsReduce latency increase throughput and improve resource efficiency across CPUs GPUs and accelerators Productionize larger models and significantly reduce your computing costs Explore our performance dashboardQueries per Second 125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences 0 12TensorFlow 0 89PyTorch 0 54Modular Engine 0 12 ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size1MODULAR ENGINE SPEED UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family vs vs vs vs vs vsLanguage Model3x3 2x5 3x1 4x2 1x4xRecommender Models6 5x5x7 5x1 1x1 2x4 3xVision Models2 1x2 2x1 7x1 5x1 5x1 3xCompute TypeIntel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge Intel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge ResultsAWS Compute Instances TensorFlow PyTorch listed by logo Full performance methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again Run any model including support for all native framework operators dynamic shapes low precision and your existing custom operators DLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseBERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases Our tools are well modular They integrate with industry standard infrastructure and open source tools to minimize migration cost Request accessseamless integration with popular libraries and tools01 Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular s off the shelf NVIDIA Triton and TensorFlow Serving builds 02 Choose your cloudDeploy the engine on prem in your own VPC on any major cloud provider or get up and running quicker with out hosted solutions 03 METRICS MONITORINGThe Modular Inference Engine works with industry standard open source tooling like Prometheus and Grafana Ready to try a preview Contact us to get early access to the Modular Inference Engine Request accessAPI References Tutorials MoreRead the Modular Inference Engine docs EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Mojo Programming language for all of AI Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuMojo a new programming language for all AI developers Mojo combines the usability of Python with the performance of C unlocking unparalleled programmability of AI hardware and extensibility of AI models Get started with MojoRead the docs SOFTMAX PYMojo pythondef softmax lst norm np exp lst np max lst return norm norm sum def softmax lst norm np exp lst np max lst return norm norm sum struct NDArray def max self NDArray return self pmap SIMD max struct SIMD type DType width Int def max self rhs Self Self return self rhs select self rhs 01Usability ProgrammabilityWrite everything in one languageWrite Python or scale all the way down to the metal Program the multitude of low level AI hardware No C or CUDA required Take a tour of Mojo FILE_NAME def sort v ArraySlice Int for i in range len v for j in range len v i 1 if v j v j 1 swap v j v j 1 FILE_NAME struct MyPair var first Int var second F32 def __init__ self first Int second F32 self first first self second secondFILE_NAME def reorder_and_process owned x HugeArray sort x Update in place give_away x Transfer ownership print x 0 Error x moved away FILE_NAME def exp dt DType elts Int x SIMD dt elts SIMD dt elts x clamp x 88 3762626647 88 37626266 k floor x INV_LN2 0 5 r k NEG_LN2 x return ldexp _exp_taylor r k FILE_NAME def exp_buffer dt DType data ArraySlice dt Search for the best vector length alias vector_len autotune 1 4 8 16 32 Use it as the vectorization length vectorize exp dt vector_len data Features include Progressive TypesLeverage types for better performance and error checking Zero Cost AbstractionsTake control of storage by inline allocating values into structures Ownership borrow checkerTake advantage of memory safety without the rough edges Portable parametric algorithmsLeverage compile time meta programming to write hardware agnostic algorithms and reduce boilerplate LANGUAGE INTEGRATED Auto tuningAutomatically find the best values for your parameters to take advantage of target hardware As well as The full power of MLIRParallel heterogenous runtimeFast compile times FILE_NAME def sort v ArraySlice Int for i in range len v for j in range len v i 1 if v j v j 1 swap v j v j 1 Features include Progressive TypesLeverage types for better performance and error checking FILE_NAME struct MyPair var first Int var second F32 def __init__ self first Int second F32 self first first self second secondFeatures include Zero Cost AbstractionsTake control of storage by inline allocating values into structures FILE_NAME def reorder_and_process owned x HugeArray sort x Update in place give_away x Transfer ownership print x 0 Error x moved away Features include Ownership borrow checkerTake advantage of memory safety without the rough edges FILE_NAME def exp dt DType elts Int x SIMD dt elts SIMD dt elts x clamp x 88 3762626647 88 37626266 k floor x INV_LN2 0 5 r k NEG_LN2 x return ldexp _exp_taylor r k Features include Portable parametric algorithmsLeverage compile time meta programming to write hardware agnostic algorithms and reduce boilerplate FILE_NAME def exp_buffer dt DType data ArraySlice dt Search for the best vector length alias vector_len autotune 1 4 8 16 32 Use it as the vectorization length vectorize exp dt vector_len data Features include LANGUAGE INTEGRATED Auto tuningAutomatically find the best values for your parameters to take advantage of target hardware 02PerformanceUnlock Python performanceUtilize the full power of the hardware including multiple cores vector units and exotic accelerator units with the world s most advanced compiler and heterogenous runtime Achieve performance on par with C and CUDA without the complexity Play with MojoParallelizationMojo leverages MLIR which enables Mojo developers to take advantage of vectors threads and AI hardware units PYTHONSingle threaded executionMojo Parallel processing across multiple coresLanguagesTime S Speedup vs PythonPython 3 10 91027 s1xPypy46 1 s22xScalar C 0 20 s5000xMojo 0 03 s35000x AlgorithmMandelbrotInstanceAWS r7iz metal 16xlIntel Xeon03InteroperabilityAccess the entire Python ecosystemExperience true interoperability with the Python ecosystem Seamlessly intermix arbitrary libraries like Numpy and Matplotlib and your custom code with Mojo Read the programming manual MAKE_PLOT def make_plot m Matrix plt Python import_module matplotlib pyplot fig plt figure 1 10 10 yn xn 64 ax fig add_axes 0 0 0 0 1 0 1 0 False 1 plt imshow image plt show make_plot compute_mandelbrot Mojo 04ExtensibilityUpgrade your models and the Modular stackEasily extend your models with pre and post processing operations or replace operations with custom ones Take advantage of kernel fusion graph rewrites shape functions and more Model extensibilityMojo can upgrade the existing operations in your model Input layerHidden layersOutput layer05GET STARTED NOWTry Mojo out right now in our PlaygroundMojo is still a work in progress but it s available to try today in our JupyterHub based Playground Run through tutorials and write your own Mojo code Sign up for accessMojo 01 EASY TO GET STARTEDWe have plenty of easy to use Jupyter notebooks to help you get started learning Mojo 02 Unleash your mojoOur docs will help you quickly discover why Mojo is such a powerful extension to Python and the future of AI programming 03 JOIN the mojo COMMUNITYCome and chat with us on our Discord and help shape the future of the language as we continue to develop it Ready to play with Mojo Reach out to gain access to the Mojo Playground Request accessAPI Reference Tutorials MoreRead the Mojo docs EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Hardware Developers Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuUnlock your hardware design with software that provides generality and usability for AI developers Modular s software stack will take care of all upstream integrations with AI frameworks graph optimizations and more so you can focus on the differentiating features of your hardware Own your code generation performance and feature set It s still early but we re excited about the future Contact us nowLearn how it works01BenefitsIntegrating with the Modular stack gets you 01 Access to all AI frameworksEffortlessly extend your customer reach to all popular AI frameworks 02 Better performanceAutofusion and graph optimizations boost your hardware performance 03 Full compatibilityWe support the ever changing AI ecosystem including the long tail of operators and models 04 Market DifferentiationYou own your performance and can utilize the full capabilities of your hardware 05 Faster time to marketYour hardware just works often with only a few weeks of development 02How it worksIntegration is simple FrameworksModular handles integration packagingend user tools Modular engineModular handles offload kernel fusion compilation caching developer tools Your Compiler KernelsYou provide LLVM or MLIR code generation and extend the stack with Mojo kernelsyour HardwareYou design the hardware and have in house expertise03Modern AI EngineModular handles framework support and end user toolingModular handles the ever changing world of AI frameworks models and operators providing you with a single cross framework integration point for your hardware stack Full framework model and op supportIntegration with TensorFlow PyTorch plus variants like ONNX and TorchScriptFull generality of models including dynamic shapes sparsity custom ops etc Thousands of long tail operators needed for compatibilityCompiler transformations and developer toolingKernel fusion and other performance optimizationsAutomatic graph partitioning for distributed inferenceStandardized and hackable tools04IntegrationPlug your hardware in at the graph or code generation levelBring your own code gen backend for CPU GPU or DSPs and everything just works For CGRA FPGA or other exotic hardware start with our standardized operator set and extend the system to your needs Focus your effort on ML operators you care aboutModular provides a library of customizable kernels and microkernels written in Mojo Focus on the subset of the problem for your hardwareEverything else just works we provide fallback legacy long tail kernels for compatibilityExtend the systemas neededAdd new Mojo kernels if you don t find what you re looking for and enable your customers to the sameUse Mojo to directly inject MLIR C C or assembly code as neededLeverage standardized operators and tools to write high level graph transformationsInterested in partnering with us Contact us to discuss how we can work together Contact UsAPI Reference Guides MoreLearn more about our platform EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Inference Engine Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuThe world s fastest unified AI inference engine Get models into production faster The Modular Engine executes all of your TensorFlow and PyTorch models with no model rewriting or conversions Bring your model as is and deploy it anywhere across server and edge with unparalleled usability and performance Get startedSee our performanceengine P99 Latency 12 1 ms P50P90P95P99TensorFlowPyTorchModular Engine ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size101UnificationTrain in any framework deploy anywhereConsolidate the bespoke AI toolchains you are using and simplify your AI deployment by orders of magnitude Cloud On PremFrameworksmodular EngineServer edgeFramework optionalityEasily deploy models trained in any framework such as TensorFlow or PyTorch without retraining conversions or pre optimization steps using a unified set of APIs There are no tricks no hacks the Engine just works incredibly fast Compute portabilitySeamlessly move your workloads to the best hardware for the job without rewriting or recompiling your models Avoid lock in and take advantage of price efficiencies and performance improvements without migration costs 02PerformanceMaximize performance minimize costsReduce latency increase throughput and improve resource efficiency across CPUs GPUs and accelerators Productionize larger models and significantly reduce your computing costs Explore our performance dashboardQueries per Second 125 qpsTensorFlow17qpsPyTorch28qpsModular Engine125qpsCost per 100k Inferences 0 12TensorFlow 0 89PyTorch 0 54Modular Engine 0 12 ModelDLRM RMC1InstanceAWS c6g 4xlarge Graviton2 Batch Size1MODULAR ENGINE SPEED UPS VS OTHER FRAMEWORKS ON DIFFERENT COMPUTE TYPES AT FLOAT32Model Family vs vs vs vs vs vsLanguage Model3x3 2x5 3x1 4x2 1x4xRecommender Models6 5x5x7 5x1 1x1 2x4 3xVision Models2 1x2 2x1 7x1 5x1 5x1 3xCompute TypeIntel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge Intel c5 4xlarge AMD c5a 4xlarge ARM c6g 4xlarge ResultsAWS Compute Instances TensorFlow PyTorch listed by logo Full performance methodology here03CompatibilityExecute any model with full compatibilityNever deal with model conversion challenges again Run any model including support for all native framework operators dynamic shapes low precision and your existing custom operators DLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseDLRM RMC1 multi hot support RoBERTa baseGPT 2BERT large uncasedDLRM RMC2 multi hot support RoBERTa baseBERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch14BERT base uncasedDLRM RMC1 multi hot support GPT 2BERT large uncasedDLRM RMC2CLIP ViT large patch1404integrationWorks with your existing AI libraries and toolsModular is designed to drop into your existing workflows and use cases Our tools are well modular They integrate with industry standard infrastructure and open source tools to minimize migration cost Request accessseamless integration with popular libraries and tools01 Industry Serving LIBRARIESEasily integrate the engine into your own custom server image or use Modular s off the shelf NVIDIA Triton and TensorFlow Serving builds 02 Choose your cloudDeploy the engine on prem in your own VPC on any major cloud provider or get up and running quicker with out hosted solutions 03 METRICS MONITORINGThe Modular Inference Engine works with industry standard open source tooling like Prometheus and Grafana Ready to try a preview Contact us to get early access to the Modular Inference Engine Request accessAPI References Tutorials MoreRead the Modular Inference Engine docs EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Get started today Get started todayModular is a fully integrated composable suite of AI infrastructure tools with unmatched industry performance that streamlines AI workflows Get started today and let us know what products you are interested in We re rolling out access as fast as we can Next Modular Blog Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuCompanyOur launch what s nextMay 11 2023Tim DavisCo Founder Chief Product OfficerTim DavisCo Founder Chief Product OfficerRead postFeatured postsProductA unified extensible platform to superpower your AIMay 2 2023 Read postEngineeringThe world s fastest unified matrix multiplicationApril 20 2023 Read postBrowse all postsCompanyOur launch what s nextMay 11 2023 ProductA unified extensible platform to superpower your AIMay 2 2023 EngineeringThe world s fastest unified matrix multiplicationApril 20 2023 EngineeringAI s compute fragmentation what matrix multiplication teaches usMarch 23 2023 CompanyWe want to hear from youDecember 15 2022 EngineeringIf AI serving tech can t solve today s problems how do we scale into the future December 8 2022 EngineeringPart 2 Increasing development velocity of giant AI modelsNovember 10 2022 CompanyModular is rebuilding AI in the face of a new economyNovember 8 2022 DesignModular s Brand StoryAugust 18 2022 EngineeringIncreasing development velocity of giant AI modelsAugust 12 2022 CompanyThe Case for a Next Generation AI Developer PlatformJune 30 2022 CultureHow we workMay 21 2022 CompanyThe future of AI depends on ModularityApril 26 2022 EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Careers Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuPlayJoin us in building the future of AISee open rolesRead about our cultureWe want to enable AI to be used by anyone anywhere Our ambitions are enormous but working here will feel very familiar You can change the world without giving up your lifeWhy Modular Grow with the bestBuild with some of the industry s best AI leaders Maximize how you workWe will always push the limits to create the best possible environment for our people and teams Read how we work Build AI for the worldBuild a next generation developer platform with production quality infrastructure for the world Have fun live lifeRegular team onsites local meetups fun strong team collaboration and more Work life balanced1Leading medical dental and vision packages2Strong compensation equity packages3Generous maternity paternity leave4401K Plan5Work wherever you want6Unlimited Vacation PTO7Corporate perks epic team fun8Great set upWorking at ModularWe believe in a thoughtful framework to family compensation growth and mission each of these elements is critical to anyone living a balanced and fulfilling life We want to ensure that you have a place to achieve the right mix We re trusting empoweringWe trust that you will hold our values and standards This means we don t micromanage you We write things downThis is key to being asynchronous It allows real time discussions to be more thoughtful and contextually driven We have levelsWe acknowledge levels of experience upfront and have a transparent and well defined leveling system Learn about usI am truly impressed with the collective experience of the Modular team in building some of the industry s most widely used AI systems and tools And humbled and excited to be part of this team in our journey to build the next generation AI platform and infrastructure for the world Amit AgarwalCloud Infrastructure LeadI picked modular because of the people and what they believe in and what they want to do I want to be a part of something that makes a difference for the better Paige BedwellProgram ManagerI joined because there is literally no better team on the planet to rebuild AI It s a once in a lifetime opportunity I m building for the world and working with the best River RiddleAI Compiler EngineerWe are a set of world class engineers and leaders who really deeply understand this problem and have solved it to varying degrees of success before Now we are committed to solving it the right way Aman LaChapelleAI Compiler EngineerThe team is incredible They re very smart They re experts in their field and we re solving the hardest computational problems in the world Abdul DakkakAI Compiler EngineerThe best part of working here is a strong commitment to culture I work on the most challenging problems have the freedom to do it anywhere and have a huge impact on AI Eric JohnsonProduct LeadJoin our teamCome and be part of a world class team that is rebuilding AI for everyone We welcome applications from all backgrounds and communities EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Terms of Service Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuTerms of UseLast Updated May 2nd 2023These Terms of Use this Agreement effective as of the date on which you check a box click a button or otherwise acknowledge your acceptance of this Agreement is by and between Modular Inc with offices located at 228 Hamilton Ave Palo Alto CA 94301 USA Modular we or us and you This Agreement constitutes a binding contract between you and Modular and your use of the Platform as defined below is at all times subject to the terms and conditions outlined in this Agreement This Agreement incorporates by reference all other terms and policies governing your use of the Platform including our Privacy Policy https www modular com privacy Acceptable Use Policy https www modular com legal use as well as any other policies we may adopt from time to time 1 Definitions Account means the account you set up to access the Platform and represents your legal and services relationship with Modular Code means any software code that you write develop or otherwise import for use on the Platform Derivative Data means data and information related to or derived from Users of the Platform that has been aggregated and or anonymized by Modular including any metrics feedback and ratings relating to any Code Developer means a User who wrote or otherwise contributed to Code Harmful Code means any software hardware or other technology device or means including any virus worm malware or other malicious computer code the purpose or effect of which is to permit unauthorized access to or to destroy disrupt disable distort or otherwise harm or impede in any manner any i computer software firmware hardware system or network or ii any application or function of any of the foregoing or the security integrity confidentiality or use of any data processed thereby Modular IP means the Platform are and any and all intellectual property provided to you or any other User in connection with the foregoing For the avoidance of doubt Modular IP includes Derivative Data and any information data or other content derived from Modular s provision of the Platform but does not include User Generated Content Platform means Modular s proprietary hosted software platform and other website functionality as made available to Users from time to time at www modular com or a successor or sub site Third Party Products means any third party products provided with integrated with or incorporated into the Platform User you and your refer to the individual person company or organization that has visited or is using the Platform that accesses or uses any part of an Account or that directs the use of the Account in the performance of its functions A User must be at least 18 years of age User Generated Content means information data and other content in any form or medium that is submitted posted or otherwise transmitted by a User through the Platform including any Code provided that for purposes of clarity User Generated Content as defined herein does not include Derivative Data 2 Account Registration and RequirementsRegistration You must provide a valid email address in order to complete the Account signup process Account registration and provisioning is at Modular s sole discretion and signing up for our waitlist does not guarantee that you will be eligible for account registration RequirementsYou must be a human to create an Account Accounts registered by bots or other automated methods are not permitted You must be age 18 or older The Children s Online Privacy Protection Act COPPA requires that online service providers obtain parental consent before they knowingly collect personally identifiable information online from children who are under thirteen 13 We do not knowingly collect or solicit personally identifiable information from children under thirteen 18 Users under the age of 18 are not permitted to use Modular Modular does not target its Platform to children under 18 and we do not permit any Users under 18 on our Platform If we learn of any User under the age of 18 we will terminate that User s Account immediately Your login may only be used by one person You may not share your Account with others and you may not use anyone else s Account Account Security You are responsible for keeping your Account secure while you use the Platform We offer tools to help you maintain your Account s security but the content of your Account and its security are your responsibility You are responsible for all content posted and activity that occurs under your Account even when content is posted by others who have Accounts under your Account You are responsible for maintaining the security of your Account and password Modular cannot and will not be liable for any loss or damage from your failure to comply with this security obligation You will promptly notify Modular if you become aware of any unauthorized use of or access to our Platform through your Account including any unauthorized use of your password or Account 3 Platform Access and UseSubject to and conditioned on your compliance with the terms and conditions of this Agreement Modular hereby grants you a right to access and use the Platform on a non exclusive non transferable and non sublicensable basis Your use is limited to personal non commercial internal business purposes Use Restrictions You shall not use the Platform for any purposes beyond the scope of the access granted in this Agreement You shall at all times comply with Modular s Acceptable Use Policy https www modular com privacy Reservation of Rights Modular reserves all rights not expressly granted to you in this Agreement Except for the limited rights and licenses expressly granted under this Agreement nothing in this Agreement grants by implication waiver estoppel or otherwise to you or any third party any intellectual property rights or other right title or interest in or to the Modular IP Suspension Notwithstanding anything to the contrary in this Agreement Modular may temporarily suspend your Account and or access to the Platform if i Modular reasonably determines that a there is a threat or attack on any of the Modular IP b your or another User s use of the Modular IP disrupts or poses a security risk to the Modular IP or to any other User customer or vendor of Modular c you are using the Modular IP for fraudulent or illegal activities or in violation of the Acceptable Use Policy e Modular s provision of the Platform to you is prohibited by applicable law or f any User Generated Content including any Code submitted posted or otherwise transmitted by you through the Platform may infringe or otherwise violate any third party s intellectual property or other rights ii any vendor of Modular has suspended or terminated Modular s access to or use of any Third Party Products required to enable you to access the Platform or iii in accordance with a violation of any other term of this Agreement each of i ii or iii a Service Suspension Modular shall use commercially reasonable efforts to provide written notice of any Service Suspension to you and to provide updates regarding resumption of access to the Platform following any Service Suspension Modular shall use commercially reasonable efforts to resume providing access to the Platform as soon as reasonably possible after the event giving rise to the Service Suspension is cured Modular will have no liability for any damage liabilities losses including any loss of data or profits or any other consequences that you or any other User may incur as a result of a Service Suspension Derivative Data Notwithstanding anything to the contrary in this Agreement Modular may monitor your use of the Platform and collect and compile Derivative Data As between you and Modular all right title and interest in Derivative Data and all intellectual property rights therein belong to and are retained solely by Modular You acknowledges that Modular may compile Derivative Data based on User Generated Content input into and transmitted via the Platform Notwithstanding anything to the contrary in this Agreement you further acknowledges that Modular may use and disclose Derivative Data for any lawful purpose 4 User ResponsibilitiesGeneral You are at all times responsible and liable for all uses of the Platform resulting from access from your Account directly or indirectly whether such access or use is permitted by or in violation of this Agreement User Generated Content You shall not upload to the Platform any User Generated Content that you do not have sufficient rights to upload You hereby represent and warrant that you have sufficient rights to use any Code you upload to or otherwise use or incorporate as part of the Platform You shall at all times abide by and comply with the Modular Acceptable Use Policy https www modular com terms You hereby grant to Modular a non exclusive royalty free worldwide license to reproduce distribute and otherwise use and display your User Generated Content and perform all acts with respect to your User Generated Content as may be necessary for Modular to provide the Platform and a non exclusive perpetual irrevocable royalty free worldwide license to reproduce distribute modify and otherwise use and display your User Generated Content incorporated within the Derivative Data and as otherwise necessary to provide you with Platform functionality Third Party Products Modular may from time to time make Third Party Products available to you or may allow for certain Third Party Products to be integrated with the Platform to allow for the transmission of Code or other User Generated Content from such Third Party Products into the Platform including for example and without limitation Github AWS Code Commit BitBucket etc For purposes of this Agreement such Third Party Products are subject to their own terms and conditions Modular is not responsible for the operation of any Third Party Products and makes no representations or warranties of any kind with respect to Third Party Products or their respective providers If you do not agree to abide by the applicable terms for any such Third Party Products then you should not install or use such Third Party Products By authorizing Modular to transmit your User Generated Content from Third Party Products into the Platform you represent and warrant to Modular that you have all right power and authority to provide such authorization User Controls and Responsibility You have and will retain sole responsibility for i all your own User Generated Content ii your technology infrastructure and network and internet connection s from which you access the Platform iii the security and use of your Account and associated credentials and iv all access to and use of the Platform including all results obtained from and all conclusions decisions and actions based on such access or use 5 Account FeesYou may access the Platform for free or we may charge a fee for using the Platform the Paid Services Paid Platform Access Certain aspects of features of the Platform may be subject to payments now or in the future Account Fees Payment Processor We use a third party payment processor the Payment Processor to bill you through a payment account linked to your Account on the Platform your Billing Account for any owed Account Fees The processing of payments will be subject to the terms conditions and privacy policies of the Payment Processor in addition to this Agreement Payment Method The terms of your payment will be based on your Payment Method and may be determined by agreements between you and the financial institution credit card issuer or other provider of your chosen Payment Method If we through the Payment Processor do not receive payment from you you agree to pay all amounts due on your Billing Account upon demand Recurring Billing Some of the Paid Services may consist of an initial period for which there is a one time charge followed by recurring period charges as agreed to by you By choosing a recurring payment plan you acknowledge that such Paid Services have an initial and recurring payment feature and you accept responsibility for all recurring charges prior to cancellation WE MAY SUBMIT PERIODIC CHARGES E G MONTHLY WITHOUT FURTHER AUTHORIZATION FROM YOU UNTIL YOU PROVIDE PRIOR NOTICE RECEIPT OF WHICH IS CONFIRMED BY US THAT YOU HAVE TERMINATED THIS AUTHORIZATION OR WISH TO CHANGE YOUR PAYMENT METHOD SUCH NOTICE WILL NOT AFFECT CHARGES SUBMITTED BEFORE WE REASONABLY COULD ACT TO TERMINATE YOUR AUTHORIZATION OR CHANGE YOUR PAYMENT METHOD CONTACT US Current Information Required YOU MUST PROVIDE CURRENT COMPLETE AND ACCURATE INFORMATION FOR YOUR BILLING ACCOUNT YOU MUST PROMPTLY UPDATE ALL INFORMATION TO KEEP YOUR BILLING ACCOUNT CURRENT COMPLETE AND ACCURATE SUCH AS A CHANGE IN BILLING ADDRESS CREDIT CARD NUMBER OR CREDIT CARD EXPIRATION DATE AND YOU MUST PROMPTLY NOTIFY US OR OUR PAYMENT PROCESSOR IF YOUR PAYMENT METHOD IS CANCELED E G FOR LOSS OR THEFT OR IF YOU BECOME AWARE OF A POTENTIAL BREACH OF SECURITY SUCH AS THE UNAUTHORIZED DISCLOSURE OR USE OF YOUR USER NAME OR PASSWORD CHANGES TO SUCH INFORMATION CAN BE MADE AT ACCOUNT SETTINGS BY CONTACTING US IF YOU FAIL TO PROVIDE ANY OF THE FOREGOING INFORMATION YOU AGREE THAT WE MAY CONTINUE CHARGING YOU FOR ANY USE OF PAID SERVICES UNDER YOUR BILLING ACCOUNT UNLESS YOU HAVE TERMINATED YOUR PAID SERVICES AS SET FORTH ABOVE Change in Amount Authorized If the amount to be charged to your Billing Account varies from the amount you preauthorized other than due to the imposition or change in the amount of state sales taxes you have the right to receive and we shall provide notice of the amount to be charged and the date of the charge before the scheduled date of the transaction Any agreement you have with your payment provider will govern your use of your Payment Method You agree that we may accumulate charges incurred and submit them as one or more aggregate charges during or at the end of each billing cycle Reaffirmation of Authorization Your non termination or continued use of a Paid Service reaffirms that we are authorized to charge your Payment Method for that Paid Service We may submit those charges for payment and you will be responsible for such charges This does not waive our right to seek payment directly from you Your charges may be payable in advance in arrears per usage or as otherwise described when you initially selected to use the Paid Service Free Trials and Other Promotions Any free trial or other promotion that provides access to a Paid Service must be used within the specified time of the trial You must stop using a Paid Service before the end of the trial period in order to avoid being charged for that Paid Service If you cancel prior to the end of the trial period and are inadvertently charged for a Paid Service please contact us at hello modular com 6 ConfidentialityYour Confidentiality Obligations You agree that any non public information we give you such as information about a private beta offering or any information or materials made available on non public portions of the Platform is Modular s confidential information regardless of whether it is marked or identified as such collectively Confidential Information You agree to only use such Confidential Information for the express purpose of testing and evaluating such beta products and not for any other purpose You should use the same degree of care as you would with your own confidential information but no less than reasonable precautions to prevent any unauthorized use disclosure publication or dissemination of our Confidential Information You promise not to disclose publish or disseminate any Confidential Information to any third party unless we don t otherwise prohibit or restrict such disclosure for example you might be part of a Modular organized group discussion about a private beta feature Exceptions Confidential Information will not include information that is a or becomes publicly available without breach of this Agreement through no act or inaction on your part such as when a private beta feature becomes part of our publicly offered Platform b known to you before we disclose it to you c independently developed by you without breach of any confidentiality obligation to us or any third party or d disclosed with permission from Modular You will not violate the terms of this Agreement if you are required to disclose Confidential Information pursuant to operation of law provided Modular has been given reasonable advance written notice to object unless prohibited by law 7 Data Security and Processing of personal InformationSecurity Measures Modular will implement and maintain commercially reasonable administrative physical and technical safeguards designed to protect applicable User Generated Content from unauthorized access use alteration or disclosure Processing of Personal Information No Sensitive Data Modular s rights and obligations with respect to Personal Information that it collects directly from you are set forth in Modular s Privacy Policy https www modular com privacy 8 Intellectual Property Ownership Feedback Modular IP You acknowledge that as between you and Modular Modular owns all right title and interest including all intellectual property rights in and to the Modular IP and with respect to Third Party Products the applicable third party providers own all right title and interest including all intellectual property rights in and to the Third Party Products Your User Generated Content Modular acknowledges that as between you and Modular you and your licensors if any retain all right title and interest including all intellectual property rights in and to User Generated Content Feedback If you sends us any communications or materials by mail email telephone or otherwise suggesting or recommending changes to the Modular IP including without limitation new features or functionality relating thereto or any comments questions suggestions or the like Feedback Modular is free to use such Feedback 9 Warranty DisclaimerMODULAR AND ITS LICENSORS SUPPLIERS PARTNERS PARENT SUBSIDIARIES OR AFFILIATED ENTITIES AND EACH OF THEIR RESPECTIVE OFFICERS DIRECTORS MEMBERS EMPLOYEES CONSULTANTS CONTRACT EMPLOYEES REPRESENTATIVES AND AGENTS AND EACH OF THEIR RESPECTIVE SUCCESSORS AND ASSIGNS MODULAR AND ALL SUCH PARTIES TOGETHER THE MODULAR PARTIES MAKE NO REPRESENTATIONS OR WARRANTIES CONCERNING THE MODULAR IP AND THE MODULAR PARTIES WILL NOT BE RESPONSIBLE OR LIABLE FOR THE ACCURACY AVAILABILITY OCCURRENCE OF ERRORS COPYRIGHT COMPLIANCE LEGALITY OR DECENCY OF MATERIAL CONTAINED IN OR ACCESSED THROUGH THE PLATFORM OR ANY CLAIMS ACTIONS SUITS PROCEDURES COSTS EXPENSES DAMAGES OR LIABILITIES ARISING OUT OF USE OF OR IN ANY WAY RELATED TO YOUR ACCESS OF THE PLATFORM OR USE OF ANY MODULAR IP THE MODULAR PARTIES MAKE NO REPRESENTATIONS OR WARRANTIES REGARDING SUGGESTIONS OR RECOMMENDATIONS OFFERED THROUGH OR IN CONNECTION WITH YOUR USE OF THE PLATFORM THE MODULAR IP IS PROVIDED BY MODULAR AND ITS LICENSORS AND SUPPLIERS ON AN AS IS BASIS WITHOUT WARRANTIES OF ANY KIND EITHER EXPRESS OR IMPLIED INCLUDING WITHOUT LIMITATION IMPLIED WARRANTIES OF MERCHANTABILITY FITNESS FOR A PARTICULAR PURPOSE NON INFRINGEMENT OR THAT USE OF THE MODULAR IP WILL BE UNINTERRUPTED OR ERROR FREE SOME STATES DO NOT ALLOW LIMITATIONS ON HOW LONG AN IMPLIED WARRANTY LASTS SO THE ABOVE LIMITATIONS MAY NOT APPLY TO YOU 10 IndemnificationYou agree to indemnify and hold the Modular Parties harmless from and against any and all claims liabilities damages actual and consequential losses and expenses including attorneys fees arising from or in any way related to any claims relating to a your use of the Modular IP including any actions taken by a third party using your Account and b your violation or breach of any of the terms of this Agreement In the event of such a claim suit or action Claim we will attempt to provide notice of the Claim to the contact information we have for your Account provided that failure to deliver such notice shall not eliminate or reduce your indemnification obligations hereunder 11 Limitation of LiabilityTO THE FULLEST EXTENT ALLOWED BY APPLICABLE LAW UNDER NO CIRCUMSTANCES AND UNDER NO LEGAL THEORY INCLUDING WITHOUT LIMITATION TORT CONTRACT STRICT LIABILITY OR OTHERWISE SHALL ANY OF THE MODULAR PARTIES BE LIABLE TO YOU OR TO ANY OTHER PERSON FOR A ANY INDIRECT SPECIAL INCIDENTAL PUNITIVE OR CONSEQUENTIAL DAMAGES OF ANY KIND INCLUDING DAMAGES FOR LOST PROFITS BUSINESS INTERRUPTION LOSS OF DATA LOSS OF GOODWILL WORK STOPPAGE ACCURACY OF RESULTS OR COMPUTER FAILURE OR MALFUNCTION B ANY SUBSTITUTE GOODS SERVICES OR TECHNOLOGY C ANY AMOUNT IN THE AGGREGATE IN EXCESS OF THE GREATER OF I ONE HUNDRED 100 DOLLARS OR II THE AMOUNTS PAID AND OR PAYABLE BY YOU TO MODULAR IN CONNECTION WITH THE ACCOUNT FEES FOR THE PLATFORM IN THE TWELVE 12 MONTH PERIOD PRECEDING THIS APPLICABLE CLAIM OR D ANY MATTER BEYOND OUR REASONABLE CONTROL SOME STATES DO NOT ALLOW THE EXCLUSION OR LIMITATION OF INCIDENTAL OR CONSEQUENTIAL OR CERTAIN OTHER DAMAGES SO THE ABOVE LIMITATION AND EXCLUSIONS MAY NOT APPLY TO YOU 12 GeneralAssignment You may not assign delegate or transfer this Agreement or your rights or obligations hereunder or your Account in any way by operation of law or otherwise without Modular s prior written consent We may transfer assign or delegate this Agreement and our rights and obligations without consent Choice of Law This Agreement are governed by and will be construed under the Federal Arbitration Act applicable federal law and the laws of the State of California without regard to the conflicts of laws provisions thereof Miscellaneous The failure of Modular to exercise in any way any right herein shall not be deemed a waiver of any further rights hereunder If any provision of this Agreement is found to be unenforceable or invalid that provision will be limited or eliminated to the minimum extent necessary so that this Agreement shall otherwise remain in full force and effect and enforceable You and Modular agree that this Agreement is the complete and exclusive statement of the mutual understanding between you and Modular and that the terms contained herein supersede and cancel all previous written and oral agreements communications and other understandings relating to the subject matter of this Agreement Except for changes by us as described here no other amendment or modification of these Terms will be effective unless in writing and signed by both you and Modular You hereby acknowledge and agree that you are not an employee agent partner or joint venturer of Modular and you do not have any authority of any kind to bind Modular in any respect whatsoever Arbitration Agreement Please read the following ARBITRATION AGREEMENT carefully because it requires you to arbitrate certain disputes and claims with Modular and limits the manner in which you can seek relief from Modular Both you and Modular acknowledge and agree that for the purposes of any dispute arising out of or relating to the subject matter of this Agreement Modular s officers directors employees and independent contractors Representatives are third party beneficiaries of this Agreement and that upon your acceptance of this Agreement Representatives will have the right and will be deemed to have accepted the right to enforce this Agreement against you as the third party beneficiary hereof Arbitration Rules Applicability of Arbitration Agreement You and Modular shall use best efforts to settle any dispute claim question or disagreement arising out of or relating to the subject matter of this Agreement directly through good faith negotiations which shall be a precondition to either party initiating arbitration If such negotiations do not resolve the dispute it shall be finally settled by binding arbitration in San Mateo County California The arbitration will proceed in the English language in accordance with the JAMS Streamlined Arbitration Rules and Procedures the Rules then in effect by one commercial arbitrator with substantial experience in resolving intellectual property and commercial contract disputes The arbitrator shall be selected from the appropriate list of JAMS arbitrators in accordance with such Rules Judgment upon the award rendered by such arbitrator may be entered in any court of competent jurisdiction Costs of Arbitration The Rules will govern payment of all arbitration fees Modular will pay all arbitration fees for claims less than seventy five thousand 75 000 dollars Modular will not seek its attorneys fees and costs in arbitration unless the arbitrator determines that your claim is frivolous Waiver of Jury Trial YOU AND MODULAR WAIVE ANY CONSTITUTIONAL AND STATUTORY RIGHTS TO GO TO COURT AND HAVE A TRIAL IN FRONT OF A JUDGE OR JURY You and Modular are instead choosing to have claims and disputes resolved by arbitration Arbitration procedures are typically more limited more efficient and less costly than rules applicable in court and are subject to very limited review by a court In any litigation between you and Modular over whether to vacate or enforce an arbitration award YOU AND MODULAR WAIVE ALL RIGHTS TO A JURY TRIAL and elect instead to have the dispute be resolved by a judge Waiver of Class or Consolidated Actions ALL CLAIMS AND DISPUTES WITHIN THE SCOPE OF THIS ARBITRATION AGREEMENT MUST BE ARBITRATED OR LITIGATED ON AN INDIVIDUAL BASIS AND NOT ON A CLASS BASIS CLAIMS OF MORE THAN ONE USER CANNOT BE ARBITRATED OR LITIGATED JOINTLY OR CONSOLIDATED WITH THOSE OF ANY OTHER USER If however this waiver of class or consolidated actions is deemed invalid or unenforceable neither you nor Modular is entitled to arbitration instead all claims and disputes will be resolved in a court Opt out You have the right to opt out of the provisions of this Section by sending written notice of your decision to opt out to the following address Modular Inc 228 Hamilton Ave 3rd Floor Palo Alto CA 94301 postmarked within thirty 30 days of first accepting this Agreement You must include i your name and residence address ii the email address and or telephone number associated with your Account and iii a clear statement that you want to opt out of this Agreement s arbitration agreement Exclusive Venue If you send the opt out notice in e and or in any circumstances where the foregoing arbitration agreement permits either you or Modular to litigate any dispute arising out of or relating to the subject matter of this Agreement in court then the foregoing arbitration agreement will not apply to either party and both you and Modular agree that any judicial proceeding other than small claims actions will be brought in the state or federal courts located in respectively San Mateo County California or the federal district in which that county falls Severability If the prohibition against class actions and other claims brought on behalf of third parties contained above is found to be unenforceable then all of the preceding language in this Arbitration Agreement section will be null and void This arbitration agreement will survive the termination of your relationship with Modular EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Privacy Policy Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuPrivacy PolicyLast Updated May 2nd 2023At Modular we take your privacy seriously Please read this Privacy Policy to learn how we treat your personal data By using or accessing our Platform as defined in the Terms or our website collectively the Services in any manner you acknowledge that you accept the practices and policies outlined below and you hereby consent that we will collect use and share your information as described in this Privacy Policy Remember that your use of Modular s Services is at all times subject to our Terms of Use https www modular com terms collectively the Terms The Terms incorporate this Privacy Policy by reference Any terms we use in this Privacy Policy without defining them have the definitions given to them in the Terms We re constantly trying to improve our Services so we may need to change this Privacy Policy from time to time but we will alert you to any such changes by placing a notice on the Modular website by sending you an email and or by some other means Please note that if you ve opted not to receive legal notice emails from us or you haven t provided us with your email address those legal notices will still govern your use of the Services and you are still responsible for reading and understanding them If you use the Services after any changes to the Privacy Policy have been posted that means you agree to all of the changes Use of information we collect is subject to the Privacy Policy in effect at the time such information is collected You may print a copy of this Privacy Policy by clicking print DefinitionsWhat this Privacy Policy CoversPersonal DataHow We Share Your Personal DataTracking Tools and Opt OutData Security and RetentionPersonal Data of ChildrenState Law Privacy RightsEuropean Union and United Kingdom Data Subject RightsChanges to this Policy Contact InformationWhat this Privacy Policy CoversThis Privacy Policy covers how we treat Personal Data that we gather when you access or use our Services Personal Data means any information that identifies or relates to a particular individual and also includes information referred to as personally identifiable information or personal information under applicable data privacy laws rules or regulations This Privacy Policy does not cover the practices of companies we don t own or control or people we don t manage If you are a User of the Platform note that the Professional and Employment Related Data categories of Personal Data collected and shared pursuant to this Privacy Policy are applicable only to users of the website who apply for open job positions with us Personal DataCategories of Personal Data We Collect This chart details the categories of Personal Data that we collect and have collected over the past 12 months Category of Personal DataExamples of Personal Data We CollectCategories of Third Parties with whom we share this dataProfile or Contact DataFirst and last name Email Unique identifiers such as passwordsService Providers Advertising Partners Analytics PartnersPayment DataPayment card type Last 4 digits of payment card Billing address phone number emailService ProvidersDevice IP DataIP address Domain server Type of device OS browser used to access ServicesService Providers Advertising Partners Analytics PartnersWeb AnalyticsWeb page interactions Referring webpage source Non identifiable request IDsService Providers Advertising Partners Analytics PartnersSocial Network DataEmail Phone number User name IP address Device IDService Providers Advertising Partners Analytics Partners Parties you authorizeProfessional or Employment Related DataJob title Resume Job HistoryGeolocation DataIP address based location information Specific location dataCategories of Sources of Personal DataWe collect Personal Data about you from the following categories of sources YouWhen you provide such information directly to us When you create an account or use our interactive tools and Services When you voluntarily provide information in free form text boxes through the Services or through responses to surveys or questionnaires When you send us an email or otherwise contact us When you use the Services and such information is collected automatically Through Cookies defined in the Tracking Tools and Opt Out section below If you use a location enabled browser we may receive information about your location If you download and install certain applications and software we make available we may receive and collect information transmitted from your computing device for the purpose of providing you the relevant Services such as information regarding when you are logged on and available to receive updates or alert notices Third PartiesVendors We may use analytics providers to analyze how you interact and engage with the Services or third parties may help us provide you with customer support We may use vendors to obtain information to generate leads and create user profiles Social Networks If you provide your social network account credentials to us or otherwise sign in to the Services through a third party site or service some content and or information in those accounts may be transmitted into your account with us Our Commercial or Business Purposes for Collecting or Disclosing Personal DataProviding Customizing and Improving the Services Creating and managing your account or other user profiles Processing orders or other transactions billing Providing you with the products services or information you request Meeting or fulfilling the reason you provided the information to us Providing support and assistance for the Services Improving the Services including testing research internal analytics and product development Personalizing the Services website content and communications based on your preferences Doing fraud protection security and debugging Carrying out other business purposes stated when collecting your Personal Data or as otherwise set forth in applicable data privacy laws such as the California Consumer Privacy Act as amended by the California Privacy Rights Act of 2020 the CPRA Marketing the Services Marketing and selling the Services Corresponding with You Responding to correspondence that we receive from you contacting you when necessary or requested and sending you information about Modular or the Services Sending emails and other communications according to your preferences or that display content that we think will interest you Meeting Legal Requirements and Enforcing Legal Terms Fulfilling our legal obligations under applicable law regulation court order or other legal process such as preventing detecting and investigating security incidents and potentially illegal or prohibited activities Protecting the rights property or safety of you Modular or another party Enforcing any agreements with you Responding to claims that any posting or other content violates third party rights Resolving disputes We will not collect additional categories of Personal Data or use the Personal Data we collected for materially different unrelated or incompatible purposes without providing you notice How We Share or Disclose Your Personal DataWe disclose your Personal Data to the categories of service providers and other parties listed in this section Depending on state laws that may be applicable to you some of these disclosures may constitute a sale of your Personal Data For more information please refer to the state specific sections below Service Providers These parties help us provide the Services or perform business functions on our behalf They include Hosting technology and communication providers Security and fraud prevention consultants Payment processors Analytics Partners These parties provide analytics on web traffic or usage of the Services They include companies that track how users found or were referred to the Services Companies that track how users interact with the Services Advertising Partners Parties You Authorize Access or Authenticate Third parties you access through the services Social media services Other users Legal ObligationsWe may share any Personal Data that we collect with third parties in conjunction with any of the activities set forth under Meeting Legal Requirements and Enforcing Legal Terms in the Our Commercial or Business Purposes for Collecting Personal Data section above Business Transfers All of your Personal Data that we collect may be transferred to a third party if we undergo a merger acquisition bankruptcy or other transaction in which that third party assumes control of our business in whole or in part Should one of these events occur we will make reasonable efforts to notify you before your information becomes subject to different privacy and security policies and practices Data that is Not Personal Data We may create aggregated de identified or anonymized data from the Personal Data we collect including by removing information that makes the data personally identifiable to a particular user We may use such aggregated de identified or anonymized data and share it with third parties for our lawful business purposes including to analyze build and improve the Services and promote our business provided that we will not share such data in a manner that could identify you Tracking Tools and Opt OutThe Services use cookies and similar technologies such as pixel tags web beacons clear GIFs and JavaScript collectively Cookies to enable our servers to recognize your web browser tell us how and when you visit and use our Services analyze trends learn about our user base and operate and improve our Services Cookies are small pieces of data usually text files placed on your computer tablet phone or similar device when you use that device to access our Services We may also supplement the information we collect from you with information received from third parties including third parties that have placed their own Cookies on your device s Please note that because of our use of Cookies the Services do not support Do Not Track requests sent from a browser at this time We use the following types of Cookies Essential Cookies Essential Cookies are required for providing you with features or services that you have requested For example certain Cookies enable you to log into secure areas of our Services Disabling these Cookies may make certain features and services unavailable Functional Cookies Functional Cookies are used to record your choices and settings regarding our Services maintain your preferences over time and recognize you when you return to our Services These Cookies help us to personalize our content for you greet you by name and remember your preferences for example your choice of language or region Performance Analytical Cookies Performance Analytical Cookies allow us to understand how visitors use our Services They do this by collecting information about the number of visitors to the Services what pages visitors view on our Services and how long visitors are viewing pages on the Services Performance Analytical Cookies also help us measure the performance of our advertising campaigns in order to help us improve our campaigns and the Services content for those who engage with our advertising For example Google LLC Google uses cookies in connection with its Google Analytics services Google s ability to use and share information collected by Google Analytics about your visits to the Services is subject to the Google Analytics Terms of Service and the Google Privacy Policy You have the option to opt out of Google s use of Cookies by visiting the Google advertising opt out page at www google com privacy_ads html or the Google Analytics Opt out Browser Add on at https tools google com dlpage gaoptout Retargeting Advertising Cookies Retargeting Advertising Cookies collect data about your online activity and identify your interests so that we can provide advertising that we believe is relevant to you You can decide whether or not to accept Cookies through your internet browser s settings Most browsers have an option for turning off the Cookie feature which will prevent your browser from accepting new Cookies as well as depending on the sophistication of your browser software allow you to decide on acceptance of each new Cookie in a variety of ways You can also delete all Cookies that are already on your device If you do this however you may have to manually adjust some preferences every time you visit our website and some of the Services and functionalities may not work To explore what Cookie settings are available to you or to modify your Cookies preferences look in the preferences or options section of your browser s menu To find out more information about Cookies including information about how to manage and delete Cookies please visit http www allaboutcookies org or https ico org uk for the public online cookies if you are located in the European Union Data SecurityWe seek to protect your Personal Data from unauthorized access use and disclosure using appropriate physical technical organizational and administrative security measures based on the type of Personal Data and how we are processing that data You should also help protect your data by appropriately selecting and protecting your password and or other sign on mechanism limiting access to your computer or device and browser and signing off after you have finished accessing your account Although we work to protect the security of your account and other data that we hold in our records please be aware that no method of transmitting data over the internet or storing data is completely secure Data RetentionWe retain Personal Data about you for as long as you have an open account with us or as otherwise necessary to provide you with our Services or to perform our business or commercial purposes for collecting your Personal Data When establishing a retention period for specific categories of data we consider who we collected the data from our need for the Personal Data why we collected the Personal Data and the sensitivity of the Personal Data In some cases we retain Personal Data for longer if doing so is necessary to comply with our legal obligations resolve disputes or collect fees owed or is otherwise permitted or required by applicable law rule or regulation We may further retain information in an anonymous or aggregated form where that information would not identify you personally Personal Data of ChildrenAs noted in the Terms of Use we do not knowingly collect or solicit Personal Data about children under 18 years of age if you are a child under the age of 18 please do not attempt to register for or otherwise use the Services or send us any Personal Data If we learn we have collected Personal Data from a child under 18 years of age we will delete that information as quickly as possible If you believe that a child under 18 years of age may have provided Personal Data to us please contact us at hello modular com State Law Privacy RightsCaliforniaIf you are a California resident you have the rights set forth in this section Please see the Exercising Your Rights section below for instructions regarding how to exercise these rights Please note that we may process Personal Data of our customers end users or employees in connection with our provision of certain services to our customers If we are processing your Personal Data as a service provider you should contact the entity that collected your Personal Data in the first instance to address your rights with respect to such data If there are any conflicts between this section and any other provision of this Privacy Policy and you are a California resident the portion that is more protective of Personal Data shall control to the extent of such conflict If you have any questions about this section or whether any of the following rights apply to you please contact us at hello modular com AccessYou have the right to request certain information about our collection and use of your Personal Data over the past 12 months In response we will provide you with the following information The categories of Personal Data that we have collected about you The categories of sources from which that Personal Data was collected The business or commercial purpose for collecting or selling your Personal Data The categories of third parties with whom we have shared your Personal Data The specific pieces of Personal Data that we have collected about you If we have disclosed your Personal Data to any third parties for a business purpose over the past 12 months we will identify the categories of Personal Data shared with each category of third party recipient If we have sold your Personal Data over the past 12 months we will identify the categories of Personal Data sold to each category of third party recipient DeletionYou have the right to request that we delete the Personal Data that we have collected about you Under the CPRA this right is subject to certain exceptions for example we may need to retain your Personal Data to provide you with the Services or complete a transaction or other action you have requested or deletion may require disproportional effort If your deletion request is subject to one of these exceptions we may deny your deletion request CorrectionYou have the right to request that we correct any inaccurate Personal Data we have collected about you Under the CPRA this right is subject to certain exceptions for example if we decide based on the totality of circumstances related to your Personal Data that such data is correct If your correction request is subject to one of these exceptions we may deny your request Exercising Your RightsTo exercise the rights described above you or your Authorized Agent defined below must send us a request that 1 provides sufficient information to allow us to verify that you are the person about whom we have collected Personal Data and 2 describes your request in sufficient detail to allow us to understand evaluate and respond to it Each request that meets both of these criteria will be considered a Valid Request We may not respond to requests that do not meet these criteria We will only use Personal Data provided in a Valid Request to verify your identity and complete your request You do not need an account to submit a Valid Request We will work to respond to your Valid Request within 45 days of receipt We will not charge you a fee for making a Valid Request unless your Valid Request s is excessive repetitive or manifestly unfounded If we determine that your Valid Request warrants a fee we will notify you of the fee and explain that decision before completing your request You may submit a Valid Request using the following methods Email us at hello modular comSubmit a form at this address https www modular com contactYou may also authorize an agent an Authorized Agent to exercise your rights on your behalf To do this you must provide your Authorized Agent with written permission to exercise your rights on your behalf and we may request a copy of this written permission from your Authorized Agent when they make a request on your behalf Personal Data Sales Opt Out and Opt InWe will not sell your Personal Data and have not done so over the last 12 months To our knowledge we do not sell the Personal Data of minors under 18 years of age We Will Not Discriminate Against You for Exercising Your Rights Under the CPRAWe will not discriminate against you for exercising your rights under the CPRA We will not deny you our services charge you different prices or rates or provide you a lower quality of goods and services if you exercise your rights under the CPRA However we may offer different tiers of our Services as allowed by applicable data privacy laws including the CPRA with varying prices rates or levels of quality of the goods or services you receive related to the value of Personal Data that we receive from you Under California Civil Code Sections 1798 83 1798 84 California residents are entitled to contact us to prevent disclosure of Personal Data to third parties for such third parties direct marketing purposes in order to submit such a request please contact us at hello modular com However we do not sell your Personal Data or have plans to do so Nevada Resident RightsIf you are a resident of Nevada you have the right to opt out of the sale of certain Personal Data to third parties who intend to license or sell that Personal Data You can exercise this right by contacting us at hello modular com with the subject line Nevada Do Not Sell Request and providing us with your name and the email address associated with your account However we do not sell your Personal Data nor have plans to do so Virginia Resident RightsIf you are a Virginia resident you have the rights set forth under the Virginia Consumer Data Protection Act VCDPA Please see the Exercising Your Rights section below for instructions regarding how to exercise these rights Please note that we may process Personal Data of our customers end users or employees in connection with our provision of certain services to our customers If we are processing your Personal Data as a service provider you should contact the entity that collected your Personal Data in the first instance to address your rights with respect to such data Additionally please note that these rights are subject to certain conditions and exceptions under applicable law which may permit or require us to deny your request If there are any conflicts between this section and any other provision of this Privacy Policy and you are a Virginia resident the portion that is more protective of Personal Data shall control to the extent of such conflict If you have any questions about this section or whether any of the following rights apply to you please contact us at hello modular com Access You have the right to request confirmation of whether or not we are processing your Personal Data and to access your Personal Data Correction You have the right to correct inaccuracies in your Personal Data to the extent such correction is appropriate in consideration of the nature of such data and our purposes of processing your Personal Data Portability You have the right to request a copy of your Personal Data in a machine readable format to the extent technically feasible European Union and United Kingdom Data Subject RightsEU and UK Residents If you are a resident of the European Union EU United Kingdom UK Lichtenstein Norway or Iceland you may have additional rights under the EU or UK General Data Protection Regulation the GDPR with respect to your Personal Data as outlined below For this section we use the terms Personal Data and processing as they are defined in the GDPR but Personal Data generally means information that can be used to individually identify a person and processing generally covers actions that can be performed in connection with data such as collection use storage and disclosure Modular will be the controller of your Personal Data processed in connection with the Services If there are any conflicts between this this section and any other provision of this Privacy Policy the policy or portion that is more protective of Personal Data shall control to the extent of such conflict If you have any questions about this section or whether any of the following applies to you please contact us at hello modular com Personal Data We Collect The Categories of Personal Data We Collect section above details the Personal Data that we collect from you Personal Data Use and Processing Grounds The Our Commercial or Business Purposes for Collecting Personal Data section above explains how we use your Personal Data We will only process your Personal Data if we have a lawful basis for doing so Lawful bases for processing include consent contractual necessity and our legitimate interests or the legitimate interest of others as further described below Contractual Necessity We process the following categories of Personal Data as a matter of contractual necessity meaning that we need to process the data to perform under our Terms of Use with you which enables us to provide you with the Services When we process data due to contractual necessity failure to provide such Personal Data will result in your inability to use some or all portions of the Services that require such data Profile or contact data Payment DataLegitimate Interest We process the following categories of Personal Data when we believe it furthers the legitimate interest of us or third parties Device data Web analytics data Geolocation Data Professional Data We may also de identify or anonymize Personal Data to further our legitimate interests Providing customizing and improving the Services Marketing the Services Corresponding with you Meeting legal requirements and enforcing legal terms Completing corporate transactions Consent In some cases we process Personal Data based on the consent you expressly grant to us at the time we collect such data When we process Personal Data based on your consent it will be expressly indicated to you at the point and time of collection Other Processing Grounds From time to time we may also need to process Personal Data to comply with a legal obligation if it is necessary to protect the vital interests of you or other data subjects or if it is necessary for a task carried out in the public interest Sharing Personal Data The How We Share Your Personal Data section above details how we share your Personal Data with third parties EU Data Subject Rights You have certain rights with respect to your Personal Data including those set forth below For more information about these rights or to submit a request please email us at hello modular com Please note that in some circumstances we may not be able to fully comply with your request such as if it is frivolous or extremely impractical if it jeopardizes the rights of others or if it is not required by law but in those circumstances we will still respond to notify you of such a decision In some cases we may also need you to provide us with additional information which may include Personal Data if necessary to verify your identity and the nature of your request Access You can request more information about the Personal Data we hold about you and request a copy of such Personal Data Rectification If you believe that any Personal Data we are holding about you is incorrect or incomplete you can request that we correct or supplement such data Erasure You can request that we erase some or all of your Personal Data from our systems Withdrawal of Consent If we are processing your Personal Data based on your consent as indicated at the time of collection of such data you have the right to withdraw your consent at any time Please note however that if you exercise this right you may have to then provide express consent on a case by case basis for the use or disclosure of certain of your Personal Data if such use or disclosure is necessary to enable you to utilize some or all of our Services Portability You can ask for a copy of your Personal Data in a machine readable format You can also request that we transmit the data to another controller where technically feasible Objection You can contact us to let us know that you object to the further use or disclosure of your Personal Data for certain purposes such as for direct marketing purposes Restriction of Processing You can ask us to restrict further processing of your Personal Data Right to File Complaint You have the right to lodge a complaint about Modular s practices with respect to your Personal Data with the supervisory authority of your country or EU Member State A list of Supervisory Authorities is available here https edpb europa eu about edpb board members_en Transfers of Personal DataThe Services are hosted and operated in the United States U S through Modular and its service providers and if you do not reside in the U S laws in the U S may differ from the laws where you reside By using the Services you acknowledge that any Personal Data about you regardless of whether provided by you or obtained from a third party is being provided to Modular in the U S and will be hosted on U S servers and you authorize Modular to transfer store and process your information to and in the U S and possibly other countries You hereby consent to the transfer of your data to the U S pursuant to EU U S Privacy Shield Frameworks respectively the details of which are further set forth below While the Privacy Shield is no longer a valid basis on which Modular may rely to transfer Personal Data from the EU to the U S pursuant to the GDPR Modular continues to comply with the EU U S Privacy Shield Framework as set forth by the U S Department of Commerce regarding the collection use and retention of Personal Data from EU member countries transferred to the U S pursuant to Privacy Shield Modular has certified that it adheres to the Privacy Shield Principles with respect to such data If there is any conflict between the policies in this Privacy Policy and data subject rights under the Privacy Shield Principles the Privacy Shield Principles shall govern To learn more about the Privacy Shield program and to view our certification page please visit https www privacyshield gov Modular will transfer Personal Data from the EU to the U S pursuant to GDPR adhering to the model clauses In certain situations we may be required to disclose Personal Data in response to lawful requests by public authorities including to meet national security or law enforcement requirements Changes to this Privacy PolicyContact Information If you have any questions or comments about this Privacy Policy the ways in which we collect and use your Personal Data or your choices and rights regarding such collection and use please do not hesitate to contact us at www modular comhello modular comwww modular com contact EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use Modular Acceptable Use Policy Engine Overview PERFORMANCE DASH dOCSMojo Overview DocsHardwareBlogCareersCompany About Vision Team Newsletter Culture contactSign inGet Started MenuAcceptable Use PolicyLast Updated May 2nd 2023This Acceptable Use Policy forms part of both Modular s Terms of Use https www modular com terms and governs User use of the Platform This Acceptable Use Policy outlines certain restricted activities in which Users may not engage while using the Platform Modular reserves the right to suspend and or terminate User accounts for any violations of or failure to comply with the guidelines set forth in this Acceptable Use Policy Compliance with Laws and RegulationsUsers shall use the Platform in compliance with all applicable laws regulations and all of the guidelines set forth herein User SafetyWe do not allow conduct content or activity on Modular that is unlawful or promotes unlawful activities is sexually obscene or relates to sexual exploitation or abuse including of minors is libelous defamatory or fraudulent is discriminatory or abusive toward any individual or group is false inaccurate or intentionally deceptive information and likely to adversely affect the public interest including health safety election integrity and civic participation harasses or abuses another individual or group including our employees officers and agents or other Users threatens or incites violence toward any individual or group especially on the basis of who they are gratuitously depicts or glorifies violence including violent images oris off topic or interacts with Platform features in a way that significantly or repeatedly disrupts the experience of other Users Intellectual Property Authenticity and Private InformationWe do not allow content or activity on Modular that attempts to reverse engineer scrape or otherwise utilize the Platform for any competitive purposes including but not limited to discovering Modular IP that constitutes Confidential Information for use in a competitive product infringes any intellectual property privacy or proprietary right of any party including patent trademark trade secret copyright right of publicity personal information or other rights unlawfully shares unauthorized product licensing keys software for generating unauthorized product licensing keys or software for bypassing checks for product licensing keys including extension of a free license beyond its trial period orimpersonates any person or entity including any of our employees or representatives including through false association with Modular or by fraudulently misrepresenting one s identity or the Platform s purpose Spam and Inauthentic Activity We do not allow content or activity on Modular that is automated excessive bulk activity and coordinated inauthentic activity such as spamming or cryptocurrencybulk distribution of promotions and advertising inauthentic interactions such as fake accounts and automated inauthentic activity creation of or participation in secondary markets for the purpose of the proliferation of inauthentic activity using Modular for propagating abuse on other platforms phishing or attempted phishing orusing Modular servers for any form of excessive automated bulk activity to place undue burden on our servers through automated means or to relay any form of unsolicited advertising or solicitation through our servers such as get rich quick schemes Site Access and SafetyWe do not allow content or activity on Modular that directly supports unlawful active attack or malware campaigns that are causing technical harms such as using the Platform to deliver malicious executables or as attack infrastructure for example by organizing denial of Platform attacks or managing command and control servers with no implicit or explicit dual use purpose prior to the abuse occurring oruses our servers to disrupt or to attempt to disrupt or to gain or to attempt to gain unauthorized access to any platform device data account or network Platforms Usage LimitsUsers will not reproduce duplicate copy sell resell scrape re use or exploit any portion of the Platform use of the Platform or access to the Platform without Modular s express written permission PrivacyMisuse of Personal Information is prohibited Any person or entity collecting data from the Platform must comply with the Modular Privacy Policy https www modular com privacy If a User collects any Personal Information from the Platform that User agrees it will only use that Personal Information for the purpose for which the respective User to whom the Personal Information pertains has authorized its use User agrees that it will reasonably secure any Personal Information it has gathered from the Platform and User will respond promptly to complaints removal requests and do not contact requests from us or other Users to the extent applicable AdvertisingWhile we understand that Users may want to promote their respective User Generated Content by posting supporters names or logos in its account the primary focus of the User Generated Content posted to the Platform should not be advertising or promotional marketing Users may include static images links and promotional text in the README documents or project description sections associated with its Account s but they must be related to the AI Algorithms Users and Developers are sharing on the Platform Users may not advertise by posting monetized or excessive bulk content Users may not promote or distribute content or activity that is illegal or otherwise prohibited by the applicable Terms of Use by which they are bound or this Acceptable Use Policy including excessive automated bulk activity for example spamming get rich quick schemes and misrepresentation or deception related to its promotion If a User decide to post any promotional materials in its account User is solely responsible for complying with all applicable laws and regulations including without limitation the U S Federal Trade Commission s Guidelines on Endorsements and Testimonials Modular reserves the right to remove any promotional materials or advertisements that in our sole discretion violate any Modular terms or policies User ProtectionUser must not engage in activity that significantly harms other Users Modular will interpret policies and resolve disputes in favor of protecting Users as a whole EngineMojo HardwarePerformanceGet StartedBlogCareersCopyright 2023 Modular Inc Terms Privacy Acceptable Use ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "# Load the spacy English model\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "\n",
    "# Define a function to clean a text corpus\n",
    "def clean_corpus(corpus):\n",
    "#     # Remove all HTML tags\n",
    "#     corpus = re.sub(\"<[^>]*>\", \"\", corpus)\n",
    "\n",
    "#     # Remove all punctuation\n",
    "#     corpus = re.sub(\"[,.!?]\", \"\", corpus)\n",
    "\n",
    "#     # Lowercase all text\n",
    "#     corpus = corpus.lower()\n",
    "\n",
    "    corpus = re.sub(r\"\\W+\", \" \", corpus)\n",
    "\n",
    "    # Split the corpus into sentences\n",
    "    sentences = corpus.split(\".\")\n",
    "\n",
    "    # Remove empty sentences\n",
    "    sentences = [sentence for sentence in sentences if sentence]\n",
    "\n",
    "#     # Tokenize the sentences\n",
    "#     tokens = []\n",
    "#     for sentence in sentences:\n",
    "#         tokens.extend(nlp(sentence).tokens)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "# Clean the text corpus\n",
    "tokens = clean_corpus(ctext)\n",
    "\n",
    "# Print the tokens\n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ff254f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T15:00:10.772347Z",
     "start_time": "2023-05-13T15:00:10.772312Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the spacy English model\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "\n",
    "# Clean the text corpus\n",
    "def clean_text(text):\n",
    "  # Remove punctuation marks\n",
    "  text = re.sub(r\"\\W+\", \" \", text)\n",
    "\n",
    "  # Convert text to lowercase\n",
    "  text = text.lower()\n",
    "\n",
    "  # Remove stop words\n",
    "  stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "  text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "  # Return the cleaned text\n",
    "  return text\n",
    "\n",
    "# Tokenize the text corpus\n",
    "def tokenize_text(text):\n",
    "  # Create a spacy document\n",
    "  nlp.max_length = len(ctext) + 100\n",
    "  doc = nlp(text)\n",
    "\n",
    "  # Get the tokens\n",
    "  tokens = [token.text for token in doc]\n",
    "\n",
    "  # Return the tokens\n",
    "  return tokens\n",
    "\n",
    "# Transform the text corpus into NLP tokens\n",
    "cctext = clean_text(ctext)\n",
    "tokens = tokenize_text(cctext)\n",
    "\n",
    "# Print the NLP tokens\n",
    "cctext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c6c730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T15:00:10.774626Z",
     "start_time": "2023-05-13T15:00:10.774602Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import spacy\n",
    "\n",
    "# Set up OpenAI API credentials\n",
    "#openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai.api_key = \" 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\"\n",
    "\n",
    "# Define the prompt that ChatGPT will use to generate responses\n",
    "prompt = \"The following is a conversation with an AI assistant. The AI assistant is helpful, kind, and knowledgeable.\"\n",
    "\n",
    "def fine_tune_chatgpt(token_str):\n",
    "    # Define the parameters for fine-tuning ChatGPT\n",
    "    model = \"text-davinci-002\"  # pre-trained GPT-3.5 model to finetune\n",
    "    engine = \"davinci\"          # API endpoint to use for finetuning\n",
    "    temperature = 0.7           # controls the randomness of the generated responses\n",
    "    max_tokens = 1024           # maximum length of generated response\n",
    "    epochs = 5                  # number of times to iterate through the training data\n",
    "    \n",
    "    # Fine-tune the model using the OpenAI API\n",
    "    fine_tuned_model = openai.FineTune.create(\n",
    "        prompt=prompt,\n",
    "        model=model,\n",
    "        engine=engine,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        epochs=epochs,\n",
    "        data=token_str\n",
    "    )\n",
    "\n",
    "    # Return the ID of the fine-tuned model for future reference\n",
    "    return fine_tuned_model.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb64aa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T15:00:10.776680Z",
     "start_time": "2023-05-13T15:00:10.776655Z"
    }
   },
   "outputs": [],
   "source": [
    "fine_tuned_model__chatgpt_3_5 = fine_tune_chatgpt(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf52730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7a4053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3e886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
